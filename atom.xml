<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>大黄菌的个人博客</title>
  <subtitle>天下武功，无勤不破</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kyonhuang.top/"/>
  <updated>2018-06-30T13:20:59.186Z</updated>
  <id>http://kyonhuang.top/</id>
  
  <author>
    <name>Kyon Huang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>从大三的暑假往后望</title>
    <link href="http://kyonhuang.top/2018-summer-and-after/"/>
    <id>http://kyonhuang.top/2018-summer-and-after/</id>
    <published>2018-06-30T13:14:57.000Z</published>
    <updated>2018-06-30T13:20:59.186Z</updated>
    
    <content type="html"><![CDATA[<p>今年夏令营的竞争着实激烈，据说每所学校的申报人数都比往年翻番有余。每天都在各种 QQ 群中探听八方消息，眼巴巴地等待着邮件、短信和电话，却至今除开本校没有收到一个入营 offer。焦虑呵，焦虑呵，不在焦虑中爆发，就在焦虑中灭亡。索性做好在珞珈山再待三年的准备，先规划一下暑假，再向后张望张望。</p>
<a id="more"></a>
<h2 id="暑假计划"><a href="#暑假计划" class="headerlink" title="暑假计划"></a>暑假计划</h2><h3 id="智能自动问答系统"><a href="#智能自动问答系统" class="headerlink" title="智能自动问答系统"></a>智能自动问答系统</h3><p>历经艰难，终于提交了中国软件杯初赛的参赛版本。当然所谓艰险都是因为自己的技术不足和时间调节不合理导致的。暑期实训的项目也是做这个智能自动问答系统，对自己在这个项目中的预期目标如下：</p>
<ol>
<li>通过项目和论文阅读，了解自动问答系统的基本结构、技术难点、常用算法等，以博文的方式进行记录和总结；</li>
<li>学习 SpringBoot 和 Radis 的基础使用，复习 MySQL 的使用；</li>
<li>争取拿个奖。</li>
</ol>
<h3 id="学科复习"><a href="#学科复习" class="headerlink" title="学科复习"></a>学科复习</h3><p>尽管可能没有夏令营了，还是进行学科复习，争取在八月预推免和九月推免冲一个理想的结果。</p>
<p>目前还没有复习的学科：</p>
<ul>
<li>[ ]高等数学</li>
<li>[ ]线性代数</li>
<li>[ ]概率论</li>
<li>[ ]系统级程序设计</li>
<li>[ ]数据库</li>
</ul>
<h3 id="中文短文本情感分析"><a href="#中文短文本情感分析" class="headerlink" title="中文短文本情感分析"></a>中文短文本情感分析</h3><p>在浏览器的标签页堆积了很多资料一直没有看，希望能在暑假给这个项目画一个圆满的句号。对自己在这个项目中的预期目标如下：</p>
<ol>
<li>阅读完《Deep Learning for Sentiment Analysis: A Survey》，以博文的方式对文中知识作梳理，对经典技术（Word2Vec、LSTM 等）要能说出自己的理解；</li>
<li>用 CNN、RNN、LSTM 进行实验，以博文的方式进行记录和总结；</li>
<li>完善项目，争取能够部署到云服务器上。</li>
</ol>
<h3 id="数据结构与算法学习"><a href="#数据结构与算法学习" class="headerlink" title="数据结构与算法学习"></a>数据结构与算法学习</h3><p>整理《算法》笔记，适当地学一些用处和出现频率较大的算法。练习可以做<br>POJ/HDOJ、CCF CSP 题目和 LeetCode。目的是保持一个解题思维的活跃。</p>
<h2 id="大四生活"><a href="#大四生活" class="headerlink" title="大四生活"></a>大四生活</h2><p>不知不觉就到了大学阶段的尾声了。</p>
<p>在拿到保研资格，去处尘埃落定后，首先是和未来的导师积极沟通，考虑是不是能提前去实验室熟悉环境和适应研究生生活。如果不能前往的话，也和导师约定一下学习的方向与要求，并可以考虑毕业论文做什么方向。</p>
<p>因为研究生的方向大概率是数据科学相关，所以应该需要继续学习。希望是能够认真打一次 Kaggle 的正式比赛，争取能够到前 10%，从而对 Python 代码编写、开源框架的使用、数据科学项目的思路以及优化的技巧都有一个极大的锻炼。另外，根据研究方向学习公开课，如果是 NLP 就考虑啃完 cs224n，其他方向也考虑啃完一门经典公开课，做和深度学习一样认真的笔记。</p>
<p>大学三年，尽管代码编写也不算少，大型项目也有花旗杯等，但总觉得自己的编程水平不稳。希望能在 Java 和 Python 上再多看一些好书，多写一些代码，多往 Github 上放一些完备而有价值的项目，多“骗”一点 star。希望本科最后一年能够啃完 3-4 本技术书籍，并满足在 Github 上拥有一个 100+ star 的技术性项目。</p>
<p>大学最后一年，也需要思考自己的未来。大学教给我最重要的教训是，信息影响规划，规划影响未来。多和学长学姐交流，了解国内读博、国外读博以及工作的利与弊、在研究生阶段需要满足的条件或者需要学习和准备的东西，以制定相应的规划，争取更好的平台。</p>
<p>最后，在大学的最后一年留下一点回忆。去万林博物馆里看看，和同学探索一下周边的馆子和旧书店，在东湖边骑骑车，在武汉的一些景点去看看…</p>
<blockquote>
<p>笑一个吧<br>功成名就不是目的<br>让自己快乐快乐这才叫做意义<br>童年的纸飞机<br>现在终于飞回我手里 </p>
<p>—  周杰伦 《稻香》</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今年夏令营的竞争着实激烈，据说每所学校的申报人数都比往年翻番有余。每天都在各种 QQ 群中探听八方消息，眼巴巴地等待着邮件、短信和电话，却至今除开本校没有收到一个入营 offer。焦虑呵，焦虑呵，不在焦虑中爆发，就在焦虑中灭亡。索性做好在珞珈山再待三年的准备，先规划一下暑假，再向后张望张望。&lt;/p&gt;
    
    </summary>
    
      <category term="翻滚吧大学生" scheme="http://kyonhuang.top/categories/%E7%BF%BB%E6%BB%9A%E5%90%A7%E5%A4%A7%E5%AD%A6%E7%94%9F/"/>
    
    
      <category term="随笔" scheme="http://kyonhuang.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
      <category term="目标" scheme="http://kyonhuang.top/tags/%E7%9B%AE%E6%A0%87/"/>
    
      <category term="学习之路" scheme="http://kyonhuang.top/tags/%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>中文短文本情感分析 web 应用开发记录（一）</title>
    <link href="http://kyonhuang.top/sentiment-analysis-webapp-record1/"/>
    <id>http://kyonhuang.top/sentiment-analysis-webapp-record1/</id>
    <published>2018-06-21T14:22:05.000Z</published>
    <updated>2018-06-29T02:32:42.505Z</updated>
    
    <content type="html"><![CDATA[<p>“中文短文本情感分析 web 应用”是我带领的小组在《软件工程》这门课的大作业选题。按照这门课大作业的传统风格，就是做一个比较寻常的网站/APP，不过我这次提议另辟蹊径，一是我个人对情感分析这个方面比较感兴趣，想要借此机会进行了解和实践；二是组内成员都志在继续深造，做一个带有科研意味的项目或许能为简历添色。</p>
<p>先简单介绍一下我们的项目。该 web 应用可分析用户输入的中文短文本中蕴含的情感，并输出数值化结果。前端使用 Vue.js 开发，后台使用 Flask 开发。算法部分目前包含自主实现的词袋模型和引入的 SnowNLP。项目地址如下（目前服务器关了，想要尝试效果可以将项目 clone 到本地，照着 README 运行）：</p>
<ul>
<li><a href="http://kyonhuang.top/sentiment-analysis-webapp/">在线使用地址</a></li>
<li><a href="https://github.com/bighuang624/sentiment-analysis-webapp" target="_blank" rel="external">项目地址</a></li>
</ul>
<p>截止这篇博文写作时，这个项目算是成型，也在 Github 上获得了 7 个 star。但是也遇到了一些问题，当然最大的问题就是分析效果不好。效果不好的原因包括很多，后文会一一介绍，当然其中一个是我们目前的算法部分还没有涉及到深度学习，不过我正在争取在近期用 LSTM 等实现效果较好的模型。</p>
<p>这篇博文首先会简单介绍情感分析的概念、技术和难点。之后针对我们的项目，详细介绍我们使用的算法、迄今为止遇到的问题和一些改进措施。</p>
<a id="more"></a>
<h2 id="什么是情感分析？"><a href="#什么是情感分析？" class="headerlink" title="什么是情感分析？"></a>什么是情感分析？</h2><p><strong>情感分析（Sentiment analysis）</strong>或意见挖掘（Opinion mining）是对人群对于产品、服务、组织、个体、问题、事件、话题等实体的意见、情感、情绪、评价、态度的计算研究。鉴于网络社交媒体的风行，我们拥有了海量的情绪化数据。情感分析已经成为自然语言处理中最有吸引力的研究领域之一，它与管理科学、社会科学领域有交集。情感分析在现实中的典型应用包括舆情分析、民意调查、产品意见调查、预测股票市场行情等等。</p>
<p>最典型的情感分析会分析一段文本对某个对象的情感是正面的还是负面。更细致的处理包括情感的分类（快乐、愤怒、恐惧、悲哀等）和情感的程度。意见挖掘可能还需要从文本中挖掘出对象的属性，再分析对应属性的情感。</p>
<p>早期的情感分析技术包括监督方法（支持向量机、最大熵、朴素贝叶斯等监督机器学习方法）和非监督方法（包括利用情感词汇、语法分析和句法模式的各种方法），而深度学习走红后，其应用到情感分析的出色效果催生大量基于深度学习的情感分析研究[1]。</p>
<h2 id="中文情感分析的难点"><a href="#中文情感分析的难点" class="headerlink" title="中文情感分析的难点"></a>中文情感分析的难点</h2><p>以下是我在查阅资料后总结的一些中文情感分析的难点：</p>
<ol>
<li>很多情感的表达是隐晦的，没有特别明显的代表性词语。例如“蓝屏”这个词一般不会出现在情感词典之中，但这个词明显表达了不满的情绪。因此需要另外根据具体领域构建针对性的情感词典。</li>
<li>同一个词在不同语境或领域里有不同的意思，可能表达不同的情感态度，例如“我家洗衣机声音很大”这些很可能是差评，而“我家音响声音很大”很可能就是好评。反讽的表达同理。</li>
<li>网络流行语等新词也会影响情感分析，比如“给力”、“不明觉厉”、“累觉不爱”等，这些词利用传统的分词一般都会被切开，而且会影响词性标注，如果想避免只能加入人工干预，修改分词的粒度和词性标注的结果。</li>
<li>以上三条在做英语情感分析时也会遇到。但是中文独有的问题是缺少高质量的有标注数据集。相比起来，英文情感分析有公认的数据集 <a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="external">IMDB</a>。此外，可能还需要一些高质量的情感词典，英文有 SentiWordNet，但是中文的词典资源质量不高，不细致，另外缺乏主客观词典。当然，因为有监督的机器学习方法的风行，现在情感分析也不一定非要情感词典。</li>
</ol>
<p>因为我们的项目主要还是拿文本分类的方法进行处理，所以以上问题不是都遇到了，仅停留在了解层面，如有谬误欢迎指出。</p>
<h2 id="初步尝试"><a href="#初步尝试" class="headerlink" title="初步尝试"></a>初步尝试</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>首先谈谈数据。根据前文所述，中文的有标注数据集很难找。我前两周和做过类似工作的学长交流时，他的做法是自行标注。而我们选择的做法是自己用 Python 编写爬虫爬取各类含评论的网站，将评论正文作为数据，评论的星级作为标签：</p>
<p><img src="https://raw.githubusercontent.com/bighuang624/pic-repo/master/douban-comment.png" alt=""></p>
<p>我们最终爬取了豆瓣的 146856 条电影评论和蜂窝网的 174055 条酒店评论作为我们的数据集。你可以在 <a href="https://github.com/bighuang624/sentiment-analysis-webapp/tree/master/training" target="_blank" rel="external">sentiment-analysis-webapp/training/</a> 找到这两份数据以及训练模型的代码。</p>
<p>我们希望最终给出的结果也能反应情感的程度，而不是单纯的正负二元分类。因此，我们没有对标签做后续处理。</p>
<h3 id="算法部分实现过程"><a href="#算法部分实现过程" class="headerlink" title="算法部分实现过程"></a>算法部分实现过程</h3><h4 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h4><p>既然是使用监督机器学习算法，那么自然需要特征。计算机是看不懂自然语言的，<strong>从文本中提取特征</strong>最终的结果一般是将文本转换为<strong>向量</strong>，而这一步不管是使用什么算法，都需要首先对文本进行分词。</p>
<p>成熟的中文分词工具还是比较多的，包括 <a href="https://github.com/FudanNLP/fnlp" target="_blank" rel="external">FudanNLP</a>、结巴分词、THULAC、Stanford CoreNLP。其中 Stanford CoreNLP 是重量级工具，需要自备数据集、数据字典等，不太方便；另外三个工具经过简单的比较后，我们最终选用了结巴分词，因为确实很容易使用，分词效果也很好。</p>
<p>分词的相关代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> jieba</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chinese_word_cut</span><span class="params">(mytext)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(jieba.cut(mytext))</div><div class="line">    </div><div class="line">X[<span class="string">'cutted_comment'</span>]=X.comment.apply(chinese_word_cut)</div></pre></td></tr></table></figure>
<h4 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h4><p>我们的算法都是使用 scikit-learn 实现的，其中从文本中提取特征的方法在<code>sklearn.feature_extraction.text</code>包中。</p>
<p>比较典型的自然语言向量化方法有词袋模型（带或不带 TF-IDF）、词嵌入等等，在这里可以简单的介绍一下。</p>
<h5 id="词袋模型"><a href="#词袋模型" class="headerlink" title="词袋模型"></a>词袋模型</h5><p><strong>词袋模型（bag of words）</strong>不考虑词语的出现顺序，也不考虑词语和前后词语之间的连接。每个词都被当作一个独立的特征来看待。这样，每个句子被编码成一个 $R^{|V| \times 1}$向量，其中 $|V|$是语料库中所有单词的数量。所有单词组成一个词汇表，每个句子向量的第 $i$ 位即是词汇表中第 $i$ 个词在句子中出现的次数。</p>
<p>词袋模型可以以单个词语做单位，也可以以 n 个连续的单词做单位（被称为 n-gram）。词袋模型的一大问题是文本中单词顺序和上下文所蕴含的信息被完全丢弃。</p>
<p>词袋模型的相关代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</div><div class="line"></div><div class="line">max_df=<span class="number">0.8</span> <span class="comment">#在超过这一比例的文档中出现的关键词过于平凡，去除掉</span></div><div class="line">min_df=<span class="number">3</span> <span class="comment">#在低于这一数量的文档中出现的关键词过于独特，去除掉</span></div><div class="line"></div><div class="line">vect = CountVectorizer(max_df=max_df, min_df=min_df, token_pattern=<span class="string">u'(?u)\\b[^\\d\\W]\\w+\\b'</span>)</div><div class="line">term_matrix = pd.DataFrame(vect.fit_transform(X_train.cutted_comment).toarray(), columns=vect.get_feature_names())</div></pre></td></tr></table></figure>
<h5 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h5><p>TF-IDF 是在词袋模型的基础上<strong>度量词语重要性</strong>的指标。在度量词语重要性时，我们的直觉是在同一文档中，最频繁出现的词语应该最重要。但实际上，出现最频繁的大部分词语肯定是类似于“the”、“and”等常见停用词（后文会谈停用词是什么）。并且，这些词在其他文档中也频繁出现。而最能描述文档主题的词一般在本文档中频繁出现，但在整个语料库中出现次数相对较少。</p>
<p>根据以上思想，我们通过 TF-IDF 这个指标来寻找重要的词语。TF（Term Frequency）指<strong>词项频率</strong>，IDF（Inverse Document Frequency）指<strong>逆文档频率</strong>。TF-IDF 通过以下方法计算：假定文档集中有 $N$ 篇文档，$f_{ij}$ 为词项 $i$ 在文档 $j$ 中出现的频率（即次数），则词项 $i$ 在文档 $j$ 中的词项频率 $TF_{ij}$ 定义为</p>
<p>$$TF_{ij} = \frac{f_{ij}}{max_kf_{kj}}$$</p>
<p>这里有一个归一化的操作，通过除以同一文档中出现最多的词项（可能不考虑停用词的频率）的频率来计算。</p>
<p>假定词项 $i$ 在文档集的 $n_i$ 篇文档中出现，那么词项 $i$ 的 IDF 定义如下：</p>
<p>$$IDF_i = log_2{\frac{N}{n_i}}$$</p>
<p>于是词项 $i$ 在文档中的得分被定义为 $TF_{ij} \times IDF_i$。相关代码如下（其实就是将<code>sklearn.feature_extraction.text</code>提供的<code>CountVectorizer</code>换为<code>TfidfVectorizer</code>）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</div><div class="line"></div><div class="line">max_df=<span class="number">0.8</span> <span class="comment">#在超过这一比例的文档中出现的关键词过于平凡，去除掉</span></div><div class="line">min_df=<span class="number">3</span> <span class="comment">#在低于这一数量的文档中出现的关键词过于独特，去除掉</span></div><div class="line"></div><div class="line">vect = TfidfVectorizer(max_df=max_df, min_df=min_df, token_pattern=<span class="string">u'(?u)\\b[^\\d\\W]\\w+\\b'</span>)</div><div class="line">term_matrix = pd.DataFrame(vect.fit_transform(X_train.cutted_comment).toarray(), columns=vect.get_feature_names())</div></pre></td></tr></table></figure>
<h5 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h5><p><strong>词嵌入（Word Embedding）</strong>是指把一个维数为所有词的数量的高维空间（one-hot 形式表示的词）“嵌入”到一个维数低得多的连续向量空间中，每个单词或词组被映射为实数域上的向量。因为我们暂时还没用到相关技术，所以不对学习词嵌入的方法进行介绍了（可能会在下一篇博文谈论）。想要了解更多可以看<a href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Sequence_Models/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5">自然语言处理与词嵌入 - 吴恩达《深度学习》系列课程笔记</a>。</p>
<h4 id="停用词"><a href="#停用词" class="headerlink" title="停用词"></a>停用词</h4><p>谈一下停用词的问题。无论是处理中文还是英文，都需要处理停用词。<strong>停用词指那些用于辅助表达但本身不携带任何含义的词</strong>，比如英文中的定冠词“the”。这些词经常在文本中大量出现，如果将其和那些包含信息更丰富的词汇放在一起统计，就容易对我们把握文本的特征形成干扰。所以在文本分类中，一般要首先在文本数据中去掉这些停用词。</p>
<p>scikit-learn 中自带了英文停用词。如果想做中文停用词的处理，可以用一些机构开源的停用词表。哈工大、四川大学、百度都有类似的词表，可以在<a href="https://github.com/chdd/weibo/tree/master/stopwords" target="_blank" rel="external">这里</a>找到。</p>
<p>不过一个值得讨论的问题是，我们做的是情感分析工作，而非单纯的文本分类。实际上，很多语气词和标点等都是停用词，但是却对句子的情感表达有着很大的影响。因此，一般在做情感分析工作时，倾向于不去处理停用词。我们会在后文的效果展示中讨论是否去除停用词对我们实际的模型效果的影响。</p>
<p>还是放一下处理停用词的相关代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_custom_stopwords</span><span class="params">(stop_words_file)</span>:</span></div><div class="line">    <span class="keyword">with</span> open(stop_words_file) <span class="keyword">as</span> f:</div><div class="line">        stopwords = f.read()</div><div class="line">    stopwords_list = stopwords.split(<span class="string">'\n'</span>)</div><div class="line">    custom_stopwords_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> stopwords_list]</div><div class="line">    <span class="keyword">return</span> custom_stopwords_list</div><div class="line">    </div><div class="line">stop_words_file = <span class="string">"stopwords.dat"</span> <span class="comment"># 停用词表文件名</span></div><div class="line">stopwords = get_custom_stopwords(stop_words_file)</div><div class="line"></div><div class="line"><span class="comment"># 注意这里增加了一个选项</span></div><div class="line">vect = CountVectorizer(max_df = max_df, </div><div class="line">                       min_df = min_df, </div><div class="line">                       token_pattern=<span class="string">u'(?u)\\b[^\\d\\W]\\w+\\b'</span>, </div><div class="line">                       stop_words=frozenset(stopwords))</div></pre></td></tr></table></figure>
<h4 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h4><p>我们初期使用的分类算法是<a href="http://kyonhuang.top/Machine-learning-in-action-notes/#/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF">朴素贝叶斯</a>，相关代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</div><div class="line">nb = MultinomialNB()</div><div class="line">nb.fit(X_train.cutted_comment, y_train)</div></pre></td></tr></table></figure>
<h4 id="管道和模型持久化"><a href="#管道和模型持久化" class="headerlink" title="管道和模型持久化"></a>管道和模型持久化</h4><p>scikit-learn 提供<strong>管道</strong>功能，可以将处理流程中的工作顺序连接，隐藏其中的功能，从外部一次调用，就能完成顺序定义的全部工作。这样做可以简化调用过程，减少出错几率。</p>
<p>同时，scikit-learn 也支持<strong>模型持久化</strong>，即将训练好的模型保存到硬盘，待后台程序启动时可以直接加载到内存。这样，就不必每次启动后台程序时都要花费大量时间和资源进行训练了。相关代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</div><div class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</div><div class="line">pipe = make_pipeline(vect, nb)</div><div class="line">pipe.fit(X_train.cutted_comment, y_train)</div><div class="line">y_pred=pipe.predict(X_test.cutted_comment)</div><div class="line">joblib.dump(pipe, <span class="string">"hotel_comment.pkl"</span>)</div></pre></td></tr></table></figure>
<h2 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h2><p>为了量化模型效果，需要模型实际预测输出和样本真是输出之间的差异（即<strong>误差</strong>）。因为过拟合的存在，训练误差不适合作为模型选择标准，因此需要从数据集中划分出与训练集互斥的测试集，以测试误差作为泛化误差的近似。</p>
<p>这里，我们选用<strong>交叉验证法（cross-validation）</strong>，这是一种十分常用的模型评估方法。<strong>k 折交叉验证（k-fold CV）</strong>指划分 k 个互斥子集，每次用 k-1 个子集作训练集，余下一个子集作测试集，进行 k 次训练与测试并取均值。其优点是结果准确，Kaggle 的参赛者大多会提交 CV 分最高的模型，而非在官方提供的测试集上得分最高的模型；缺点是计算量比较大。</p>
<p>常用的 k 值包括 5、10、20。这里我们统一用 5 折交叉验证来分析各种搭配得到的模型效果。其中所使用的停用词为<a href="https://github.com/dongxiexidian/Chinese/blob/master/stopwords.dat" target="_blank" rel="external">这份</a>。</p>
<p>对于豆瓣数据集，各种模型的评分如下：</p>
<ul>
<li>CountVectorizer + 不去除停用词：0.505020743656528</li>
<li>CountVectorizer + 去除停用词：0.4937080095876466</li>
<li>TfidfVectorizer + 不去除停用词：0.49594151903667905</li>
</ul>
<p>而对于酒店数据集，各种模型的评分如下：</p>
<ul>
<li>CountVectorizer + 不去除停用词：0.5133750057452774</li>
<li>CountVectorizer + 去除停用词：0.5060018311093455</li>
<li>TfidfVectorizer + 不去除停用词：0.5297950445100629</li>
</ul>
<p>可以看到，去除停用词的效果普遍比不去除停用词要差。而词袋模型和 TF-IDF 的效果比较结果则与数据集有关，这也说明需要针对具体问题选择合适的学习算法。</p>
<h2 id="问题和改进措施"><a href="#问题和改进措施" class="headerlink" title="问题和改进措施"></a>问题和改进措施</h2><p>从之前 CV 的分数，可以判断我们模型的正确率大概在 50% 左右，相比起在 5 种给分中随机预测的 20% 看似要好很多，但实际表现为不管输入的是正面还是负面情感句子、程度如何，基本上都给 5 分，偶尔会给 4 分。</p>
<h3 id="样本类别不均衡"><a href="#样本类别不均衡" class="headerlink" title="样本类别不均衡"></a>样本类别不均衡</h3><p>从模型经常给出高分预测的表现，我们很容易做出样本中<strong>正负类别样本不均衡</strong>的判断。实际上，我们的酒店评论数据集中，有 148939 条标签值大于 3，而只有 6895 条标签值小于 3，比例达到 21.6 : 1。豆瓣数据集情况略好，但正负面评论数比例也达到了 5.69 : 1。数据集中样本类别不均衡导致训练出的模型偏向于给出正面预测，以减小损失函数。</p>
<p>处理样本不均衡的方式包括以下几种：</p>
<ul>
<li><p><strong>尝试其他评价指标</strong>：当样本类别不均衡时，准确度这个指标不但没有说服力，反而会对分类器的好坏产生误导。这时，<strong>精确率（Precision）</strong>、<strong>召回率（Recall）</strong>以及 <strong>F1 得分（F1 Score，精确率与召回率的调和平均）</strong>作为评价指标会更加有效。</p>
</li>
<li><p><strong>对数据集进行过采样和欠采样</strong>：</p>
<ul>
<li><strong>过采样（over-sampling）</strong>指采样个数大于该类样本个数，适用于小类的数据样本。具体表现为添加部分样本的副本；</li>
<li><strong>欠采样（under-sampling）</strong>指采样个数小于该类样本个数，适用于大类的数据样本。具体表现为删除部分样本。</li>
</ul>
</li>
<li><p><strong>数据增强</strong>：数据增强是 CV 中经常使用的方式，联系到 NLP 领域，可以将文本进行句子顺序打乱、句内词序打乱、同义词替换等操作来增加相应类别的样本量。</p>
</li>
</ul>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><p>使用 scikit-learn 提供的方法，我们来计算一下在原始酒店数据集上用 TfidfVectorizer + 不去除停用词训练出来的模型的精确率、召回率和 F1 得分：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line">metrics.accuracy_score(y_test, y_pred)</div><div class="line"><span class="string">'''</span></div><div class="line">0.5307027623293653</div><div class="line">'''</div><div class="line">metrics.confusion_matrix(y_test, y_pred)</div><div class="line"><span class="string">'''</span></div><div class="line">array([[    0,     0,   151,   237,    27],</div><div class="line">       [    0,     0,   227,  1017,   106],</div><div class="line">       [    0,     0,   530,  3603,   507],</div><div class="line">       [    0,     1,   327, 12089,  6894],</div><div class="line">       [    0,     0,    58,  7266, 10474]])</div><div class="line">'''</div><div class="line">metrics.precision_score(y_test, y_pred, average=<span class="string">'macro'</span>)</div><div class="line"><span class="string">'''</span></div><div class="line">0.29816554278872476</div><div class="line">'''</div><div class="line">metrics.recall_score(y_test, y_pred, average=<span class="string">'micro'</span>)</div><div class="line"><span class="string">'''</span></div><div class="line">0.5307027623293653</div><div class="line">'''</div><div class="line">metrics.f1_score(y_test, y_pred, average=<span class="string">'weighted'</span>)  </div><div class="line"><span class="string">'''</span></div><div class="line">0.5048778200537771</div><div class="line">'''</div></pre></td></tr></table></figure>
<p>可以看到精确率相对来说比较低。</p>
<!--1. 说明什么？
2. 进一步处理数据-->
<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p>解决了样本类别不均衡以及模型评估的问题，我们很容易想到，我们一开始采用的朴素贝叶斯是否是在这个问题上表现最好的机器学习模型？SVM、随机森林或者 Kaggle 前任大杀器 XGBoost 会不会有更出色的结果？</p>
<p>To be continued…</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>文本分类中常见的特征选择方法除开 TF-IDF 外，还包括信息增益、互信息、期望交叉熵、CHI 统计等[2]。根据清华大学刘知远老师在博士阶段的研究，TF-IDF 具有较强的普适性，能够满足绝大部分的中文场景下的需求。不过也有其他研究工作表明使用信息增益的性能表现也很优秀。由于我们之后会使用深度学习模型在做端到端的学习，并且特征选择不是目前的瓶颈，因此这里不进行深入研究。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>通过这个项目，我感觉我确实很喜欢情感分析这个研究方向。我也因此承担了绝大部分的算法研究开发工作，查阅了很多文献和网络资料，由此对情感分析研究现状乃至自然语言处理的一些基础知识有了比较深入的了解，可谓受益匪浅。</p>
<p>比较可惜的是，我们在课程作业结题时实现的版本还不尽人意，而且因为事务忙碌和自身安排原因，深度学习模型计划了很久都没有动手实现。写这篇博文一是对现有工作做一个总结，同时有些算法写的比较详细，巩固一下所学知识；二就是督促自己尽早实现基于深度学习的模型，届时也会出该系列的第二篇博文。也欢迎看到这里的读者在 Github 和这里继续关注我们的工作。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><h3 id="引用文献"><a href="#引用文献" class="headerlink" title="引用文献"></a>引用文献</h3><ul>
<li>[1] <a href="https://arxiv.org/abs/1801.07883" target="_blank" rel="external">Deep Learning for Sentiment Analysis : A Survey</a>. Lei Zhang, Shuai Wang, Bing Liu.</li>
<li>[2] 徐泓洋, 杨国为. <a href="http://www.wanfangdata.com.cn/details/detail.do?_type=perio&amp;id=gykzjsj201711038" target="_blank" rel="external">中文文本特征选择方法研究综述</a>[J]. 工业控制计算机, 2017, 30(11):80-81.</li>
</ul>
<h3 id="参考书籍"><a href="#参考书籍" class="headerlink" title="参考书籍"></a>参考书籍</h3><ul>
<li>《互联网大规模数据挖掘与分布式处理》 1.3.1</li>
</ul>
<h3 id="网络资料"><a href="#网络资料" class="headerlink" title="网络资料"></a>网络资料</h3><ul>
<li><a href="https://www.zhihu.com/question/20700012" target="_blank" rel="external">中文情感分析 (Sentiment Analysis) 的难点在哪？现在做得比较好的有哪几家？ - 知乎</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34482959" target="_blank" rel="external">如何用Python和机器学习训练中文文本情感分类模型？</a></li>
<li><a href="https://blog.csdn.net/simona081/article/details/80275506" target="_blank" rel="external">处理文本分类中样本不均衡的问题 - CSDN博客</a></li>
</ul>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']]}
});
</script>
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=default"></script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;“中文短文本情感分析 web 应用”是我带领的小组在《软件工程》这门课的大作业选题。按照这门课大作业的传统风格，就是做一个比较寻常的网站/APP，不过我这次提议另辟蹊径，一是我个人对情感分析这个方面比较感兴趣，想要借此机会进行了解和实践；二是组内成员都志在继续深造，做一个带有科研意味的项目或许能为简历添色。&lt;/p&gt;
&lt;p&gt;先简单介绍一下我们的项目。该 web 应用可分析用户输入的中文短文本中蕴含的情感，并输出数值化结果。前端使用 Vue.js 开发，后台使用 Flask 开发。算法部分目前包含自主实现的词袋模型和引入的 SnowNLP。项目地址如下（目前服务器关了，想要尝试效果可以将项目 clone 到本地，照着 README 运行）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://kyonhuang.top/sentiment-analysis-webapp/&quot;&gt;在线使用地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/bighuang624/sentiment-analysis-webapp&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;项目地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;截止这篇博文写作时，这个项目算是成型，也在 Github 上获得了 7 个 star。但是也遇到了一些问题，当然最大的问题就是分析效果不好。效果不好的原因包括很多，后文会一一介绍，当然其中一个是我们目前的算法部分还没有涉及到深度学习，不过我正在争取在近期用 LSTM 等实现效果较好的模型。&lt;/p&gt;
&lt;p&gt;这篇博文首先会简单介绍情感分析的概念、技术和难点。之后针对我们的项目，详细介绍我们使用的算法、迄今为止遇到的问题和一些改进措施。&lt;/p&gt;
    
    </summary>
    
      <category term="开源小项目" scheme="http://kyonhuang.top/categories/%E5%BC%80%E6%BA%90%E5%B0%8F%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="机器学习" scheme="http://kyonhuang.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="自然语言处理" scheme="http://kyonhuang.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="文本分类" scheme="http://kyonhuang.top/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    
      <category term="情感分析" scheme="http://kyonhuang.top/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
      <category term="情感计算" scheme="http://kyonhuang.top/tags/%E6%83%85%E6%84%9F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>面向对象程序设计复习笔记</title>
    <link href="http://kyonhuang.top/OOP-notes/"/>
    <id>http://kyonhuang.top/OOP-notes/</id>
    <published>2018-06-18T00:24:35.000Z</published>
    <updated>2018-06-17T11:46:35.502Z</updated>
    
    <content type="html"><![CDATA[<p>作为一个软件工程的大三学生，如果要求我立刻回答“面向对象程序设计是什么？”、“面向对象的特性是什么？”等问题，我想我是难以做到的。这是因为我们专业的“面向对象程序设计”这一门课程后有一个“(Java)”，在上这门课的时候我们可能更多地关注 Java 语法，而忽略了面向对象程序设计思想的一些精髓。实际上这些精髓映射出的是软件工程发展过程的智慧成果，只是当时我们什么也不懂。而面向对象程序设计的思想及设计模式的韵味则需要更大的代码量才能一探究竟。总之，这篇复习笔记会比较简洁地重温一下这些精髓的概念，真正去理解面向对象的思想，才会发现这些概念的设计精妙之处。</p>
<h3 id="概念重温"><a href="#概念重温" class="headerlink" title="概念重温"></a>概念重温</h3><ul>
<li><strong>对象</strong>：一个自包含的实体，用一组可识别的特性和行为来标识。</li>
<li><strong>类</strong>：具有相同的属性和功能的对象的抽象的集合。</li>
<li><strong>实例化</strong>：创建对象的过程。</li>
<li><strong>方法重载</strong>：提供创建同名的多个方法的能力，但这些方法需使用不同的参数类型。好处是在不改变原方法的基础上，新增功能。</li>
</ul>
<h3 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h3><p>面向对象的程序是由对象组成的，每个对象包含对用户公开的特定功能部分和隐藏的实现部分。在 OOP 中，<strong>不必关心对象的具体实现，只要能够满足用户的需求即可</strong>。</p>
<p>传统的结构化程序设计通过设计一系列的<strong>过程</strong>（即算法）来求解问题，首先确定如何操作数据，然后再决定如何组织数据。而 OOP 则把数据放在第一位，然后再考虑操作数据的算法。</p>
<h3 id="面向对象的好处"><a href="#面向对象的好处" class="headerlink" title="面向对象的好处"></a>面向对象的好处</h3><p><strong>封装、继承、多态</strong>，<strong>面向对象的三大特性</strong>降低了程序的耦合度，从而存在以下优点：</p>
<ul>
<li>可维护</li>
<li>可复用</li>
<li>可扩展</li>
<li>灵活性好</li>
</ul>
<a id="more"></a>
<h3 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h3><p><strong>封装（encapsulation）</strong>指每个对象都包含它能进行操作所需要的所有信息，因此对象不必依赖其他对象来完成自己的操作。</p>
<p>实现封装的关键在于绝对不能让类中的方法直接地访问其他类的实例域，程序仅通过对象的方法与对象数据进行交互。</p>
<p>优点：</p>
<ol>
<li>良好的封装能减少耦合；</li>
<li>类内部的实现可以自由修改；</li>
<li>类具有清晰的对外接口。</li>
</ol>
<h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><p><strong>继承（inheritance）</strong>定义了类如何相互关联，共享特性。继承的工作方式是，定义父类和子类，其中子类不但继承父类所有特性，还可以定义新的特性。</p>
<p>在 Java 中，继承通过关键字<code>extends</code>实现。有些语言（如 C++）允许一个类有多个父类（称为多继承），而 Java 不支持多继承，而是选择用接口提供多继承的好处，并避免多继承的复杂性和低效性。</p>
<p>如果子类继承于父类：</p>
<ol>
<li>子类拥有父类非<code>private</code>的属性和功能；</li>
<li>子类具有自己的属性和功能；</li>
<li>子类还可以以自己的方式实现父类的功能（<strong>方法重写</strong>）。</li>
</ol>
<p>优点：</p>
<ol>
<li>使得所有子类公共部分都放在父类，使得代码得到共享，避免重复；</li>
<li>继承可使得修改或扩展继承而来的实现都较为容易。</li>
</ol>
<p>缺点：</p>
<ol>
<li>继承是一种类与类之间<strong>强耦合</strong>的关系。父类变，子类不得不变；</li>
<li>继承会破坏保障，父类实现细节暴露给子类。</li>
</ol>
<p>如果想要阻止某个类或方法被继承，可以使用<code>final</code>修饰符。</p>
<h3 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h3><p><strong>多态</strong>表示不同的对象可以执行相同的动作，但要通过它们自己的实现代码来执行。</p>
<ol>
<li>子类以父类的身份出现；</li>
<li>子类在工作时以自己的方式来实现；</li>
<li>子类以父类的身份出现时，子类特有的属性和方法不可以使用。</li>
</ol>
<p>多态的原理是当方法被调用时，无论对象是否被转换为其父类，都只有位于对象继承链最末端的方法实现会被调用。</p>
<p>实现多态的技术称为<strong>动态绑定（dynamic binding）</strong>，是指在执行期间判断所引用对象的实际类型，根据其实际的类型调用其相应的方法。</p>
<ul>
<li>静态绑定发生在编译时期，动态绑定发生在运行时；</li>
<li>使用<code>private</code>或<code>static</code>或<code>final</code>修饰的变量或者方法，使用静态绑定。而虚方法（可以被子类重写的方法）则会根据运行时的对象进行动态绑定；</li>
<li>静态绑定使用类信息来完成，而动态绑定则需要使用对象信息来完成；</li>
<li>重载（Overload）的方法使用静态绑定完成，而重写（Override）的方法则使用动态绑定完成。</li>
</ul>
<h3 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h3><p>Java 中，使用<code>abstract</code>可以声明一个<strong>抽象方法</strong>。为了提高程序的清晰度，包含一个或多个抽象方法的类本身必须被声明为<strong>抽象类</strong>。除了抽象方法之外，抽象类还可以包含具体数据和具体方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> String name;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String n)</span> </span>&#123;</div><div class="line">        name = n;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> String <span class="title">getDescription</span><span class="params">()</span></span>;  <span class="comment">// 无需实现</span></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> name;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>抽象方法充当着占位的角色，具体实现在子类中。若子类没有全部实现抽象方法，则子类也必须被声明为抽象类。</p>
<p>抽象类不能被实例化，但是可以定义一个抽象类的<strong>对象变量</strong>并引用非抽象子类的对象：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Person p = <span class="keyword">new</span> Student(<span class="string">"Kyon Huang"</span>, <span class="string">"Software Engineering"</span>);</div></pre></td></tr></table></figure>
<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p><strong>接口（interface）</strong>是对类的一组需求描述，主要用来描述类具有什么功能，而并不给出每个功能的具体实现。一个类可以<strong>实现（implement）</strong>一个或多个接口，并在需要接口的地方，随时使用实现了相应接口的对象。</p>
<p>例如，<code>Arrays</code>类中的<code>sort</code>方法承诺可以对对象数组进行排序，但前提是对象所属的类必须实现了<code>Comparable</code>接口。<code>Comparable</code>接口的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt; </span>&#123;</div><div class="line">    <span class="comment">// 接口中所有方法自动为 public，不必提供关键字</span></div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(T other)</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>为了让类实现一个接口，通常需要下面两个步骤：</p>
<ol>
<li>将类声明为实现给定的接口（使用关键字<code>implements</code>）；</li>
<li>对接口中的所有方法进行定义。</li>
</ol>
<p>在上例中，让<code>Employee</code>类实现<code>Comparable</code>接口，则有：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Employee</span>&gt; </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Employee other)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> Double.compare(salary, other.salary);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>接口不是类，不能使用<code>new</code>运算符实例化一个接口。但是可以声明接口的变量，并引用实现了接口的类对象。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li>《Java 核心技术卷 I》</li>
<li>《大话设计模式》</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作为一个软件工程的大三学生，如果要求我立刻回答“面向对象程序设计是什么？”、“面向对象的特性是什么？”等问题，我想我是难以做到的。这是因为我们专业的“面向对象程序设计”这一门课程后有一个“(Java)”，在上这门课的时候我们可能更多地关注 Java 语法，而忽略了面向对象程序设计思想的一些精髓。实际上这些精髓映射出的是软件工程发展过程的智慧成果，只是当时我们什么也不懂。而面向对象程序设计的思想及设计模式的韵味则需要更大的代码量才能一探究竟。总之，这篇复习笔记会比较简洁地重温一下这些精髓的概念，真正去理解面向对象的思想，才会发现这些概念的设计精妙之处。&lt;/p&gt;
&lt;h3 id=&quot;概念重温&quot;&gt;&lt;a href=&quot;#概念重温&quot; class=&quot;headerlink&quot; title=&quot;概念重温&quot;&gt;&lt;/a&gt;概念重温&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对象&lt;/strong&gt;：一个自包含的实体，用一组可识别的特性和行为来标识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;类&lt;/strong&gt;：具有相同的属性和功能的对象的抽象的集合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实例化&lt;/strong&gt;：创建对象的过程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;方法重载&lt;/strong&gt;：提供创建同名的多个方法的能力，但这些方法需使用不同的参数类型。好处是在不改变原方法的基础上，新增功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;面向对象&quot;&gt;&lt;a href=&quot;#面向对象&quot; class=&quot;headerlink&quot; title=&quot;面向对象&quot;&gt;&lt;/a&gt;面向对象&lt;/h3&gt;&lt;p&gt;面向对象的程序是由对象组成的，每个对象包含对用户公开的特定功能部分和隐藏的实现部分。在 OOP 中，&lt;strong&gt;不必关心对象的具体实现，只要能够满足用户的需求即可&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;传统的结构化程序设计通过设计一系列的&lt;strong&gt;过程&lt;/strong&gt;（即算法）来求解问题，首先确定如何操作数据，然后再决定如何组织数据。而 OOP 则把数据放在第一位，然后再考虑操作数据的算法。&lt;/p&gt;
&lt;h3 id=&quot;面向对象的好处&quot;&gt;&lt;a href=&quot;#面向对象的好处&quot; class=&quot;headerlink&quot; title=&quot;面向对象的好处&quot;&gt;&lt;/a&gt;面向对象的好处&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;封装、继承、多态&lt;/strong&gt;，&lt;strong&gt;面向对象的三大特性&lt;/strong&gt;降低了程序的耦合度，从而存在以下优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可维护&lt;/li&gt;
&lt;li&gt;可复用&lt;/li&gt;
&lt;li&gt;可扩展&lt;/li&gt;
&lt;li&gt;灵活性好&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="学科补完计划" scheme="http://kyonhuang.top/categories/%E5%AD%A6%E7%A7%91%E8%A1%A5%E5%AE%8C%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="面向对象程序设计" scheme="http://kyonhuang.top/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="软件工程" scheme="http://kyonhuang.top/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
      <category term="Java" scheme="http://kyonhuang.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>《基于 Web 的问答系统综述》阅读笔记</title>
    <link href="http://kyonhuang.top/survey-on-web-based-question-answering-notes/"/>
    <id>http://kyonhuang.top/survey-on-web-based-question-answering-notes/</id>
    <published>2018-06-17T09:10:59.000Z</published>
    <updated>2018-06-17T14:16:43.895Z</updated>
    
    <content type="html"><![CDATA[<p>原文链接：<a href="http://www.jsjkx.com/jsjkx/ch/reader/create_pdf.aspx?file_no=20170601&amp;flag=&amp;journal_id=jsjkx&amp;year_id=2017" target="_blank" rel="external">基于 Web 的问答系统综述</a></p>
<p>作者：李舟军，李水华</p>
<p>简介：详细介绍了基于 Web 的问答系统的研究背景、架构及其问题分析、信息检索、答案抽取这三大关键技术的研究进展，并分析了基于 Web 的问答系统所面临的问题。</p>
<p>选读原因：选了一篇中文的基于 Web 的问答系统综述，和手头上工作比较贴近，来对接下来的研究方向有个大致的了解和思考，因此记录也比较详细。</p>
<a id="more"></a>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><strong>问答系统（Question Answering, QA）</strong>以自然语言为输入与输出，理解用户的查询意图后，通过一系列的检索、分析与处理，返回精确、简练的答案。</p>
<p>根据问答系统知识来源的不同，该文将问答系统分为 3 类：</p>
<ol>
<li><strong>基于知识库的问答系统（Qustion Answering over Knowledge Bases, KBQA）</strong>：主要以知识库作为问答系统的知识来源；</li>
<li><strong>基于社区的问答系统（Community-based Question Answering, CQA）</strong>：主要以问答社区（如知乎、百度知道等）作为问答系统的知识来源；</li>
<li><strong>基于 Web 的问答系统（Web-based Question Answering, WQA）</strong>：以开放的互联网上的 Web 文档作为问答系统的知识来源，从搜索引擎上返回的相关网页片段中抽取出用户所提问题的答案。</li>
</ol>
<p>其中，WQA 系统同时具有搜索引擎和问答系统的优点，与时俱进，不断更新。</p>
<h3 id="WQA-系统"><a href="#WQA-系统" class="headerlink" title="WQA 系统"></a>WQA 系统</h3><p><img src="https://raw.githubusercontent.com/bighuang624/pic-repo/master/Architecture-of-question-answering-system.png" alt="Architecture-of-question-answering-system"></p>
<p>经典的 WQA 系统通常由以下 3 个模块构成（其他 QA 系统各模块大体一致，功能有所不同。上图来源[1]）：</p>
<ol>
<li><strong>问题分析模块</strong>：根据用户的查询意图生成相应的查询语句，可能包含对问题的分类、提取问题的关键词或者生成一些其他描述用户查询意图的中间数据；</li>
<li><strong>信息检索模块</strong>：将问题分析模块得到的查询语句或关键词提交给搜索引擎，并整理返回的搜索结果来得到可能包含正确答案的网页片段（性能瓶颈）；</li>
<li><strong>答案抽取模块</strong>：利用信息抽取技术，从网页片段中抽取答案，可能需要用到问题分析模块得到的问题类别、关键词等数据。</li>
</ol>
<h4 id="问题分析模块"><a href="#问题分析模块" class="headerlink" title="问题分析模块"></a>问题分析模块</h4><p>流程：</p>
<ol>
<li>分词</li>
<li>问题分类：问题的类别是反应用户提问意图的重要信息</li>
<li>问题重写：便于搜索引擎理解问题语义</li>
</ol>
<h5 id="问题分类"><a href="#问题分类" class="headerlink" title="问题分类"></a>问题分类</h5><p>问题分类的作用体现在：</p>
<ul>
<li><strong>能够有效减少候选答案空间，提高系统返回答案的准确性</strong>。例如，一个问句被分类为时间类，则在答案抽取阶段，系统把不含时间的候选句子过滤掉；</li>
<li><strong>决定答案喧杂策略，根据不同的问句类型调节对不同问题的答案选择策略</strong>。例如，对于“安徽省的简称是什么”，分析出其询问地点类别，抽取文档库中地点类的文档作为候选答案。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/bighuang624/pic-repo/master/question-classifier.png" alt="问题分类体系"></p>
<p>表一为国际权威的 UIUC 问句分类体系，针对英文分类。表二是哈工大定义的中文问句分类体系。</p>
<p>很多 WQA 系统采用规则分类器对问题进行分类。最简单的规则可以是通过问题是否包含某个词来分类，而比较复杂的规则包括基于语义模式匹配的问题分类[2]。如果没有一条规则能够与问题匹配成功，则借助一些统计机器学习的方法分类，例如 SVM、RNN 等。</p>
<h5 id="关键词提取和扩展"><a href="#关键词提取和扩展" class="headerlink" title="关键词提取和扩展"></a>关键词提取和扩展</h5><p>关键词既可作为搜索引擎的输入，也可辅助答案的抽取过程。WQA 系统通常在分词、取出停用词之后进行关键词的提取，并将名词、动词、形容词等作为关键词。因此可以用一些简单规则提取，例如“所有带形容词的名词都是关键词”等。也可以分析问题的语法结构，抽取主语、宾语作为关键词[3]。</p>
<p>关键词的扩展主要用于解决关键词的同义词的匹配问题，通常需要一些同义词词库进行辅助。</p>
<h5 id="问题重写"><a href="#问题重写" class="headerlink" title="问题重写"></a>问题重写</h5><p>当问题本身（而非关键词）作为搜索引擎的输入时，可能较难领会语义，此时需要对问题进行重写。一些启发式的方法依靠简单的字符串操作（替换、拼接、删除）来实现问题重写，也有较为复杂的优化方法，例如定义一个针对问题的操作集合，然后利用概率模型选择最合适的操作来重写问题[4]。</p>
<h4 id="信息检索模块"><a href="#信息检索模块" class="headerlink" title="信息检索模块"></a>信息检索模块</h4><p>信息检索模块的实现可以调用搜索引擎提供的接口，也可以利用爬虫技术。搜索引擎所具有的高质量摘要技术能过滤原始网页的噪音数据，因此无需抓取解析原始网页。</p>
<h4 id="答案抽取模块"><a href="#答案抽取模块" class="headerlink" title="答案抽取模块"></a>答案抽取模块</h4><p>答案抽取模块是 WQA 系统中的重点和难点，通常包括两个步骤：</p>
<ol>
<li>候选答案抽取：从网页片段中抽取出候选答案；</li>
<li>候选答案排序：对候选答案进行排序，得到最佳答案。</li>
</ol>
<h5 id="候选答案抽取"><a href="#候选答案抽取" class="headerlink" title="候选答案抽取"></a>候选答案抽取</h5><p>抽取候选答案的几种典型方法：</p>
<ol>
<li>手工编辑或自动生成名词词典，将词典中的所有名词都作为候选答案。这种做法的候选答案集非常大，因此候选答案排序以及维护难度很大，难以更新以应对新的领域和新的概念；</li>
<li>利用<strong>命名实体识别（Named Entity Recognition, NER）</strong>工具，抽取命名实体作为候选答案。具体效果受问题分类算法和命名实体识别算法效果的影响；</li>
<li>根据手工编辑或自动生成的文本模式抽取候选答案。准确率较高，但匹配较为死板，无法适应新的数据。</li>
</ol>
<h5 id="候选答案排序"><a href="#候选答案排序" class="headerlink" title="候选答案排序"></a>候选答案排序</h5><p>候选答案排序及最佳答案选择的几种典型方法：</p>
<ol>
<li>采用<strong>向量空间模型（Vector Space Model, VSM）</strong>计算候选答案与问题的相似度，并以此进行排序[5]；</li>
<li>根据语法结构判断候选答案与问题的匹配度，并以此进行排序；</li>
<li>根据词汇特征、相似度特征、统计特征等多种特征进行综合排序。</li>
</ol>
<h3 id="WQA-面临的主要问题"><a href="#WQA-面临的主要问题" class="headerlink" title="WQA 面临的主要问题"></a>WQA 面临的主要问题</h3><ol>
<li>问题分类有待改善：问题分类的本质是短文本分类，受限于特征稀缺，分类器效果有待提升；</li>
<li>同义句子的理解需要解决：同义词的使用和句法结构的变化使得 WQA 系统难以准确抽取答案；</li>
<li>高质量的 QA 对难以获取：缺少相关数据；</li>
<li>利用跨语言语料能力较差：网页片段可能存在多种语言，WQA 系统难以利用多种语言的文本数据来回答某一种特定语言的问题；</li>
<li>通用型不足：回答通用领域问题的能力尚有待进一步增强；</li>
<li>处理复杂问题的能力不足：对于定义型、原因型、关系型、比较型、方法型等问题难以给出满意的回答。</li>
</ol>
<h3 id="WQA-的发展趋势"><a href="#WQA-的发展趋势" class="headerlink" title="WQA 的发展趋势"></a>WQA 的发展趋势</h3><ol>
<li>与其他问答系统的融合；</li>
<li>通过答案摘要生成答案；</li>
<li>自动生成高质量问答对数据；</li>
<li>提升 WQA 系统处理复杂问题的能力；</li>
<li>跨语言能力、跨领域能力的进一步增强；</li>
<li>与语音识别、语音生成等工具的进一步结合；</li>
<li>辅助机器人。</li>
</ol>
<h3 id="文献"><a href="#文献" class="headerlink" title="文献"></a>文献</h3><p>[1] 镇丽华, 王小林, 杨思春. 自动问答系统中问句分类研究综述[J]. 安徽工业大学学报(自科版), 2015, 32(1):48-54.</p>
<p>[2] LI X, HU D, LI H, et al. Automatic question answering from Web documents[J]. Wuhan University Journal of Natural Sciences, 2007, 12(5):875 880.</p>
<p>[3] LIU Z J, WANG X L, CHEN Q C, et al. A Chinese question answering system based on Web search [C]. International Conference on Machine Learning and Cybernetics, Lanzhou: IEEE, 2014:816-820.</p>
<p>[4] CHALI Y, HASAN S A, MOJAHID M. A reinforcement learning formulation to the complex question answering problem<br>[J]. Information Processing &amp; Management, 2015, 51(3):252 272.</p>
<p>[5] 余正涛，樊孝忠，郭剑毅，等. 基于潜在语义分析的汉语问答系统答案提取[J]. 计算机学报，2006，29(10):1889—1893.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文链接：&lt;a href=&quot;http://www.jsjkx.com/jsjkx/ch/reader/create_pdf.aspx?file_no=20170601&amp;amp;flag=&amp;amp;journal_id=jsjkx&amp;amp;year_id=2017&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;基于 Web 的问答系统综述&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作者：李舟军，李水华&lt;/p&gt;
&lt;p&gt;简介：详细介绍了基于 Web 的问答系统的研究背景、架构及其问题分析、信息检索、答案抽取这三大关键技术的研究进展，并分析了基于 Web 的问答系统所面临的问题。&lt;/p&gt;
&lt;p&gt;选读原因：选了一篇中文的基于 Web 的问答系统综述，和手头上工作比较贴近，来对接下来的研究方向有个大致的了解和思考，因此记录也比较详细。&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://kyonhuang.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="综述" scheme="http://kyonhuang.top/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="问答系统" scheme="http://kyonhuang.top/tags/%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="信息检索" scheme="http://kyonhuang.top/tags/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/"/>
    
      <category term="答案抽取" scheme="http://kyonhuang.top/tags/%E7%AD%94%E6%A1%88%E6%8A%BD%E5%8F%96/"/>
    
      <category term="问题分析" scheme="http://kyonhuang.top/tags/%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    
      <category term="自然语言处理" scheme="http://kyonhuang.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>基于设备行为特征的用户身份认证论文综述</title>
    <link href="http://kyonhuang.top/user-authentication-of-behavioral-biometrics-notes/"/>
    <id>http://kyonhuang.top/user-authentication-of-behavioral-biometrics-notes/</id>
    <published>2018-06-06T09:29:13.000Z</published>
    <updated>2018-06-06T09:30:54.699Z</updated>
    
    <content type="html"><![CDATA[<p>这篇论文综述已经成文比较久了，是四月上旬写成的。“基于设备行为特征的用户身份认证”是朱老师给我的一个题目，希望我能在阅读论文后有一些想法，并做实验去实现。</p>
<p>这篇论文综述算是一个阶段性总结，但是我们并没有一个具体的好的 idea，我这学期时间比较紧张，也不太好漫无目的地写程序做实验找实验者得到数据再以此找 idea，因此暂时搁置去做其他的工作。但是也算是我在实验室的工作之一，锻炼了我读论文的能力。希望大四有机会看能不能进一步做出一些成果。</p>
<h2 id="论文总体背景"><a href="#论文总体背景" class="headerlink" title="论文总体背景"></a>论文总体背景</h2><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>身份认证是指用户声明自己的身份并利用相关特征数据来证实该身份，将该用户的相关特征数据与其声明用户的模板进行比较，是一种一对一的匹配方法。安全的身份认证是保证计算机及网络系统安全的基本前提。现有的身份认证技术主要包括三类，分别利用了不同的信息:</p>
<ol>
<li>记忆信息，如密码、PIN 等；</li>
<li>辅助设备、如 ID 卡、令牌等；</li>
<li>生物特征，如指纹，虹膜等。</li>
</ol>
<p>这些传统的识别技术自身均存有缺陷，如密码难于记忆并容易搞混和泄露，ID 卡需要随身携带且易失窃或失效，生物认证需要额外的硬件设备。鉴于此，研究人员仍然在不断寻找新的身份认证手段和方法。[1]</p>
<p><strong>基于设备行为特征的用户身份认证</strong>是研究通过键盘、鼠标等计算机输入设备以及触摸屏、陀螺仪等移动终端设备的使用行为特征来识别计算机操作者身份的可行性及相关方法。该研究基于所有用户在设备上进行操作的行为特征不尽相同的<strong>假设</strong>。因为其有着不需要额外的设备、在当前大多数计算机系统中可以直接部署、认证和监控期间对用户几乎无干扰等优点，因此逐渐成为身份认证研究中的新热点。除开网络安全、机器学习，该问题也被归于<strong>生物行为统计学（Behavioral Biometrics）</strong>。</p>
<a id="more"></a>
<h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><p>在该研究中中，对模型或系统性能的评估指标通常与生物统计学中类似问题相同，定义如下：</p>
<ul>
<li>False Acceptance Rate（错误接受率，FAR）：冒名顶替者被系统接受的百分比；</li>
<li>False Rejection Rate（错误拒绝率，FRR）：真实授权用户被系统拒绝的百分比；</li>
<li>Equal Error Rate（等错误率，EER）：错误接受率和错误拒绝率相等时的错误率，即前两者相交的点。[2]</li>
</ul>
<h2 id="具体论文介绍"><a href="#具体论文介绍" class="headerlink" title="具体论文介绍"></a>具体论文介绍</h2><h3 id="基于鼠标行为特征的用户身份认证与监控-1"><a href="#基于鼠标行为特征的用户身份认证与监控-1" class="headerlink" title="基于鼠标行为特征的用户身份认证与监控[1]"></a>基于鼠标行为特征的用户身份认证与监控[1]</h3><p>本文对 20 个用户 2 个月的鼠标行为数据进行比较分析，结合 SVM（支持向量机）建立模型。</p>
<p>本文的亮点是提出了一种基于顺序前进贪婪搜索和支持向量机的特征组合选择算法，以降低鼠标特征空间的维数，显著提高身份认证和监控的准确度。错误接受率为 1.67%，错误拒绝率为 3.68%。</p>
<h3 id="User-Authentication-using-Combination-of-Behavioral-Biometrics-over-the-Touchpad-acting-like-Touch-screen-of-Mobile-Device-2"><a href="#User-Authentication-using-Combination-of-Behavioral-Biometrics-over-the-Touchpad-acting-like-Touch-screen-of-Mobile-Device-2" class="headerlink" title="User Authentication using Combination of Behavioral Biometrics over the Touchpad acting like Touch screen of Mobile Device[2]"></a>User Authentication using Combination of Behavioral Biometrics over the Touchpad acting like Touch screen of Mobile Device[2]</h3><p>本文的研究成果表明，在触摸屏设备上，用 k-NN 分类方法，手指压力比击键力学更能给出判别信息。此外，仅使用手指压力，准确度高达99%。</p>
<p>本文的优点是详细地介绍了生物统计学，以及数据采集使用的设备和方法。</p>
<h3 id="动态实时身份认证的方法研究-3"><a href="#动态实时身份认证的方法研究-3" class="headerlink" title="动态实时身份认证的方法研究[3]"></a>动态实时身份认证的方法研究[3]</h3><p>本文研究的前提是介入式场景的身份认证需要的时间短（几秒内），但是人的短时行为不稳定，影响准确率；而认证时间长，内部攻击可能已经完成。</p>
<p>本文研究重点在于动态场景和固定场景配合的身份认证。动态场景中，系统等待合适的时机注入异常事件，构建包括鼠标光标的跳变、隐藏和呆滞 3 种异常场景，采集用户在异常发生时的鼠标行为；在连续两次动态身份认证异常后，系统引导用户进入固定场景（本文在此设计了一款记忆性的拼图游戏）以长时间采集行为数据，确定是判断为用户正常、更新模版库还是判断为伪造用户并报警。</p>
<p>本文的亮点是提出了一种全场景身份认证系统，动态用场景和固定场景的配合克服固定场景无法实时身份认证的弊端，而且保证了用户体验和资源节省。错误接受率为 1.8%，错误拒绝率为 3.0%，平均认证时间仅需 8.12s。</p>
<h3 id="行为截获技术对鼠标动力学身份认证的影响-4"><a href="#行为截获技术对鼠标动力学身份认证的影响-4" class="headerlink" title="行为截获技术对鼠标动力学身份认证的影响[4]"></a>行为截获技术对鼠标动力学身份认证的影响[4]</h3><p>本文研究了三种截获用户鼠标行为数据的方法：消息钩子、WM_INPUT 消息处理和过滤驱动，在采样时钟分辨率、时间精度、位置信息等方面分析了不同方法所获取的数据之间的区别，并利用神经网络分类器构建了身份认证模型。</p>
<p>本文的结论是三种行为截获技术中，消息钩子方法截获的数据时间准确性高，轨迹位置表示的误差较小，用于身份认证的效果较好。</p>
<p>本文的亮点是研究重点另辟蹊径，放在了行为截获技术这一特征采集的源头。</p>
<h3 id="A-Practical-Real-Time-Authentication-System-with-Identity-Tracking-Based-on-Mouse-Dynamics-5"><a href="#A-Practical-Real-Time-Authentication-System-with-Identity-Tracking-Based-on-Mouse-Dynamics-5" class="headerlink" title="A Practical Real-Time Authentication System with Identity Tracking Based on Mouse Dynamics[5]"></a>A Practical Real-Time Authentication System with Identity Tracking Based on Mouse Dynamics[5]</h3><p>本文提出了一种基于鼠标动态的实时认证方法，称为PAITS（Practical Authentication with Identity Tracking System）。该方法也是通过注入异常事件，与“动态实时身份认证的方法研究”一文相比，优点在于数据集更大：12 个志愿者，1038 个鼠标会话。</p>
<h3 id="Verification-of-Computer-Users-Using-Keystroke-Dynamics-6"><a href="#Verification-of-Computer-Users-Using-Keystroke-Dynamics-6" class="headerlink" title="Verification of Computer Users Using Keystroke Dynamics[6]"></a>Verification of Computer Users Using Keystroke Dynamics[6]</h3><p>本文的特点在于采用了模糊 ARTMAP、径向基函数网络（RBFN）和学习矢量量化（LVQ）神经网络模型等一些较为少见的神经网络模型，声称在特征选用按键持续时间与按键间隔时间相结合时识别准确率最好能够达到 100%。考虑到本文发表的时间（1997年），如今常用的神经网络理应有更好的分类效果，因此怀疑以上表现的原因是数据集较小。</p>
<h3 id="User-Re-Authentication-via-Mouse-Movements-7"><a href="#User-Re-Authentication-via-Mouse-Movements-7" class="headerlink" title="User Re-Authentication via Mouse Movements[7]"></a>User Re-Authentication via Mouse Movements[7]</h3><p>通过突然的警报来构建动态场景，根据鼠标移动行为来进行用户认证。假阳性率为0.43%，假阴性率为1.75%。可能是因为发表时间较早（2004 年），与其余论文比没有感觉有特别突出的亮点。</p>
<h3 id="The-detection-of-faked-identity-using-unexpected-questions-and-mouse-dynamics-8"><a href="#The-detection-of-faked-identity-using-unexpected-questions-and-mouse-dynamics-8" class="headerlink" title="The detection of faked identity using unexpected questions and mouse dynamics[8]"></a>The detection of faked identity using unexpected questions and mouse dynamics[8]</h3><p>本文的研究前提和其他论文不太相似，不需要保存有声明用户的行为特征数据，而基于记忆检测（RT-based memory detection），通过通过鼠标轨迹有效检测伪造身份。</p>
<p>本文的实验场景中，要求被试者采用假身份并通过已知的信息进行排练，以达到伪装的目的。他们需要在现场的监测人员的监督下，在电脑上回答问题。问题分为了可预测问题（准备好答案的身份相关问题，例如出生年月）、不可预测问题（没有做好反应准备的身份相关问题，例如属相）和控制问题（包含个人信息且必须正确回答，因为这些问题的真实答案对于现场的监测人员是透明的，例如肤色）。对于不可预测问题，会在反应时间、错误数量以及鼠标轨迹上反映出来。</p>
<p>本文选取的特征数量较多（13个），在此之上选取了效果最好的 4 个进行训练，并使用了四种分类器：随机森林、Logistic、支持向量机和 Logistic Model Tree，用 10 折交叉验证来表明结果的可靠性。</p>
<p>本文的缺点在于数据集太少（不到 100 个样本）、数据分布缺少泛化性（被试者只有意大利和德国人）、只用了准确率做评估指标（没有使用 FAR、FRR、EER）。</p>
<h3 id="Keystroke-dynamics-as-a-biometric-for-authentication-9"><a href="#Keystroke-dynamics-as-a-biometric-for-authentication-9" class="headerlink" title="Keystroke dynamics as a biometric for authentication[9]"></a>Keystroke dynamics as a biometric for authentication[9]</h3><p>本文的亮点：</p>
<ol>
<li>提出一些基于击键特征的具体应用场景，例如任何访问服务器的用户都会被提示输入一些与他/她的用户名和密码相关联的短语。如果他/她的键入模式匹配在声明的标识的合理阈值内，则授予访问权限；或者通过检测打字节奏来判断困倦、疲劳等用户非正常状态，用于空中交通控制等；</li>
<li>主张使用结构化文本，而非任意文本（或称自由文本）来获得用户击键数据。</li>
</ol>
<h3 id="HMOG-New-Behavioral-Biometric-Features-for-Continuous-Authentication-of-Smartphone-Users-10"><a href="#HMOG-New-Behavioral-Biometric-Features-for-Continuous-Authentication-of-Smartphone-Users-10" class="headerlink" title="HMOG: New Behavioral Biometric Features for Continuous Authentication of Smartphone Users[10]"></a>HMOG: New Behavioral Biometric Features for Continuous Authentication of Smartphone Users[10]</h3><p>本文引入了一套行为特征，称为 HMOG（hand movement, orientation, and grasp，手的移动、定位和抓取），对移动设备上三种特征（HMOG、击键和轻触）单独和结合时分类结果进行了综合评价。</p>
<p>本文的亮点：</p>
<ol>
<li>讨论了在坐着和行走两种情况下收集到的数据的不同。坐着时 EER 为 10.05%，行走时 EER 为 7.16%，行走时数据使用时效果更好的原因是 HMOG 特征能够捕捉到行走所引起的独特的身体动作；</li>
<li>分析了认证过程对移动设备能耗的影响。</li>
</ol>
<h3 id="Silent-User-Identification-Via-Touch-and-Movement-Behavioral-Biometrics-11"><a href="#Silent-User-Identification-Via-Touch-and-Movement-Behavioral-Biometrics-11" class="headerlink" title="Silent User Identification Via Touch and Movement Behavioral Biometrics[11]"></a>Silent User Identification Via Touch and Movement Behavioral Biometrics[11]</h3><p>本文的研究重点在于提出了 SilentSense：一种通过利用用户触摸行为、生物识别技术和利用集成传感器来捕捉用户的屏幕触控动作所造成的微移动框架。</p>
<p>该框架通过集成了一个基于运动的生物识别技术，解决由触摸引起的移动设备的微移动被大规模的用户移动抑制的问题。所用的技术包括：</p>
<ol>
<li>考虑到用户可以用任何姿态握住手机，将手机坐标系中的原始加速度矢量实时转换为地球坐标系；</li>
<li>利用带通滤波器对线性加速度进行滤波；</li>
<li>从处理后的加速度数据中提取行走特征。步行者的垂直位移与他/她的步长和高度直接相关，因此是一个重要的特征。</li>
</ol>
<p>研究的用户行为包括轻触、滚屏、扔甩、多次触碰，选用特征包括垂直位移、步长、水平加速度的均值和标准差。</p>
<p>另外，本文还提出了一种新的在线决策机制，可以控制打开或关闭传感器，以提供了能耗成本、延迟和准确性之间的平衡。该在线决策机制会根用户的习惯，产生适应性的观察频率。</p>
<h3 id="Implicit-Smartphone-User-Authentication-with-Sensors-and-Contextual-Machine-Learning-12"><a href="#Implicit-Smartphone-User-Authentication-with-Sensors-and-Contextual-Machine-Learning-12" class="headerlink" title="Implicit Smartphone User Authentication with Sensors and Contextual Machine Learning[12]"></a>Implicit Smartphone User Authentication with Sensors and Contextual Machine Learning[12]</h3><p>本文系统地展示了如何在传感器和特征选择、机器学习技术、上下文检测和多设备的不同设计方案中实现高认证精度。提出的 SmarterYou 框架认证精确度为 98.1%，系统开销可忽略不计，电池消耗不足 2.4%。</p>
<p>本文的亮点在于：</p>
<ol>
<li>使用了 KRR（kernel ridge regression）算法；</li>
<li>使用 Fisher scores 来选取特征子集。Fisher scores 是广泛使用的监督特征选择方法之一；</li>
<li>较为详细地介绍了上下文检测：在不同环境下，传感器的测量结果可能不同。因此单独训练上下文检测模型来在做用户认证前的上下文检测。在初步实验后，将提出的四种上下文合并为两种，最终实现上下文检测精度超过 99%，时间小于 3 毫秒。数据获取方法是让用户在受控的实验室条件下使用他们的智能手机，使用过程中保持运动或静止；当为用户执行上下文检测时，使用的上下文检测模型是用其他用户的数据进行训练的。</li>
</ol>
<p>另外，本文包含了一个移动设备上相关工作效果比较的表格，可以参考。</p>
<p><img src="https://user-images.githubusercontent.com/18595460/38462995-1b1cdfce-3b22-11e8-8693-cafda9807f44.png" alt="2018-04-08 10 48 58"></p>
<h2 id="可以深入研究的方向"><a href="#可以深入研究的方向" class="headerlink" title="可以深入研究的方向"></a>可以深入研究的方向</h2><ol>
<li>将对上述研究的学习成果从“用户身份认证”迁移到“爬虫识别”。不过，基于行为特征的验证码实际上已经非常成熟了，例如通过拖动条采集响应时间、拖拽速度、位置、轨迹、重试次数等特征进行识别，以及 <a href="https://www.leiphone.com/news/201412/Hnux7n19OcNWwUFt.html" target="_blank" rel="external">Google 的复选框点击验证码</a>。因此，如果要选择这个方向，需要有更多创新。</li>
<li>将对上述研究的学习成果从“用户身份认证”迁移到“用户体验分析”。根据用户行为特征的异常来判断用户的心情，或者内容对用户的吸引力。</li>
<li>移动设备验证码：现在移动端好像都是短信验证码，或者是最基本的图形验证码。能不能实现在触摸屏上画一个圈就能验证？或者与手机划线解锁相结合？</li>
<li>提出一个具体的应用场景，并调整选取特征、指标、算法等。</li>
</ol>
<h2 id="论文列表"><a href="#论文列表" class="headerlink" title="论文列表"></a>论文列表</h2><p>[1] 沈超, 蔡忠闽, 管晓宏,等. 基于鼠标行为特征的用户身份认证与监控[J]. 通信学报, 2010, 31(7):68-75.</p>
<p>[2] Saevanee, Hataichanok, and P. Bhatarakosol. “User Authentication Using Combination of Behavioral Biometrics over the Touchpad Acting Like Touch Screen of Mobile Device.” International Conference on Computer and Electrical Engineering IEEE Computer Society, 2008:82-86.</p>
<p>[3] 毛传武, 程阳, 余文明. 动态实时身份认证的方法研究[J]. 网络与信息安全学报, 2016, 2(3):76-85.</p>
<p>[4] 王淼, 蔡忠闽, 沈超,等. 行为截获技术对鼠标动力学身份认证的影响[J]. 微电子学与计算机, 2013, 30(4):14-21.</p>
<p>[5] Chen, Xiao Jun, et al. “A practical real-time authentication system with Identity Tracking based on mouse dynamics.” Computer Communications Workshops IEEE, 2014:121-122.</p>
<p>[6] Obaidat, M. S., and B. Sadoun. “Verification of computer users using keystroke dynamics.” IEEE Transactions on Systems Man &amp; Cybernetics Part B Cybernetics A Publication of the IEEE Systems Man &amp; Cybernetics Society 27.2(1997):261-9.</p>
<p>[7] Pusara, Maja, and C. E. Brodley. “User re-authentication via mouse movements.” The Workshop on Visualization &amp; Data Mining for Computer Security ACM, 2004:1-8.</p>
<p>[8] Monaro, M, L. Gamberini, and G. Sartori. “The detection of faked identity using unexpected questions and mouse dynamics.” Plos One 12.5(2017).</p>
<p>[9] Monrose, Fabian, and A. D. Rubin. “Keystroke dynamics as a biometric for authentication.” Future Generation Computer Systems 16.4(2000):351-359.</p>
<p>[10] Sitová, Zdeňka, et al. “HMOG: New Behavioral Biometric Features for Continuous Authentication of Smartphone Users.” IEEE Transactions on Information Forensics &amp; Security 11.5(2016):877-892.</p>
<p>[11] Bo, Cheng, et al. “SilentSense:silent user identification via touch and movement behavioral biometrics.” Computer Science (2013):187-190.</p>
<p>[12] Lee, Wei Han, and R. B. Lee. “Implicit Smartphone User Authentication with Sensors and Contextual Machine Learning.” (2017):297-308.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇论文综述已经成文比较久了，是四月上旬写成的。“基于设备行为特征的用户身份认证”是朱老师给我的一个题目，希望我能在阅读论文后有一些想法，并做实验去实现。&lt;/p&gt;
&lt;p&gt;这篇论文综述算是一个阶段性总结，但是我们并没有一个具体的好的 idea，我这学期时间比较紧张，也不太好漫无目的地写程序做实验找实验者得到数据再以此找 idea，因此暂时搁置去做其他的工作。但是也算是我在实验室的工作之一，锻炼了我读论文的能力。希望大四有机会看能不能进一步做出一些成果。&lt;/p&gt;
&lt;h2 id=&quot;论文总体背景&quot;&gt;&lt;a href=&quot;#论文总体背景&quot; class=&quot;headerlink&quot; title=&quot;论文总体背景&quot;&gt;&lt;/a&gt;论文总体背景&lt;/h2&gt;&lt;h3 id=&quot;研究背景&quot;&gt;&lt;a href=&quot;#研究背景&quot; class=&quot;headerlink&quot; title=&quot;研究背景&quot;&gt;&lt;/a&gt;研究背景&lt;/h3&gt;&lt;p&gt;身份认证是指用户声明自己的身份并利用相关特征数据来证实该身份，将该用户的相关特征数据与其声明用户的模板进行比较，是一种一对一的匹配方法。安全的身份认证是保证计算机及网络系统安全的基本前提。现有的身份认证技术主要包括三类，分别利用了不同的信息:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;记忆信息，如密码、PIN 等；&lt;/li&gt;
&lt;li&gt;辅助设备、如 ID 卡、令牌等；&lt;/li&gt;
&lt;li&gt;生物特征，如指纹，虹膜等。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些传统的识别技术自身均存有缺陷，如密码难于记忆并容易搞混和泄露，ID 卡需要随身携带且易失窃或失效，生物认证需要额外的硬件设备。鉴于此，研究人员仍然在不断寻找新的身份认证手段和方法。[1]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于设备行为特征的用户身份认证&lt;/strong&gt;是研究通过键盘、鼠标等计算机输入设备以及触摸屏、陀螺仪等移动终端设备的使用行为特征来识别计算机操作者身份的可行性及相关方法。该研究基于所有用户在设备上进行操作的行为特征不尽相同的&lt;strong&gt;假设&lt;/strong&gt;。因为其有着不需要额外的设备、在当前大多数计算机系统中可以直接部署、认证和监控期间对用户几乎无干扰等优点，因此逐渐成为身份认证研究中的新热点。除开网络安全、机器学习，该问题也被归于&lt;strong&gt;生物行为统计学（Behavioral Biometrics）&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://kyonhuang.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="身份认证" scheme="http://kyonhuang.top/tags/%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81/"/>
    
      <category term="行为特征" scheme="http://kyonhuang.top/tags/%E8%A1%8C%E4%B8%BA%E7%89%B9%E5%BE%81/"/>
    
      <category term="综述" scheme="http://kyonhuang.top/tags/%E7%BB%BC%E8%BF%B0/"/>
    
      <category term="生物行为统计学" scheme="http://kyonhuang.top/tags/%E7%94%9F%E7%89%A9%E8%A1%8C%E4%B8%BA%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>计算机网络复习笔记</title>
    <link href="http://kyonhuang.top/computer-network-notes/"/>
    <id>http://kyonhuang.top/computer-network-notes/</id>
    <published>2018-05-24T08:35:42.000Z</published>
    <updated>2018-06-27T01:37:28.609Z</updated>
    
    <content type="html"><![CDATA[<h2 id="计算机网络与因特网"><a href="#计算机网络与因特网" class="headerlink" title="计算机网络与因特网"></a>计算机网络与因特网</h2><p>一个<strong>协议</strong>定义了在两个或多个通信实体之间交换报文的格式与次序，以及报文发送/接收或其他事件所采取的动作。</p>
<h3 id="协议层次及其服务模型"><a href="#协议层次及其服务模型" class="headerlink" title="协议层次及其服务模型"></a>协议层次及其服务模型</h3><p><strong>因特网协议栈（Internet protocol stack）</strong>自顶向下：</p>
<ol>
<li><strong>应用层</strong>：网络应用程序及应用层协议存留的地方。<ul>
<li>常见应用层协议：HTTP、DNS、FTP、SMTP、DHCP</li>
<li>位于应用层的分组信息称为<strong>报文（message）</strong></li>
</ul>
</li>
<li><strong>运输层</strong>：负责在<strong>应用程序</strong>端点之间传送应用层报文。<ul>
<li>常见运输层协议：TCP、UDP</li>
<li>位于应用层的分组信息称为<strong>报文段（segment）</strong></li>
</ul>
</li>
<li><strong>网络层</strong>：负责在<strong>主机</strong>间传送网络层的分组。<ul>
<li>常见网络层协议：IP</li>
<li>位于网络层的分组信息称为<strong>数据报（datagram）</strong></li>
</ul>
</li>
<li><strong>链路层</strong>：负责将整个帧从一个网络元素移动到临近的网络元素。<ul>
<li>链路层的例子包括以太网，WiFi</li>
<li>由于分组从源到目的地传送通常要经过几条链路，所以可能被途径不同的链路层协议处理</li>
<li>位于链路层的分组信息称为<strong>帧（frame）</strong> </li>
</ul>
</li>
<li><strong>物理层</strong>：将帧中的每个比特从一个结点移动到下一结点。<ul>
<li>与链路的实际传输媒介相关。</li>
</ul>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/426df589-6f97-4622-b74d-4a81fcb1da8e.png" alt=""></p>
<p>ISO-OSI 模型：</p>
<ol>
<li>应用层</li>
<li>表示层：使通信的应用协议能够解释交换数据的含义，提供数据压缩、数据解密、数据描述等服务；</li>
<li>会话层：提供数据交换的定界和同步功能，包括建立检查点和恢复方案的方法；</li>
<li>运输层</li>
<li>网络层</li>
<li>链路层</li>
<li>物理层</li>
</ol>
<p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/ac106e7e-489a-4082-abd9-dabebe48394c.jpg" alt=""></p>
<a id="more"></a>
<h3 id="网络边缘"><a href="#网络边缘" class="headerlink" title="网络边缘"></a>网络边缘</h3><p>几种因特网的接入方式：</p>
<ul>
<li>家庭接入：DSL（数字用户线，Digital Subscriber）、电缆、FTTH（光纤到户，Fiber To The Home）、拨号和卫星</li>
<li>企业（和家庭）接入：以太网和 WiFi</li>
<li>广域无线接入：3G 和 LTE</li>
</ul>
<h3 id="网络核心"><a href="#网络核心" class="headerlink" title="网络核心"></a>网络核心</h3><p><strong>网络核心</strong>：由连接因特网端系统的<strong>分组交换机和链路</strong>构成的网络。</p>
<p>通过网络链路和交换机<strong>移动数据</strong>的两种基本方法：</p>
<ol>
<li><strong>分组交换（packet switching）</strong></li>
<li><strong>电路交换（circuit switching）</strong></li>
</ol>
<h4 id="分组交换"><a href="#分组交换" class="headerlink" title="分组交换"></a>分组交换</h4><p>将长报文分成较小的数据块（称为分组），在源和目的地之间，每个分组都通过通信链路和<strong>分组交换机（packet switch）</strong>传送。</p>
<p>分组交换机主要有两类：</p>
<ul>
<li><strong>路由器（router）</strong>：常用于网络核心中，网络中大于几千台主机时使用<ul>
<li>使用<strong>网络层</strong>地址转发分组，是第三层的分组交换机；</li>
<li>优点：分组不会通过路由器循环；防火墙保护</li>
<li>缺点：不是即插即用的；对每个分组处理时间更长</li>
</ul>
</li>
<li><strong>链路层交换机（link-layer switch）</strong>：常用于接入网中，网络中小于几百台主机时使用<ul>
<li>使用 <strong>MAC</strong> 地址转发分组，是第二层的分组交换机；</li>
<li>优点：即插即用；相对高的分组过滤和转发速率</li>
<li>缺点：大型交换网络生成可观的 ARP 流量和处理量；对广播风暴不提供任何保护措施</li>
</ul>
</li>
</ul>
<p><strong>存储转发传输（store-and-forward transmission）</strong>：两种分组交换机能够开始向输出链路传输该分组的第一个比特之前，都必须接收到整个分组。因此存在一定的存储转发时延。设分组为 L 比特，链路传输速率为 R 比特/秒，则每条链路的存储转发时延为 L/R 秒。</p>
<h4 id="电路交换"><a href="#电路交换" class="headerlink" title="电路交换"></a>电路交换</h4><p>每台主机都与一台交换机直连，当两台主机通信时，该网络在两台主机之间创建一条专用的<strong>端到端连接（end-to-end connection，又称电路）</strong>。</p>
<p>端系统通信会话期间需要预留资源（缓存，链路传输速率）。端到端连接的实现方式包括频分复用和时分复用。</p>
<h4 id="分组交换与电路交换的对比"><a href="#分组交换与电路交换的对比" class="headerlink" title="分组交换与电路交换的对比"></a>分组交换与电路交换的对比</h4><ul>
<li>电路交换不考虑需求，而预先分配了传输链路的使用，使得已分配而并不需要的链路时间未被使用，对线路的利用率很低；</li>
<li>分组交换按需分配链路使用。</li>
</ul>
<p>趋势朝着分组交换方向发展。</p>
<h3 id="分组交换网中的时延、丢包和吞吐量"><a href="#分组交换网中的时延、丢包和吞吐量" class="headerlink" title="分组交换网中的时延、丢包和吞吐量"></a>分组交换网中的时延、丢包和吞吐量</h3><p><strong>结点总时延 = 处理时延 + 排队时延 + 传输时延 + 传播时延</strong></p>
<ul>
<li><strong>节点处理时延（nodal processing delay）</strong>：检查分组首部和决定该分组导向何处所需时间（可能包括检查比特级差错）；</li>
<li><strong>排队时延（queuing delay）</strong>：分组在队列中等待传输的时间；</li>
<li><strong>传输时延（transmission delay）</strong>：路由器将分组推出所需时间；</li>
<li><strong>传播时延（propagation delay）</strong>：分组从一台路由器向另一台路由器传播所需时间。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/3939369b-3a4a-48a0-b9eb-3efae26dd400.png" alt=""></p>
<ul>
<li><p>丢包（packet lost）：当排队队列满时，由于没有地方进行缓存，路由器将丢弃该分组。丢弃的分组可能重传，也可能不传。</p>
</li>
<li><p>吞吐量（throughput）：</p>
<ul>
<li>瞬时吞吐量（instantaneous throughput）：主机接受文件的速率（bps）</li>
<li>平均吞吐量（average throughput）：主机在某个时间区间接受文件的平均速率（bps）</li>
</ul>
</li>
</ul>
<h2 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h2><h3 id="非重点知识"><a href="#非重点知识" class="headerlink" title="非重点知识"></a>非重点知识</h3><p>因特网为应用程序提供了两个<em>运输层</em>协议：</p>
<ul>
<li>TCP：面向连接、可靠数据传输、有拥塞控制机制；</li>
<li>UDP：不提供不必要服务、无连接、不可靠、没有拥塞控制机制。</li>
</ul>
<p>套接字（Socket）：同一台主机内应用层与运输层之间的接口。也称为应用程序编程接口（API）。</p>
<p>往返时间（Round-Trip Time，RTT）：一个短分组从客户到服务器然后再返回客户所花费的时间。</p>
<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p><strong>HTTP（超文本传输协议，HyperText Transfer Protocol）</strong>：</p>
<ul>
<li>定义了 Web 客户端向 Web 服务器请求 Web 页面的方式；</li>
<li>使用 TCP 作为支撑运输层协议 =&gt; 连接建立后可以通过套接字访问</li>
<li>无状态协议（stateless protocol）：不保存关于客户机的任何信息</li>
</ul>
<p>HTTP 默认使用持久连接，但 HTTP 客户和服务器也能配置成使用非持久连接。</p>
<ul>
<li><strong>非持久连接（non-persisitent connection）</strong>：当客户机/服务器交互运行于 TCP 协议上时，每个请求/响应对是经<strong>一个单独的</strong> TCP 连接发送；</li>
<li><strong>持久连接（persistent connection）</strong>：当客户机/服务器交互运行于 TCP 协议上时，所有请求/响应对是经<strong>相同的</strong> TCP 连接发送。</li>
</ul>
<h4 id="HTTP-1-0-vs-HTTP-1-1"><a href="#HTTP-1-0-vs-HTTP-1-1" class="headerlink" title="HTTP 1.0 vs HTTP 1.1"></a>HTTP 1.0 vs HTTP 1.1</h4><ul>
<li><strong>请求方法的增加</strong>：HTTP 1.0 只有 GET、POST、HEAD 三个请求方法；HTTP 1.1 新增了 PUT、DELETE、OPTIONS、CONNECT、TRACE。</li>
<li><strong>HTTP 1.0 使用非持久连接</strong>，需要为每一个请求的对象建立和维护一个连接，<strong>给 Web 服务器造成较大负担，且有额外时延</strong>；<strong>HTTP 1.1 使用持久连接</strong>，通过请求头中的“Connection: Keep-Alive”实现。</li>
<li>HTTP 1.1 还有一些性能改善措施，例如支持请求流水线，100（Continue）响应码，Host 请求头字段等。</li>
</ul>
<!--##### 报文格式

略-->
<h4 id="HTTP-请求页面过程"><a href="#HTTP-请求页面过程" class="headerlink" title="HTTP 请求页面过程"></a>HTTP 请求页面过程</h4><ol>
<li>有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。</li>
<li>在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。</li>
<li>HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。</li>
<li>连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。</li>
<li>HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。</li>
<li>浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。</li>
</ol>
<h4 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h4><p>cookie 技术的四个组件：</p>
<ol>
<li>在 HTTP 响应报文中的一个 cookie 首部行；</li>
<li>在 HTTP 请求报文中的一个 cookie 首部行；</li>
<li>用户浏览器管理的 cookie 文件；</li>
<li>位于 Web 站点的一个后端数据库。</li>
</ol>
<h4 id="Web-缓存"><a href="#Web-缓存" class="headerlink" title="Web 缓存"></a>Web 缓存</h4><p>Web 缓存器/代理服务器：代表初始 Web 服务器来满足 HTTP 请求的网络实体。</p>
<p>优点：</p>
<ul>
<li>减少对客户请求的响应时间；</li>
<li>减少一个机构的接入链路到因特网的通信量。</li>
</ul>
<p>条件 GET：</p>
<ul>
<li>目的：防止缓存器中的对象副本不是最新；</li>
<li>判别方法：请求报文使用 GET 方法，且包含一个“If-Modified-Since:”首部行。</li>
</ul>
<h3 id="FTP"><a href="#FTP" class="headerlink" title="FTP"></a>FTP</h3><p><strong>FTP（文件传输协议，File Transfer Protocol）</strong>：客户端通过 FTP 向一台远程主机上传文件或从远程主机下载文件。</p>
<p>FTP 和 HTTP 比较：</p>
<ul>
<li>相同点：都是文件传输协议，都运行在 TCP 上；</li>
<li>不同点：<ol>
<li>FTP 是<strong>带外传送的（out-of-band）</strong>，它使用两个并行 TCP 连接来传输文件，一个是<strong>控制连接（control connection）</strong>，一个是<strong>数据连接（data connection）</strong>；HTTP 是<strong>带内的（in-band）</strong>，在同一个连接中发送请求和响应首部行。</li>
<li>FTP 服务器必须在整个会话间保存用户状态信息，而 HTTP 不保存客户机的任何信息。 </li>
</ol>
</li>
</ul>
<h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p><strong>DNS（域名系统，Domain Name System）</strong>：主要任务是负责将用户提供主机名解析为 IP 地址。其他提供的服务有：</p>
<ul>
<li>主机别名（host aliasing）；</li>
<li>邮件服务器别名（mail server aliasing）；</li>
<li>负载分配（load distribution）。</li>
</ul>
<p>DNS 通常由其他应用层协议使用，包括 HTTP、SMTP 和 FTP。DNS 运行在 UDP 上，使用 53 号端口。</p>
<p>DNS <strong>解释域名过程</strong>的简单描述：</p>
<ol>
<li>应用程序调用 DNS 客户端，并指明需要被转换的主机名；</li>
<li>用户主机上的 DNS 向网络中发送一个 DNS 查询报文；</li>
<li>经过若干毫秒到若干秒的时延后，用户主机上的 DNS 接收到一个提供所希望映射的 DNS 报文，并传递到调用 DNS 的应用程序。</li>
</ol>
<p>DNS 既是一个允许主机查询分布式数据库的应用层协议，也是一个由分层的 DNS 服务器实现的分布式数据库。DNS 的层次结构包含根 DNS 服务器，顶级域（TLD）DNS 服务器，权威 DNS 服务器。DNS 不适用于集中式设计的原因包括：</p>
<ol>
<li>单点故障：如果 DNS 服务器崩溃，整个因特网随之瘫痪；</li>
<li>通信容量：整个 DNS 服务器不得不处理所有的 DNS 查询；</li>
<li>远距离的集中式数据库：距离 DNS 服务器远的主机的查询将产生严重的延迟；</li>
<li>维护：集中式的数据库非常庞大，难以维护。</li>
</ol>
<h3 id="SMTP"><a href="#SMTP" class="headerlink" title="SMTP"></a>SMTP</h3><p><strong>SMTP（简单邮件传输协议，Simple Mail Transfer Protocol）</strong>是因特网电子邮件应用的核心，用于从发送方的邮件服务器发送报文到接收方的邮件服务器。</p>
<p>SMTP 和 HTTP 比较：</p>
<ul>
<li>相同点：都用于从一台主机向另一台主机传送文件，都使用持续连接；</li>
<li>不同点：<ol>
<li>SMTP 是一个<strong>推协议（push protocol）</strong>，即发送邮件服务器把文件推向接收邮件服务器；而 HTTP 是一个<strong>拉协议（pull protocol）</strong>。</li>
<li>SMTP 要求每个报文使用 7-bit ASCII 码格式，HTTP 数据则不受这种限制。</li>
<li>处理既有文本又有图像的文档时，SMTP 把所有报文对象放在一个报文之中，而 HTTP 把每个对象封装到独立的响应报文中。</li>
</ol>
</li>
</ul>
<h3 id="DHCP"><a href="#DHCP" class="headerlink" title="DHCP"></a>DHCP</h3><p><strong>DHCP（动态主机配置协议，Dynamic Host Configuration Protocol）</strong>提供了即插即用的连网方式，用户不再需要去手动配置 IP 地址等信息。</p>
<p>DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、默认路由器 IP 地址、域名服务器的 IP 地址。</p>
<p>工作方式如下：需要 IP 地址的主机广播发送 DHCP 发现报文（将目的地址置为全 1，即 255.255.255.255:67，源地址设置为全 0，即 0.0.0.0:68），DHCP 服务器收到发现报文之后，则在 IP 地址池中取一个地址，发送 DHCP 提供报文给该主机。</p>
<h2 id="运输层"><a href="#运输层" class="headerlink" title="运输层"></a>运输层</h2><p>运输层协议：</p>
<ul>
<li>为运行在不同主机上的应用进程之间提供了逻辑通信；</li>
<li>在端系统中实现（而非路由器）；</li>
<li>UDP 和 TCP 最基本的责任是，将两个端系统间 IP 的交付服务扩展为运行在端系统上的两个进程之间的交付服务。TCP 还附加提供可靠数据传输、拥塞控制等服务。</li>
</ul>
<h3 id="多路复用和多路分解"><a href="#多路复用和多路分解" class="headerlink" title="多路复用和多路分解"></a>多路复用和多路分解</h3><p><strong>多路分解（demultiplexing）</strong>：将运输层报文段中的数据交付到正确的套接字的工作。</p>
<p><strong>多路复用（multiplexing）</strong>：从源主机的不同套接字中收集数据块，并为每个数据块封装上首部信息从而生成报文段，然后将报文段传递到网络层的工作。</p>
<p>UDP 套接字：由包含目的 IP 地址和目的端口号的二元组标识。</p>
<p>TCP 套接字：由包含源 IP 地址、源端口号、目的 IP 地址、目的端口号的四元组标识。</p>
<p>对于两个具有相同目的 IP 地址和目的端口号，但具有不同源 IP 地址或源端口号的报文段，UDP 报文段将通过<strong>相同的目的套接字</strong>被定向到<strong>相同的目的进程</strong>；TCP 报文段将被定向到两个<strong>不同的</strong>套接字。</p>
<h3 id="无连接运输：UDP"><a href="#无连接运输：UDP" class="headerlink" title="无连接运输：UDP"></a>无连接运输：UDP</h3><p>特点：</p>
<ul>
<li>尽力而为：报文段可能无序到达或丢失；</li>
<li>无连接：发送报文段前没有握手。</li>
</ul>
<p>选择使用 UDP 构建应用的原因：</p>
<ol>
<li>应用层能更好地控制要发送的数据和发送时间（相对的，TCP 有一个拥塞控制机制）；</li>
<li>无需连接建立（不会引入建立连接的时延）；</li>
<li>无连接状态：不用维护连接状态或跟踪参数，可以支持更多活跃客户；</li>
<li>分组首部开销小：TCP 报文段有 20 字节的首部开销，而 UDP 只有 8 字节。</li>
</ol>
<h4 id="UDP-差错检测——检验和"><a href="#UDP-差错检测——检验和" class="headerlink" title="UDP 差错检测——检验和"></a>UDP 差错检测——检验和</h4><p><strong>UDP 检验和（checksum）</strong>提供<strong>差错检测</strong>功能，以检测报文段运输时的比特改变，但不提供差错恢复。</p>
<p><img src="https://raw.githubusercontent.com/bighuang624/pic-repo/master/checksum.png" alt="checksum.png"></p>
<p>发送方：</p>
<ol>
<li>对报文段中 3 个 16 比特字求和；</li>
<li>求和遇到的溢出被回卷（左边溢出的 1 加到最右边）；</li>
<li>对和进行反码运算，结果放在检验和字段。</li>
</ol>
<p>接收方：全部的 4 个 16 比特字（包括检验和）加在一起，若没有差错，接收方处该和将是 1111 1111 1111 1111。</p>
<h3 id="可靠数据传输"><a href="#可靠数据传输" class="headerlink" title="可靠数据传输"></a>可靠数据传输</h3><p>可靠数据传输的实现在运输层、链路层以及应用层。</p>
<p><strong>可靠数据传输协议（reliable data transfer protocol）</strong>的演变思路：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/5265289-0b392823b3635f5c.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>为了解决发送方利用率极低的问题，停等操作 =&gt; 流水线操作（允许发送方发送多个分组而无需等待确认）。解决<strong>流水线操作的差错恢复</strong>的两种方法：<strong>回退 N 步（Go-Back-N，GBN）</strong>、<strong>选择性重传（Selective Repeat，SR）</strong>。</p>
<h4 id="回退-N-步协议（GBN）"><a href="#回退-N-步协议（GBN）" class="headerlink" title="回退 N 步协议（GBN）"></a>回退 N 步协议（GBN）</h4><p>允许发送方发送多个分组，但流水线中未确认的分组数不能超过某个最大允许数 N。</p>
<p>GBN 协议也被称为滑动窗口协议（sliding-window protocol），N 被称为窗口长度。</p>
<p><strong>GBN 发送方</strong>必须响应三种类型的事件：</p>
<ul>
<li>上层的调用</li>
<li>收到一个 ACK：累计确认，表明正确接收到序号 n 及之前的分组</li>
<li>超时事件：出现超时，发送方重传所有已发送但还未被确认过的分组</li>
</ul>
<p><strong>GBN 接收方</strong>：</p>
<ul>
<li>正确、按序接收到分组 n，则为其发送一个 ACK；否则丢弃该分组，并为最近按序接收的分组重新发送 ACK。</li>
<li>丢弃所有失序分组。</li>
</ul>
<p><strong>优点</strong>：不需要缓存任何失序分组。</p>
<p><strong>缺点</strong>：对该分组的重传也许会丢失或出错，甚至因此需要更多重传。</p>
<h4 id="选择性重传协议（SR）"><a href="#选择性重传协议（SR）" class="headerlink" title="选择性重传协议（SR）"></a>选择性重传协议（SR）</h4><p>通过让发送方仅重传那些它怀疑在接收方出错（即丢失或受损）的分组，来避免不必要的重传。</p>
<p><strong>SR 接收方</strong>：确认一个正确接收的分组而不管是否按序。<strong>失序的分组将被缓存</strong>，直到所有序号更小的分组都被收到为止，这时将一批分组按序交付给上层。</p>
<p>困境：序号范围有限时，接收方可能因窗口太大而无法分辨是一个新分组还是一次重传。 =&gt; 窗口大小须小于等于序号空间大小的一半。</p>
<h3 id="面向连接的运输：TCP"><a href="#面向连接的运输：TCP" class="headerlink" title="面向连接的运输：TCP"></a>面向连接的运输：TCP</h3><h4 id="TCP-连接"><a href="#TCP-连接" class="headerlink" title="TCP 连接"></a>TCP 连接</h4><ul>
<li>全双工服务：TCP 连接是双向的</li>
<li><strong>最大报文段长度（MSS，Maximum Segment Size）</strong>：运输层概念，指 TCP 可从缓存中取出并放入报文段中的数据量，通常根据最初确定的由本地发送主机发送的<strong>最大链路层帧长度（即最大传输单元，MTU）</strong>来设置。</li>
</ul>
<h5 id="报文段结构"><a href="#报文段结构" class="headerlink" title="报文段结构"></a>报文段结构</h5><p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/55dc4e84-573d-4c13-a765-52ed1dd251f9.png" alt=""></p>
<ul>
<li><strong>序号</strong>：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。</li>
<li><strong>确认号</strong>：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。</li>
<li><strong>数据偏移</strong>：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。</li>
<li><strong>确认 ACK</strong>：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。</li>
<li><strong>同步 SYN</strong>：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。</li>
<li><strong>终止 FIN</strong>：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。</li>
<li><strong>窗口</strong>：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。</li>
</ul>
<!--#### 往返时延估计与超时

略-->
<h4 id="可靠数据传输-1"><a href="#可靠数据传输-1" class="headerlink" title="可靠数据传输"></a>可靠数据传输</h4><p>TCP 在 IP 不可靠的尽力而为服务之上创建了一种<strong>可靠数据传输服务</strong>，确保一个进程从其接收缓存中读出的数据流是无损坏、无间隔、非冗余和按序的数据流。</p>
<p>TCP 发送方 3 个与发送和重传有关的主要事件：</p>
<ol>
<li>从上层应用接收数据；</li>
<li>定时器超时；</li>
<li>收到 ACK 报文。</li>
</ol>
<p><strong>快速重传!</strong>：TCP 使用<strong>冗余 ACK</strong>（再次确认某个报文段的 ACK），而非否定确认。一旦收到 3 个冗余 ACK，TCP 就执行快速重传，即在该报文段的定时器过期之前重传丢失的报文段。</p>
<p>TCP 的差错恢复机制是 GBN 协议和 SR 协议的混合体。</p>
<h4 id="流量控制（flow-control）"><a href="#流量控制（flow-control）" class="headerlink" title="流量控制（flow control）"></a>流量控制（flow control）</h4><p>TCP 流量控制的<strong>目的</strong>：消除<strong>接收方</strong>缓存溢出的可能性。</p>
<p>TCP 流量控制的<strong>实现</strong>：发送方维护一个称为<strong>接收窗口（receive window）</strong>的变量，通过发给发送方报文段的接收窗口字段，通知发送方该接收方还有多少可用的缓存空间。</p>
<h4 id="TCP-连接管理"><a href="#TCP-连接管理" class="headerlink" title="TCP 连接管理"></a>TCP 连接管理</h4><h5 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h5><p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/e92d0ebc-7d46-413b-aec1-34a39602f787.png" alt=""></p>
<p>假设 A 为客户端，B 为服务器端。</p>
<ul>
<li>首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。</li>
<li>A 向 B 发送连接请求报文段，SYN=1，ACK=0，选择一个初始的序号 x。</li>
<li>B 收到连接请求报文段，如果同意建立连接，则向 A 发送连接确认报文段，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。</li>
<li>A 收到 B 的连接确认报文段后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。</li>
<li>B 收到 A 的确认后，连接建立。</li>
</ul>
<p>原因：第三次握手是为了防止失效的连接请求到达服务器，导致服务器错误打开连接。</p>
<h5 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h5><p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg" alt=""></p>
<ul>
<li>A 发送连接释放报文段，FIN=1。</li>
<li>B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。</li>
<li>当 B 不再需要连接时，发送连接释放请求报文段，FIN=1。</li>
<li>A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL 时间后释放连接。</li>
<li>B 收到 A 的确认后释放连接。</li>
</ul>
<p>原因：客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。</p>
<h4 id="拥塞控制（congestion-control）"><a href="#拥塞控制（congestion-control）" class="headerlink" title="拥塞控制（congestion control）"></a>拥塞控制（congestion control）</h4><p>TCP 拥塞控制的<strong>目的</strong>：消除<strong>路由器</strong>缓存溢出导致的丢包和重传，以及缓存队列造成的排队时延。</p>
<p>流量控制为了让接收方来得及接收，而拥塞控制是为了降低整个网络的拥塞成都。</p>
<h5 id="拥塞控制方法"><a href="#拥塞控制方法" class="headerlink" title="拥塞控制方法"></a>拥塞控制方法</h5><p>根据<strong>网络层是否为运输层拥塞控制提供了显式帮助</strong>，区分两种拥塞控制方法：</p>
<ul>
<li><strong>端到端拥塞控制</strong>：没有显式支持，通过对网络行为观察来推断是否拥塞（TCP 采用）；</li>
<li><strong>网络辅助的拥塞控制</strong>：网络层构件（路由器）向发送方提供反馈信息。拥塞信息可以通过<strong>专门的阻塞分组</strong>或者<strong>分组中的字段</strong>从网络反馈到发送方。</li>
</ul>
<h5 id="TCP-拥塞控制"><a href="#TCP-拥塞控制" class="headerlink" title="TCP 拥塞控制"></a>TCP 拥塞控制</h5><p>TCP 让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。</p>
<p>问题：</p>
<ol>
<li>如何限制发送流量速率？答：发送方维护变量<strong>拥塞窗口（cwnd）</strong>，LastByteSent - LastByteAcked &lt;= min{cwnd, rwnd}。通过调节 cwnd 的值，发送方能调整它向连接发送数据的速率；</li>
<li>如何感知拥塞？答：超时或收到 3 个冗余 ACK；</li>
<li>感知到拥塞时，采用何种算法去改变发送速率？答：(1) 一个丢包意味着拥塞，因此降低发送方速率；(2) 当对先前未确认报文段的确认到达时，能够增加发送方的速率；(3) <strong>带宽探测</strong>：增加速率以响应到达的 ACK，除非出现丢包，此时才减小传输速率。</li>
</ol>
<p><strong>TCP 拥塞控制算法（TCP congestion control algorithm）</strong>包括三个主要部分：</p>
<ol>
<li><strong>慢启动</strong>（强制）<!--：开始时 cwnd=1 MSS，发送方只能发送一个报文。收到确认后，cwnd 和发送速率就翻番。设置一个阈值 **ssthresh**，cwnd >= ssthresh 时，进入**拥塞避免**。若出现**超时**，则令 ssthresh = cwnd/2，然后重新执行**慢启动**-->；</li>
<li><strong>拥塞避免</strong>（强制）<!--：进入此状态时，cwnd /= 2。每次收到确认只将 cwnd 的值增加 1 MSS-->；</li>
<li><strong>快速恢复</strong>（推荐）<!--：对于引起进入快速恢复状态的缺失报文段，对收到的每个冗余 ACK，cwnd += 1 MSS。最终，当丢失报文段的一个 ACK 到达时，TCP 进入**拥塞避免**。若出现**超时**，则令 ssthresh = cwnd/2，然后执行慢启动。若出现**丢包**-->；</li>
</ol>
<p><img src="https://raw.githubusercontent.com/bighuang624/pic-repo/master/TCP-congestion-control-algorithm.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/910f613f-514f-4534-87dd-9b4699d59d31.png" alt=""></p>
<h2 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h2><p>网络层的作用是将在主机间传送分组，因此需要两种重要的网络层功能：</p>
<ul>
<li><strong>转发（forwarding）</strong>：当一个分组到达路由器的一条输入链路时，路由器必须将该分组移动到适当的输出链路；</li>
<li><strong>路由选择（routing）</strong>：当分组从发送方流向接收方时，网络层必须决定这些分组所采用的路由或路径。</li>
</ul>
<p>因特网的网络层提供<strong>尽力而为服务（best-effort service）</strong>，有三个主要组件：</p>
<ul>
<li>IP 协议</li>
<li>路由选择协议</li>
<li>ICMP 协议（互联网控制报文协议）：用于主机和路由器沟通网络层的信息。最典型的用途是差错报告。</li>
</ul>
<h3 id="虚电路与数据报网络"><a href="#虚电路与数据报网络" class="headerlink" title="虚电路与数据报网络"></a>虚电路与数据报网络</h3><ul>
<li><strong>虚电路（Virtual-Circuit，VC）网络</strong>：仅在网络层提供<strong>连接</strong>服务的计算机网络。由路由器维持连接状态信息。</li>
<li><strong>数据报网络</strong>：仅在网络层提供<strong>无连接</strong>服务的计算机网络。每当一个端系统要发送分组，它就为该分组加上目的端系统的地址，然后将分组推进网络中。</li>
</ul>
<h3 id="路由器"><a href="#路由器" class="headerlink" title="路由器"></a>路由器</h3><ul>
<li>主要作用：将数据报从入链路转发到出链路；</li>
<li>路由器具有截断的协议栈，即没有网络层以上的部分；</li>
<li>每台路由器具有一张<strong>转发表（forwarding table）</strong>，指示分组对应的输出端口；</li>
<li>路由器的四个<strong>组成部分</strong>：输入端口 + 交换结构 + 输出端口 + 路由选择处理器；</li>
<li>每个输入端口存放一份转发表副本的原因：转发决策能在每个输入端口本地做出，无须调用中央路由选择处理器，因此避免了集中式处理的瓶颈。</li>
</ul>
<h3 id="IPv4-vs-IPv6"><a href="#IPv4-vs-IPv6" class="headerlink" title="IPv4 vs IPv6"></a>IPv4 vs IPv6</h3><h4 id="IPv4-数据报格式"><a href="#IPv4-数据报格式" class="headerlink" title="IPv4 数据报格式"></a>IPv4 数据报格式</h4><p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg" alt=""></p>
<ul>
<li><strong>版本</strong>：有 4（IPv4）和 6（IPv6）两个值；</li>
<li><strong>首部长度</strong>：占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为首部固定长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。</li>
<li><strong>区分服务</strong>：用来获得更好的服务，一般情况下不使用。</li>
<li><strong>总长度</strong>：包括首部长度和数据部分长度。</li>
<li><strong>标识</strong>：在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。</li>
<li><strong>标志</strong>：发生分片时，最后一个片此位设为 0，其他所有片此位设为 1。</li>
<li><strong>片偏移</strong>：和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/23ba890e-e11c-45e2-a20c-64d217f83430.png" alt=""></p>
<ul>
<li><strong>生存时间</strong>：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。</li>
<li><strong>协议</strong>：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。</li>
<li><strong>首部检验和</strong>：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。</li>
<li><strong>源和目的 IP 地址</strong>。</li>
<li><strong>选项</strong>：允许 IP 首部被扩展。因为复杂，在 IPv6 首部已去掉。</li>
</ul>
<h4 id="IPv4-编址"><a href="#IPv4-编址" class="headerlink" title="IPv4 编址"></a>IPv4 编址</h4><p><strong>接口（interface）</strong>：主机和物理链路之间的边界。一个 IP 地址技术上是与一个接口相关联的。</p>
<p><strong>子网（subnet）</strong>：分开主机和路由器的每个接口，产生几个隔离的网络岛，这些<strong>子网</strong>使用接口连接。</p>
<p>IP 编址为子网分配一个地址：223.1.1.0/24，其中的 /24 记法称为<strong>子网掩码（network mask）</strong>，指示了 32 比特中的最左侧 24 比特定义了子网地址。</p>
<p><strong>因特网的地址分配策略</strong>是<strong>无类别域间路由选择（Classless Interdomain Routing, CIDR）</strong>，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。</p>
<p><strong>动态主机配置协议（Dynamic Host Configuration Protocol, DHCP）</strong>，又被称为即插即用协议（plug-and-play protocol）。利用 DHCP，主机可以<strong>自动获取 IP 地址</strong>。除了为主机分配地址外，DHCP 还允许一台主机获取其他信息，如它的子网掩码，默认网关，本地 DNS 服务器地址等。DHCP 协议的 4 个步骤：</p>
<ol>
<li>DHCP 服务器发现</li>
<li>DHCP 服务器提供</li>
<li>DHCP 请求</li>
<li>DHCP ACK</li>
</ol>
<!--网络地址转换（Network Address Translation, NAT）

UPnP（通用即插即用）：允许主机发现并配置临近 NAT 协议-->
<!--寻址（大氛围 -> 小范围 -> 节点）*-->
<h4 id="IPv6"><a href="#IPv6" class="headerlink" title="IPv6"></a>IPv6</h4><p>IPv6 引入的变化：</p>
<ul>
<li><strong>扩大的地址容量</strong>：IP 地址长度从 32 比特增加到 128 比特；</li>
<li><strong>简化高效的 40 字节定长首部</strong>；</li>
<li><strong>流标签与优先级</strong>。</li>
</ul>
<p>IPv6 中不包含的 IPv4 字段：</p>
<ul>
<li>分片/重新组装：IPv6 不允许在中间路由器上进行分片与重新组装，只能在源与目的地上执行；</li>
<li>首部检验和：运输层和链路层协议已执行了检验操作；</li>
<li>选项。</li>
</ul>
<p>从 IPv4 到 IPv6 的迁移：</p>
<ul>
<li>双栈（dual-stack）：使用该方法的 IPv6 结点还具有完整的 IPv4 实现；</li>
<li>建隧道（tunneling）：将两台 IPv6 路由器之间的中间 IPv4 路由器集合称为一个隧道。借助于隧道，在隧道发送端的 IPv6 结点可将整个 IPv6 数据报放到一个 IPv4 数据报的有效载荷字段中。</li>
</ul>
<h3 id="路由选择算法"><a href="#路由选择算法" class="headerlink" title="路由选择算法"></a>路由选择算法</h3><ul>
<li>目的：给定一组路由器以及连接路由器的链路，找到一条源路由器到目的路由器的好路径。</li>
<li>分类方式：<ul>
<li>全局式 vs 分散式：全局式要求以所有结点之间的连通性及所有链路费用为输入，而分散式中每个结点仅有与之相连链路的费用知识；</li>
<li>静态 vs 动态：动态算法对网络变化有较大反应；</li>
<li>负载敏感 vs 负载迟钝：负载敏感算法中链路费用动态变化以反映底层链路的当前拥塞水平。当今的因特网路由选择协议（RIP、OSPF 和 BGP）都是负载迟钝的。</li>
</ul>
</li>
</ul>
<h4 id="链路状态路由选择算法（LS）"><a href="#链路状态路由选择算法（LS）" class="headerlink" title="链路状态路由选择算法（LS）"></a>链路状态路由选择算法（LS）</h4><ul>
<li>迭代、全局式</li>
<li>根据 <strong>Dijkstra</strong> 算法实现</li>
<li>最差情况 O(n^2)，用堆可控制在 O(nlogn)</li>
<li>可能的问题：振荡 =&gt; 解决方案：并非所有路由器都同时运行 LS 算法</li>
</ul>
<h4 id="距离向量路由选择算法（DV）"><a href="#距离向量路由选择算法（DV）" class="headerlink" title="距离向量路由选择算法（DV）"></a>距离向量路由选择算法（DV）</h4><ul>
<li>迭代、异步、分布式</li>
<li>根据 <strong>Bellman-Ford</strong> 方程实现</li>
<li>对于结点 x：<ul>
<li>知道 x 到直接相连邻居 v 的费用</li>
<li>保存每个邻居的距离向量 Dv = [Dv(y); y 为每个结点]</li>
<li>保存结点 x 自己的距离向量 Dx = [Dx(y); y 为每个结点]</li>
</ul>
</li>
<li><strong>迭代</strong>：每个结点等待来自任何邻居的更新，当接收到一个更新时计算它的新距离向量，并向它的邻居发布其新距离向量（最终会收敛）</li>
<li>问题：当某链路费用增加时，可能发生<strong>无穷计数</strong>问题 =&gt; <strong>毒性逆转（poisoned reverse）</strong>技术：如果 z 通过 y 路由选择到目的地 x，则 z 将告诉 y Dz(x) 无穷大</li>
</ul>
<h4 id="层次路由选择"><a href="#层次路由选择" class="headerlink" title="层次路由选择"></a>层次路由选择</h4><p>前两种算法将网络只看作一个互联路由器的集合，忽视了规模带来的复杂度和管理自治的需要。由此引入<strong>自治系统（Autonomous System, AS）</strong>：</p>
<ul>
<li>由一组通常处于相同管理控制下的路由器组成</li>
<li>在同一 AS 中的路由器运行同样的路由选择算法，且拥有彼此的信息</li>
<li>为了互联 AS，每个 AS 内有一台或多台<strong>网关路由器（gateway router）</strong>，负责向在本 AS 之外的目的地转发分组</li>
</ul>
<h3 id="路由选择协议"><a href="#路由选择协议" class="headerlink" title="路由选择协议!"></a>路由选择协议!</h3><p>互联网使用的路由选择协议都是<strong>自适应</strong>的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。</p>
<p>可以把路由选择协议划分为两大类：</p>
<ul>
<li><strong>AS 内部</strong>路由选择协议：RIP（路由选择信息协议）、OSPF（开放最短路优先）</li>
<li><strong>AS 间</strong>路由选择协议：BGP（边界网关协议）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/276c31df-3b28-4ac2-b006-1e80fc86a64f.jpg" alt=""></p>
<h4 id="RIP"><a href="#RIP" class="headerlink" title="RIP"></a>RIP</h4><p><strong>RIP（路由选择信息协议）</strong>是一种分布式的基于<strong>距离向量（DV）</strong>的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1，跳数最多为 15，超过 15 表示不可达。</p>
<p>RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本 AS 中任何一个网络的最短距离和下一跳路由器地址。</p>
<p>算法过程：</p>
<ul>
<li>对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1；</li>
<li>对修改后的 RIP 报文中的每一个项目，进行以下步骤：</li>
<li>若原来的<strong>路由选择表</strong>中没有目的网络 N，则把该项目添加到路由选择表中；</li>
<li>否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由选择表中的项目；否则：若收到的项目中的距离 d 小于路由选择表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。</li>
<li>若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。</li>
</ul>
<p>优点：实现简单，开销小</p>
<p>缺点：能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。</p>
<h4 id="OSPF"><a href="#OSPF" class="headerlink" title="OSPF"></a>OSPF</h4><p><strong>OSPF（开放最短路优先）</strong>路由选择协议基于<strong>链路状态（LS）</strong>。路由器向本 AS 内所有路由器广播信息（洪泛法），信息包括与哪些相邻路由器相连以及链路的度量。当链路状态发生变化或者周期到达时，路由器才会发送信息。</p>
<p>优点：</p>
<ul>
<li>更新收敛快</li>
<li>安全</li>
<li>允许使用多条相同费用的路径</li>
<li>对单播与多播路由选择的综合支持</li>
<li>支持在单个路由选择域内的层次结构</li>
</ul>
<h4 id="BGP"><a href="#BGP" class="headerlink" title="BGP"></a>BGP</h4><p>AS 之间的路由选择很困难，主要是因为互联网规模很大。并且各个 AS 内部使用不同的路由选择协议，就无法准确定义路径的度量。并且 AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。</p>
<p><strong>BGP（边界网关协议）</strong>只能寻找一条比较好的路由，而不是最佳路由。它的手段如下：</p>
<ol>
<li>从相邻 AS 处获得子网可达性信息；</li>
<li>向本 AS 内部的所有路由器传播这些可达性信息；</li>
<li>基于可达性信息和 AS 策略，决定到达子网的好路由。</li>
</ol>
<p>每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。</p>
<h2 id="链路层"><a href="#链路层" class="headerlink" title="链路层"></a>链路层</h2><p>两种不同类型的链路层信道：</p>
<ul>
<li><strong>点对点链路（point-to-point link）</strong>：由链路一端的单个发送方和链路另一端的单个接收方组成；</li>
<li><strong>广播链路（broadcast link）</strong>：多个发送和接收结点都连接到相同的、单一的、共享的广播信道上。</li>
</ul>
<p>链路层提供的服务：</p>
<ul>
<li><strong>成帧（framing）</strong>：将数据报封装成链路层帧；</li>
<li><strong>链路接入（link access）</strong>：媒介访问控制（Medium Access Control，MAC）协议用于协调多个结点的帧传输；</li>
<li><strong>可靠交付（reliable delivery）</strong></li>
<li><strong>差错检测和纠正（error detection and correction）</strong></li>
</ul>
<h3 id="差错检测与纠正技术"><a href="#差错检测与纠正技术" class="headerlink" title="差错检测与纠正技术"></a>差错检测与纠正技术</h3><p>3 种技术：</p>
<ul>
<li><p><strong>奇偶校验（Parity Checking）</strong>：用于描述差错检测与纠正的基本思想。单个奇偶校验位原理是附加一个校验 bit，使其和数据 bit 中总有偶数个 1。因为无法处理偶数个 bit 差错的情况，因此可以使用二维奇偶校验，根据行和列来识别实际发生差错的 bit 并纠正。</p>
</li>
<li><p><strong>检验和方法（Checksum）</strong>：常用于运输层。因特网检验和是数据的 3 个 16 bit 字求得的和的反码。接收方对接收的数据（包括检验和）的和取反码，检测其是否全部为 1。</p>
</li>
<li><p><strong>循环冗余检测（Cyclic Redundancy Check，CRC）</strong>：常用于适配器中的链路层。</p>
<ol>
<li>发送方和接收方首先必须协商一个 r+1 比特模式，称为<strong>生成多项式（generator）</strong>G（最高位为 1）；</li>
<li>对于 d 比特数据段 D，发送方附加 r 比特 R；</li>
<li>d+r 比特用模 2 算数恰好能被 G 整除。</li>
</ol>
</li>
</ul>
<p>接收方检测和纠正错误的能力被称为<strong>前向纠错（Forward Error Correction，FEC）</strong>。</p>
<h3 id="多路访问链路和协议"><a href="#多路访问链路和协议" class="headerlink" title="多路访问链路和协议"></a>多路访问链路和协议</h3><p>广播链路的<strong>多路访问问题（multiple access problem）</strong>：如何协调多个发送和接收结点对一个共享广播信道的访问。 =&gt; <strong>多路访问协议</strong></p>
<p><strong>碰撞（collide）</strong>：结点同时接收到多个帧。碰撞帧的信号纠缠在一起，以至于涉及这次碰撞的所有帧都丢失了。</p>
<p>任何多路访问协议能被划分为 3 种类型之一：</p>
<ul>
<li><strong>信道划分协议（channel partitioning protocol）</strong><ul>
<li>时分多路复用（TDM）：优点是消除了碰撞且公平；缺点是限速，且需等待轮次。</li>
<li>频分多路复用（FDM）：优缺点同上。</li>
<li>码分多址（CDMA）：每个结点使用被分配的唯一编码来对它发送的数据进行编码。不同的结点能够同时传输，并且抗干扰。</li>
</ul>
</li>
<li><strong>随机接入协议（random access protocol）</strong>：有碰撞时，涉及碰撞的每个结点反复重发（重发前等待一个随机时延）<ul>
<li>时隙 ALOHA：时间被划分为时隙（传输一帧的时间）。结点只在时隙起点开始传输帧。如果有碰撞，该结点在时隙结束前检测到这次碰撞，并以概率 p 在后续的每个时隙中重传直到无碰撞传输。</li>
<li>纯 ALOHA：非时隙，完全分散</li>
<li>载波侦听多路访问（CSMA）</li>
<li><strong>具有碰撞检测的载波侦听多路访问（CSMA/CD）</strong></li>
</ul>
</li>
<li><strong>轮流协议（taking-turns protocol）</strong><ul>
<li><strong>轮询协议（polling protocol）</strong>：结点之一被指定为主结点，以循环的方式轮询每个结点，告诉其能传输的帧。高效，但引入了轮询时延，且主结点不够健壮。</li>
<li><strong>令牌传递协议（token-passing protocol）</strong>：固定次序传递令牌（一个小的特殊帧），收到令牌的结点仅当有帧要发送时持有令牌，否则转发。没有主结点，缺点是一个结点的故障使整个信道崩溃，并且有结点忘记释放时需要调用恢复步骤。</li>
</ul>
</li>
</ul>
<p><strong>载波侦听（carrier sensing）</strong>：一个结点在传输前先听信道，如果信道上有其他帧则等待。</p>
<p><strong>碰撞检测（collision detection）</strong>：一个传输结点在传输时一直在侦听此信道，如果检测到另一个结点正在传输干扰帧，则停止传输，随机等待一段时间。</p>
<h3 id="交换局域网"><a href="#交换局域网" class="headerlink" title="交换局域网"></a>交换局域网</h3><h4 id="链路层编址"><a href="#链路层编址" class="headerlink" title="链路层编址"></a>链路层编址</h4><p><strong>MAC 地址</strong>是节点（主机或路由器）的适配器具有的链路层地址，长度为 6 字节，具有扁平结构。</p>
<p><strong>地址解析协议（ARP，Address Resolution Protocol）</strong>将 IP 地址转换为 MAC 地址。ARP 可看作跨越链路层和网络层两边的协议，并且是即插即用的，无需系统管理员配置。</p>
<p>发送方用 ARP 解析并在子网之内发送的工作流程：</p>
<ol>
<li>构造 ARP 分组，包括发送、接收 IP 地址和自己的 MAC 地址；</li>
<li>让适配器在链路层帧中封装 ARP 分组，在子网中广播；</li>
<li>每个适配器把帧中的 ARP 分组传递给 ARP 模块进行比对；</li>
<li>匹配的节点给查询主机发送响应 ARP 分组；</li>
<li>查询主机更新 ARP 表。</li>
</ol>
<h4 id="以太网"><a href="#以太网" class="headerlink" title="以太网"></a>以太网</h4><ul>
<li>以太网是目前为止最流行的<strong>有线局域网</strong>。</li>
<li>以太网技术向网络层提供无连接、不可靠服务。</li>
<li>CSMA/CD：以太网的多路访问协议</li>
</ul>
<h4 id="链路层交换机"><a href="#链路层交换机" class="headerlink" title="链路层交换机"></a>链路层交换机</h4><ul>
<li>交换机的任务：接收入链路层帧并将它们转发到出链路</li>
<li>交换机的功能：<ul>
<li><strong>过滤（filtering）</strong>：决定一个帧应该转发到某个接口还是被丢弃</li>
<li><strong>转发（forwarding）</strong>：决定一个帧应该被导向哪个接口</li>
</ul>
</li>
<li>交换机的功能通过<strong>交换机表（switch table）</strong>完成：<ul>
<li>表项包含一个 MAC 地址，通向该 MAC 地址的交换机接口和表项放置在表中的时间（非过期时间）；</li>
<li>如果没有对于目的地址的表项，交换机广播该帧；</li>
<li>交换机表动态、自治建立，这是通过<strong>自学习（self-learning）</strong>实现。</li>
</ul>
</li>
<li><strong>自学习（self-learning）</strong>：对于在每个接口接收到的每个<strong>入帧</strong>，存储：<ol>
<li>该帧<strong>源地址</strong>字段中的 MAC 地址；</li>
<li>该帧到达的接口；</li>
<li>当前时间。</li>
</ol>
</li>
</ul>
<h4 id="VLAN（虚拟局域网）"><a href="#VLAN（虚拟局域网）" class="headerlink" title="VLAN（虚拟局域网）"></a>VLAN（虚拟局域网）</h4><p><strong>VLAN（虚拟局域网，Virtual Local Network）</strong>：端口被网络管理员划分为组，每组构成一个 VLAN</p>
<p><strong>支持 VLAN 的交换机</strong>：</p>
<ul>
<li>允许经一个单一的物理局域网基础设施定义多个虚拟局域网，在一个 VLAN 内的主机彼此通信，仿佛它们与交换机连接；</li>
<li>问题：VLAN 隔离：流量无法在 VLAN 中交换；</li>
<li>解决方案：VLAN 交换机的一个端口与一台外部路由器相连，并将该端口配置为属于两个 VLAN（即视为通过路由器转发跨越）。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>主要参考机械工业出版社《计算机网络自顶向下方法（第 6 版）》。</p>
<p>其他参考资料：</p>
<ul>
<li><a href="https://github.com/CyC2018/Interview-Notebook/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md" target="_blank" rel="external">Interview-Notebook/计算机网络.md at master · CyC2018/Interview-Notebook</a></li>
<li><a href="https://blog.csdn.net/bian_qing_quan11/article/details/72912373" target="_blank" rel="external">HTTP1.0、HTTP1.1与HTTPS - CSDN博客</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;计算机网络与因特网&quot;&gt;&lt;a href=&quot;#计算机网络与因特网&quot; class=&quot;headerlink&quot; title=&quot;计算机网络与因特网&quot;&gt;&lt;/a&gt;计算机网络与因特网&lt;/h2&gt;&lt;p&gt;一个&lt;strong&gt;协议&lt;/strong&gt;定义了在两个或多个通信实体之间交换报文的格式与次序，以及报文发送/接收或其他事件所采取的动作。&lt;/p&gt;
&lt;h3 id=&quot;协议层次及其服务模型&quot;&gt;&lt;a href=&quot;#协议层次及其服务模型&quot; class=&quot;headerlink&quot; title=&quot;协议层次及其服务模型&quot;&gt;&lt;/a&gt;协议层次及其服务模型&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;因特网协议栈（Internet protocol stack）&lt;/strong&gt;自顶向下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;应用层&lt;/strong&gt;：网络应用程序及应用层协议存留的地方。&lt;ul&gt;
&lt;li&gt;常见应用层协议：HTTP、DNS、FTP、SMTP、DHCP&lt;/li&gt;
&lt;li&gt;位于应用层的分组信息称为&lt;strong&gt;报文（message）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;运输层&lt;/strong&gt;：负责在&lt;strong&gt;应用程序&lt;/strong&gt;端点之间传送应用层报文。&lt;ul&gt;
&lt;li&gt;常见运输层协议：TCP、UDP&lt;/li&gt;
&lt;li&gt;位于应用层的分组信息称为&lt;strong&gt;报文段（segment）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;网络层&lt;/strong&gt;：负责在&lt;strong&gt;主机&lt;/strong&gt;间传送网络层的分组。&lt;ul&gt;
&lt;li&gt;常见网络层协议：IP&lt;/li&gt;
&lt;li&gt;位于网络层的分组信息称为&lt;strong&gt;数据报（datagram）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;链路层&lt;/strong&gt;：负责将整个帧从一个网络元素移动到临近的网络元素。&lt;ul&gt;
&lt;li&gt;链路层的例子包括以太网，WiFi&lt;/li&gt;
&lt;li&gt;由于分组从源到目的地传送通常要经过几条链路，所以可能被途径不同的链路层协议处理&lt;/li&gt;
&lt;li&gt;位于链路层的分组信息称为&lt;strong&gt;帧（frame）&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;物理层&lt;/strong&gt;：将帧中的每个比特从一个结点移动到下一结点。&lt;ul&gt;
&lt;li&gt;与链路的实际传输媒介相关。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/426df589-6f97-4622-b74d-4a81fcb1da8e.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;ISO-OSI 模型：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;应用层&lt;/li&gt;
&lt;li&gt;表示层：使通信的应用协议能够解释交换数据的含义，提供数据压缩、数据解密、数据描述等服务；&lt;/li&gt;
&lt;li&gt;会话层：提供数据交换的定界和同步功能，包括建立检查点和恢复方案的方法；&lt;/li&gt;
&lt;li&gt;运输层&lt;/li&gt;
&lt;li&gt;网络层&lt;/li&gt;
&lt;li&gt;链路层&lt;/li&gt;
&lt;li&gt;物理层&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/CyC2018/Interview-Notebook/master/pics/ac106e7e-489a-4082-abd9-dabebe48394c.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="学科补完计划" scheme="http://kyonhuang.top/categories/%E5%AD%A6%E7%A7%91%E8%A1%A5%E5%AE%8C%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="学科复习笔记" scheme="http://kyonhuang.top/tags/%E5%AD%A6%E7%A7%91%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="计算机网络" scheme="http://kyonhuang.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>操作系统复习笔记</title>
    <link href="http://kyonhuang.top/operating-system-notes/"/>
    <id>http://kyonhuang.top/operating-system-notes/</id>
    <published>2018-05-15T08:35:42.000Z</published>
    <updated>2018-06-02T01:35:24.479Z</updated>
    
    <content type="html"><![CDATA[<h2 id="操作系统引论"><a href="#操作系统引论" class="headerlink" title="操作系统引论"></a>操作系统引论</h2><h3 id="操作系统的定义"><a href="#操作系统的定义" class="headerlink" title="操作系统的定义"></a>操作系统的定义</h3><p>定义一：是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。</p>
<p><strong>定义二</strong>：是一组控制和管理计算机硬件和软件资源、合理地对各类作业进行调度以及方便用户使用的程序的集合。</p>
<h3 id="操作系统的作用"><a href="#操作系统的作用" class="headerlink" title="操作系统的作用"></a>操作系统的作用</h3><ol>
<li>作为用户与计算机硬件系统之间的接口；</li>
<li>作为计算机系统资源的管理者；</li>
<li>实现对计算机资源的抽象。</li>
</ol>
<h3 id="操作系统的基本特征"><a href="#操作系统的基本特征" class="headerlink" title="操作系统的基本特征"></a>操作系统的基本特征</h3><h4 id="1-并发"><a href="#1-并发" class="headerlink" title="1. 并发*"></a>1. 并发*</h4><p>两个或多个事件在同一时间<strong>间隔</strong>内发生。</p>
<h4 id="2-共享"><a href="#2-共享" class="headerlink" title="2. 共享"></a>2. 共享</h4><p>系统中的资源可供多个并发执行的进程共同使用。</p>
<p>两种共享方式：</p>
<ul>
<li><strong>互斥共享</strong>：共享的资源称为临界资源，同一时间只允许一个进程访问。需要用同步机制来实现对临界资源的访问；</li>
<li>同时访问：微观上交替进行。</li>
</ul>
<h4 id="3-虚拟"><a href="#3-虚拟" class="headerlink" title="3. 虚拟"></a>3. 虚拟</h4><p>把一个物理实体转换为多个逻辑实体。</p>
<p>主要有两种虚拟技术：时分复用技术（如分时系统）、空分复用技术（如虚拟内存）。</p>
<h4 id="4-异步"><a href="#4-异步" class="headerlink" title="4. 异步"></a>4. 异步</h4><p>多个作业的执行顺序和每个作业的执行时间是不确定的。</p>
<h3 id="操作系统的主要功能"><a href="#操作系统的主要功能" class="headerlink" title="操作系统的主要功能"></a>操作系统的主要功能</h3><ol>
<li><strong>处理器管理</strong>：处理器的运行和分配，以进程为基本单位，因此也被看作进程管理。包括进程控制、进程同步、进程通信、进程调度；</li>
<li><strong>存储器管理</strong>：内存分配、内存保护（不相互干扰）、地址映射（逻辑 -&gt; 物理）、内存扩充（虚拟存储技术）；</li>
<li><strong>设备管理</strong>：包括缓存管理（I/O 设备和 CPU 之间）、设备分配、设备处理；</li>
<li><strong>文件管理</strong>：包括文件存储空间的管理、目录管理、文件读写管理和保护；</li>
<li><strong>提供用户接口</strong>：程序接口（如 API）和用户接口（如 GUI）。</li>
</ol>
<a id="more"></a>
<h3 id="多道批处理系统"><a href="#多道批处理系统" class="headerlink" title="多道批处理系统"></a>多道批处理系统</h3><ul>
<li>每次由作业调度算法，从外存的后备队列中选择若干作业调入内存，共享 CPU 和各种资源。程序 A 因 I/O 操作暂停执行时，调度另一道程序 B 运行。</li>
<li>根本目的：提高 CPU 的利用率，充分发挥系统部件的并行性。</li>
<li>优点：资源利用率高；系统吞吐量大。</li>
<li>缺点：平均周转时间长；无用户交互能力。</li>
</ul>
<h3 id="分时系统"><a href="#分时系统" class="headerlink" title="分时系统"></a>分时系统</h3><p>在一台主机上连接了多个配有显示器和键盘的终端并由此所组成的系统，该系统允许多个用户同时通过自己的终端，以交互方式使用计算机，共享主机中的资源。</p>
<h3 id="实时系统"><a href="#实时系统" class="headerlink" title="实时系统"></a>实时系统</h3><p>指系统能及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。</p>
<h2 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h2><h3 id="顺序执行与并发执行"><a href="#顺序执行与并发执行" class="headerlink" title="顺序执行与并发执行"></a>顺序执行与并发执行</h3><p>程序<strong>顺序</strong>执行时的特征：</p>
<ol>
<li><strong>顺序性</strong>：严格按照程序所规定的次序执行；</li>
<li><strong>封闭性</strong>：程序在封闭环境下运行，系统中所有资源的状态只有本程序才能改变；</li>
<li><strong>可再现性</strong>：只要初始条件相同，无论怎样执行，其结果都相同。</li>
</ol>
<p>程序<strong>并发</strong>执行时的特征：</p>
<ol>
<li><strong>间断性</strong></li>
<li><strong>非封闭性</strong></li>
<li><strong>不可再现性</strong></li>
</ol>
<h3 id="进程与线程-1"><a href="#进程与线程-1" class="headerlink" title="进程与线程"></a>进程与线程</h3><ul>
<li><p><strong>进程</strong>是<strong>资源分配</strong>的基本单位。进程控制块（Process Control Block，PCB）描述进程的基本信息和运行状态。所谓的创建进程和撤销进程，都是指对 PCB 的操作。</p>
</li>
<li><p><strong>线程</strong>是<strong>独立调度</strong>的基本单位。一个进程中可以有多个线程，它们共享进程的资源和内存地址空间。</p>
</li>
</ul>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ul>
<li><p>拥有资源：进程是资源分配的基本单位，但是<strong>线程不拥有资源</strong>，线程可以访问隶属进程的资源。</p>
</li>
<li><p>调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换；从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。</p>
</li>
<li><p>系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。</p>
</li>
<li><p>通信方面：进程间通信（IPC）需要进程同步和互斥手段的辅助，以保证数据的一致性。而线程间可以通过直接读/写同一进程中的数据段（如全局变量）来进行通信。</p>
</li>
</ul>
<h3 id="进程的状态及转换"><a href="#进程的状态及转换" class="headerlink" title="进程的状态及转换"></a>进程的状态及转换</h3><p>进程的三种基本状态：</p>
<ol>
<li><strong>就绪</strong>状态：已分配除 CPU 外的所有必要资源</li>
<li><strong>执行</strong>状态：获得 CPU，程序正在执行</li>
<li><strong>阻塞</strong>状态：发生某事件（I/O 请求、申请缓冲空间等）暂时无法继续执行</li>
</ol>
<p><img src="https://user-images.githubusercontent.com/18595460/40005754-5d106890-57cb-11e8-841d-2c7c9d4b4b4c.png" alt="process-state-i"></p>
<h4 id="引入挂起操作"><a href="#引入挂起操作" class="headerlink" title="引入挂起操作"></a>引入挂起操作</h4><p><strong>挂起</strong>：当该操作用于某个进程时，意味着此时该进程处于静止状态。如果进程正在执行，它将暂停执行。若原本处于就绪状态，则该进程此时暂不接受调度。与挂起操作对应的操作是激活操作。</p>
<p>引入原因：</p>
<ol>
<li>终端用户的需要；</li>
<li>父进程请求；</li>
<li>负荷调节的需要；</li>
<li>操作系统的需要。</li>
</ol>
<p><img src="https://user-images.githubusercontent.com/18595460/40005753-5cc9261a-57cb-11e8-8057-f2f19ccbdfee.png" alt="process-state-ii"></p>
<h3 id="进程同步"><a href="#进程同步" class="headerlink" title="进程同步"></a>进程同步</h3><p><strong>进程同步机制的主要任务</strong>：对多个相关进程在执行次序上进行协调，使并发执行的诸进程之间能有效共享资源和相互合作，从而使程序执行具有可再现性。</p>
<p><strong>两种形式的制约关系</strong>：间接相互制约关系（通过共享系统资源）、直接相互制约关系（源于相互合作）</p>
<p><strong>临界资源</strong>：一段时间内仅允许一个进程使用的资源。</p>
<p><strong>临界区</strong>：进程中访问临界资源的那段代码。</p>
<p><strong>同步机制规则</strong>：空闲让进、忙则等待、有限等待、让权等待。</p>
<p><strong>经典的进程同步问题</strong>：生产者-消费者问题、读者-写者问题、哲学家进餐问题（暂略，详见课本 p60）</p>
<h4 id="信号量机制"><a href="#信号量机制" class="headerlink" title="信号量机制"></a>信号量机制</h4><p>信号量（Semaphore）是一个整型变量，可以对其执行<strong>P、V 原语操作</strong>：</p>
<ul>
<li>P：如果信号量大于 0，执行 -1 操作；如果信号量等于 0，进程阻塞，等待信号量大于 0；</li>
<li>V：对信号量执行 +1 操作，唤醒阻塞的进程让其完成 P 操作。</li>
</ul>
<p>原语操作意指不可分割，通常做法是执行这些操作时屏蔽中断。</p>
<p>如果信号量的取值只能为 0 或 1，那么即是<strong>互斥量（Mutex）</strong>。0 表示临界区已经加锁，1 表示临界区解锁。</p>
<p><strong>发展过程</strong>：整型信号量 -&gt; 记录型信号量 -&gt; AND 型信号量 -&gt; 信号量集</p>
<ul>
<li>整型信号量：P 申请，V 释放；</li>
<li>记录型信号量：增加一个等待队列；</li>
<li>AND 型信号量：AND 同步机制将进程在整个运行过程中需要的所有资源，一次性全部分配给进程，待进程使用完后一起释放（要么全部分配，要么一个都不分配）；</li>
<li>信号量集：对 AND 型信号量集进行扩充，允许一次申请多个资源，而且在分配之前，测试某资源的数量是否大于临界值。</li>
</ul>
<p><strong>信号量的应用</strong>：</p>
<ol>
<li>实现进程互斥；</li>
<li>实现前趋关系。</li>
</ol>
<h3 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信"></a>进程通信</h3><h4 id="进程同步与进程通信的区别"><a href="#进程同步与进程通信的区别" class="headerlink" title="进程同步与进程通信的区别"></a>进程同步与进程通信的区别</h4><ul>
<li>进程同步：控制多个进程按一定顺序执行；</li>
<li>进程通信：进程间信息交换。</li>
</ul>
<p>进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。</p>
<p>信号量也属于进程通信的一种方式，但是属于低级进程通信，因为它传输的信息非常小。</p>
<h4 id="进程通信方式"><a href="#进程通信方式" class="headerlink" title="进程通信方式"></a>进程通信方式</h4><p>高级通信机制可归为以下四大类：</p>
<h5 id="1-共享存储器系统"><a href="#1-共享存储器系统" class="headerlink" title="1. 共享存储器系统"></a>1. 共享存储器系统</h5><p>又可分为以下两种类型：</p>
<ol>
<li>基于共享数据结构的通信方式：仅适用于传递相对少量的数据，通信效率低下，属于低级通信；</li>
<li>基于共享存储区的通信方式：高级通信。</li>
</ol>
<h5 id="2-管道通信系统"><a href="#2-管道通信系统" class="headerlink" title="2. 管道通信系统"></a>2. 管道通信系统</h5><p><strong>管道（pipe）</strong>：用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件。写进程以<strong>字符流</strong>形式将大量数据送入管道，而读进程从管道中接收数据。管道机制必须提供互斥、同步和确定对方是否存在的协调能力。</p>
<h5 id="3-消息传递系统"><a href="#3-消息传递系统" class="headerlink" title="3. 消息传递系统"></a>3. 消息传递系统</h5><p>在该机制中，以格式化的消息为单位，将通信的数据封装到消息中，并利用操作系统提供的一组通信命令（原语），在进程间进行消息传递。</p>
<p>优点：隐藏通信细节，使通信过程对用户透明化，降低了通信程序设计的复杂性和错误率。</p>
<p>该机制是多处理机系统、分布式系统和计算机网络领域最主要的通信工具。根据实现方式不同，可进一步分为直接通信方式（直接将消息发送给目标进程）和间接通信方式（通过共享中间实体[称为邮箱]）。</p>
<h5 id="4-客户机-服务器系统"><a href="#4-客户机-服务器系统" class="headerlink" title="4. 客户机-服务器系统"></a>4. 客户机-服务器系统</h5><p>网络环境的各种应用领域中的主流通信实现机制，主要实现方法分为：</p>
<ol>
<li><strong>套接字（Socket）</strong>：一个通信标识类型的数据结构，是进程通信和网络通信的基本构件；</li>
<li><strong>远程过程调用（RPC）</strong>：一个通信协议，允许运行于本地系统上的进程调用远程系统上的进程，而对程序员表现为常规的过程调用，无需额外为此编程。</li>
</ol>
<h2 id="处理机调度与死锁"><a href="#处理机调度与死锁" class="headerlink" title="处理机调度与死锁"></a>处理机调度与死锁</h2><h3 id="作业调度"><a href="#作业调度" class="headerlink" title="作业调度"></a>作业调度</h3><p>又称<strong>高级调度</strong>。主要功能是根据某种算法，从外存上后备队列中选择多个<strong>作业</strong>调入内存，为其<strong>创建进程</strong>、<strong>分配必要的资源</strong>，并插入<strong>就绪队列</strong>。</p>
<p>主要用于多道批处理系统中，分时系统和实时系统无作业调度。</p>
<p><strong>作业</strong>：用户提交给系统的一项相对独立的工作。操作员把其通过响应的输入设备输入到磁盘存储器，并保存在一个后备作业队列中。<strong>作业控制块</strong>是作业在系统中存在的标志，其中保存了系统对作业进行管理和调度所需的全部信息。</p>
<p>作业调度算法：</p>
<h4 id="1-先来先服务（FCFS）"><a href="#1-先来先服务（FCFS）" class="headerlink" title="1. 先来先服务（FCFS）"></a>1. 先来先服务（FCFS）</h4><p>调度最先进入就绪队列的作业。</p>
<p>有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。</p>
<h4 id="2-短作业优先（SJF）"><a href="#2-短作业优先（SJF）" class="headerlink" title="2. 短作业优先（SJF）"></a>2. 短作业优先（SJF）</h4><p>调度估计运行时间最短的作业。</p>
<p>长作业可能处于一直等待短作业执行完毕的状态（饥饿）。因为如果一直有短作业到来，那么长作业永远得不到调度。</p>
<h4 id="3-优先级调度算法（PSA）"><a href="#3-优先级调度算法（PSA）" class="headerlink" title="3. 优先级调度算法（PSA）"></a>3. 优先级调度算法（PSA）</h4><p>基于作业的紧迫程度，由外部赋予相应的优先级。</p>
<h4 id="4-高响应比优先调度算法（HRRN）"><a href="#4-高响应比优先调度算法（HRRN）" class="headerlink" title="4. 高响应比优先调度算法（HRRN）"></a>4. 高响应比优先调度算法（HRRN）</h4><p>引入动态优先级：优先级随等待时间延长而增加。</p>
<h3 id="进程调度"><a href="#进程调度" class="headerlink" title="进程调度"></a>进程调度</h3><p>又称<strong>低级调度</strong>。主要功能是在保存处理机的现场信息后，根据某种算法，决定<strong>就绪队列</strong>获得处理机的<strong>进程</strong>，使其进入运行状态。</p>
<p>多道批处理系统、分时系统和实时系统都配置进程调度。</p>
<h4 id="进程调度方式"><a href="#进程调度方式" class="headerlink" title="进程调度方式"></a>进程调度方式</h4><h5 id="1-非抢占方式"><a href="#1-非抢占方式" class="headerlink" title="1) 非抢占方式"></a>1) 非抢占方式</h5><p>一旦把处理机分配给某进程，则直至该进程完成或被阻塞时，才把处理机另外分配。</p>
<h5 id="2-抢占方式"><a href="#2-抢占方式" class="headerlink" title="2) 抢占方式"></a>2) 抢占方式</h5><p>允许调度程序根据某种原则，去暂停某个正在执行的进程，并将其处理机重新分配。</p>
<p>抢占必须遵循的原则：</p>
<ol>
<li>优先权原则</li>
<li>短进程优先原则</li>
<li>时间片原则</li>
</ol>
<p>进程调度算法：</p>
<h4 id="1-轮转调度（RR）"><a href="#1-轮转调度（RR）" class="headerlink" title="1. 轮转调度（RR）"></a>1. 轮转调度（RR）</h4><p>将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时分配一个 CPU 时间片给队首进程。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。</p>
<p>轮转调度算法中，效率和时间片大小有很大关系。时间片小意味着频繁执行进程调度和进程上下文的切换，增加系统开销；时间片长则退化为 FCFS 算法，无法满足短作业和交互式用户的需求。</p>
<h4 id="2-优先级调度"><a href="#2-优先级调度" class="headerlink" title="2. 优先级调度"></a>2. 优先级调度</h4><p>把处理机分配给就绪队列中优先级最高的进程。又可以分为非抢占式和抢占式两种。</p>
<h4 id="3-多队列调度"><a href="#3-多队列调度" class="headerlink" title="3. 多队列调度"></a>3. 多队列调度</h4><p>将进程就绪队列拆分为多个，不同的就绪队列采用不同的调度算法，也可以设置不同的优先级。</p>
<h4 id="4-多级反馈队列（multileved-feedback-queue）"><a href="#4-多级反馈队列（multileved-feedback-queue）" class="headerlink" title="4. 多级反馈队列（multileved feedback queue）"></a>4. 多级反馈队列（multileved feedback queue）</h4><p><img src="https://user-images.githubusercontent.com/18595460/40105062-7ef33bb8-5924-11e8-8ae2-8454f82717b2.png" alt="multileved-feedback-queue"></p>
<ol>
<li>设置多个就绪队列。优先级逐个降低，时间片长度依次翻倍（1，2，4，…）；</li>
<li>每个队列采用 FCFS 算法。若在该队列中一个时间片中未完成，则转入下一队列的末尾等待调度。在最后一个队列则按 RR 运行；</li>
<li>按队列优先级调度。仅当优先级更高的所有队列均空时，才会调度下一个队列中的进程运行。</li>
</ol>
<h3 id="实时调度"><a href="#实时调度" class="headerlink" title="实时调度"></a>实时调度</h3><p>又称<strong>中级调度</strong>。主要功能是将暂时不能运行的进程调至外存等待（<strong>此时进程状态为挂起</strong>），当其具备运行条件且内存有空闲时再调入（并将状态修改为就绪）。</p>
<p>引入的主要目的是，提高内存利用率和系统吞吐量。</p>
<h3 id="死锁概述"><a href="#死锁概述" class="headerlink" title="死锁概述"></a>死锁概述</h3><p><strong>定义</strong>：两个或多个进程由于<strong>资源竞争</strong>而造成的僵局。若无外力作用，这些进程将永远无法向前推进。</p>
<p><strong>产生死锁的原因</strong>：</p>
<ol>
<li>竞争不可抢占性资源引起死锁；</li>
<li>竞争可消耗资源引起死锁；</li>
<li>进程推进顺序不当引起死锁：申请和释放资源的顺序不当。</li>
</ol>
<p><strong>产生死锁的必要条件（任一不成立则死锁不发生）</strong>：</p>
<ol>
<li>互斥条件：进程间必须互斥使用某些资源；</li>
<li>请求和保持条件：进程已经占有至少一个资源，但又提出了新的资源请求；</li>
<li>不可抢占条件：进程已获得的资源在未使用完前不得被抢占；</li>
<li>循环等待条件：在发生死锁时，必然存在一个进程-资源的循环链。</li>
</ol>
<p><strong>处理死锁的基本方法</strong>：</p>
<ol>
<li>预防死锁：通过设置某些限制条件，破坏死锁四个必要条件中的一个或多个；</li>
<li>避免死锁：在资源动态分配时，用某种方法防止系统进入不安全状态，从而避免死锁；</li>
<li>检测和解除死锁：允许系统产生死锁，但能及时检测并通过某些措施解除。</li>
</ol>
<p>从上到下对死锁的防范程度依次减弱，但资源利用率和并发程度提高。</p>
<p>顺便一提，大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。</p>
<h3 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h3><p><strong>安全序列</strong>：指系统能够按照某种进程顺序，为每个进程分配其所需资源，直至满足每个进程对资源的<strong>最大需求</strong>，使每个进程都可顺利地完成。如果系统能够找到这样一个安全序列，则称其处于<strong>安全状态</strong>；反之则处于不安全状态。</p>
<p>最有代表性的避免死锁算法是 Dijkstra 的<strong>银行家算法</strong>（暂略，详见课本 p111）。</p>
<h2 id="存储器管理"><a href="#存储器管理" class="headerlink" title="存储器管理"></a>存储器管理</h2><h3 id="程序的装入和链接"><a href="#程序的装入和链接" class="headerlink" title="程序的装入和链接"></a>程序的装入和链接</h3><p>用户程序要在系统中运行需要经过以下几个步骤：</p>
<ol>
<li>编译：由编译程序（Compiler）对用户源程序进行编译，形成若干个目标模块（Object Module）；</li>
<li>链接：由链接程序（Linker）将编译后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个完整的装入模块（Load Module）；</li>
<li>装入：由装入程序（Loader）将装入模块装入内存。</li>
</ol>
<p>其中，程序<strong>装入</strong>方式有以下三种：</p>
<ol>
<li>绝对装入方式：目标模块采用绝对地址。即逻辑地址和实际内存地址完全相同，装入时不需对地址进行变换；</li>
<li>可重定位装入方式（静态重定位）：在装入时，由重定位装入程序一次性完成；</li>
<li>动态运行时装入方式：重定位推迟到程序真正执行时进行。即装入内存后的所有地址都仍是相对地址。这种方式需要硬件支持，程序可以在内存中移动（对换/紧凑），可以实现虚拟存储。</li>
</ol>
<p>其中，<strong>重定位</strong>是将装入模块中指令和数据的相对地址调整成相应内存单元的绝对地址。</p>
<p>程序<strong>链接</strong>方式也有三种：</p>
<ol>
<li>静态链接：在程序运行前将目标模块和所需库函数链接，以后不再拆开；</li>
<li>装入时动态链接；</li>
<li>运行时动态链接：可加快装入过程，节省大量内存空间。</li>
</ol>
<h3 id="连续分配存储管理方式"><a href="#连续分配存储管理方式" class="headerlink" title="连续分配存储管理方式"></a>连续分配存储管理方式</h3><ol>
<li>单一连续分配：内存分为系统区和用户区，用户区仅一道用户程序独占。最简单，适用于单用户、单任务 OS；</li>
<li>固定分区分配：系统初启时将用户区划分为若干分区，大小和分界固定且每个分区只允许装入一道作业。程序道数、程序大小受限，且有较多内部碎片；</li>
<li>动态分区分配：见下；</li>
<li>动态可重定位分区分配：见下。</li>
</ol>
<h4 id="动态分区分配"><a href="#动态分区分配" class="headerlink" title="动态分区分配"></a>动态分区分配</h4><p>分区个数、大小可变。常用空闲分区表或空闲分区链来管理可用内存。</p>
<p><strong>动态分区分配算法</strong>：</p>
<ol>
<li><strong>首次适应（FF）</strong>：将空闲分区按地址递增的次序排列，找第一个满足大小要求的空闲分区。优点是保留了高地址的大空闲区，缺点是低地址产生碎片，增加查找开销；</li>
<li><strong>循环首次适应（NF）</strong>：按地址递增的次序排列，从上次找到的空闲分区的下一个空闲分区开始查找。优点是空闲分区分布更均匀，缺点是缺乏大空闲区；</li>
<li><strong>最佳适应（BF）</strong>：按容量大小递增排序，找满足大小要求的最小空闲分区。缺点是产生大量碎片；</li>
<li><strong>最坏适应（WF）</strong>：按容量大小递减排序，找满足大小要求的最大空闲分区。</li>
</ol>
<h4 id="动态可重定位分区分配"><a href="#动态可重定位分区分配" class="headerlink" title="动态可重定位分区分配"></a>动态可重定位分区分配</h4><p>在动态分区分配方式的基础上增加<strong>紧凑</strong>功能：将内存中的所有作业进行移动，将多个分散的空闲分区拼接成一个大分区。</p>
<h3 id="对换"><a href="#对换" class="headerlink" title="对换"></a>对换</h3><p><strong>对换</strong>指把内存中<strong>暂时不能运行</strong>的进程或暂时不用的<strong>程序和数据</strong>调出到外存上，以便腾出足够的内存空间，再把<strong>已具备运行条件的进程</strong>或<strong>进程所需的程序和数据</strong>调入内存。</p>
<p>优点：改善内存利用率，提高处理机利用率和系统吞吐量。</p>
<p>类型：</p>
<ul>
<li>整体对换：以进程为单位；</li>
<li>页面（分段）对换：以页或段为单位。</li>
</ul>
<h3 id="离散分配方式"><a href="#离散分配方式" class="headerlink" title="离散分配方式"></a>离散分配方式</h3><p>离散分配方式分为以下三种：</p>
<ul>
<li><strong>分页存储管理方式</strong></li>
<li><strong>分段存储管理方式</strong></li>
<li><strong>段页式存储管理方式</strong>：程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页</li>
</ul>
<h3 id="分页和分段的比较"><a href="#分页和分段的比较" class="headerlink" title="分页和分段的比较"></a>分页和分段的比较</h3><ol>
<li>页是信息的<strong>物理</strong>单位，分页是为了实现离散分配，提高内存利用率；段是信息的<strong>逻辑</strong>单位，分段是为了满足用户需求。</li>
<li>页大小固定且由系统决定；段长度不固定，且由用户编写的程序决定。</li>
<li>分页的地址空间是一维线性的；分段的地址空间是二维的。</li>
</ol>
<h2 id="虚拟存储器"><a href="#虚拟存储器" class="headerlink" title="虚拟存储器"></a>虚拟存储器</h2><h3 id="虚拟存储器概述"><a href="#虚拟存储器概述" class="headerlink" title="虚拟存储器概述"></a>虚拟存储器概述</h3><ul>
<li>理论基础：局部性原理</li>
<li>定义：具有<strong>请求调入</strong>功能和<strong>置换</strong>功能，能从<strong>逻辑</strong>上对内存容量加以扩充的一种存储器系统</li>
<li>特性：<ul>
<li>离散性：实现的前提；</li>
<li>多次性：一个作业被分多次调入内存；</li>
<li>对换性：允许在作业运行过程中换入、换出；</li>
<li>虚拟性：能从逻辑上扩充内存容量。</li>
</ul>
</li>
<li>实现：分页请求系统 / 分段请求系统</li>
</ul>
<h3 id="请求分页存储管理方式"><a href="#请求分页存储管理方式" class="headerlink" title="请求分页存储管理方式"></a>请求分页存储管理方式</h3><p>为了支持虚拟存储器功能，在基本分页基础上增加请求调页功能和页面置换功能。</p>
<p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。</p>
<p>请求分段存储管理方式与其在实现原理及所需硬件支持上都十分相似。</p>
<h3 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h3><h4 id="1-最佳（Optimal）"><a href="#1-最佳（Optimal）" class="headerlink" title="1. 最佳（Optimal）"></a>1. 最佳（Optimal）</h4><p>将<strong>最长时间内不再被访问</strong>的页面换出。通常可以保证获得最低的缺页率，然而是一种<strong>理论上的算法</strong>，因为无法知道一个页面多长时间不再被访问。</p>
<h4 id="2-先进先出（FIFO）"><a href="#2-先进先出（FIFO）" class="headerlink" title="2. 先进先出（FIFO）"></a>2. 先进先出（FIFO）</h4><p>将<strong>最先进入的页面</strong>换出。</p>
<p>该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。</p>
<h4 id="3-最近最久未使用（LRU）"><a href="#3-最近最久未使用（LRU）" class="headerlink" title="3. 最近最久未使用（LRU）"></a>3. 最近最久未使用（LRU）</h4><p>将<strong>最近最久未使用</strong>的页面换出。</p>
<p>可以用栈来实现该算法，栈中存储页面的页面号。当进程访问一个页面时，将该页面的页面号从栈移除，并将它压入栈顶。这样，最近被访问的页面总是在栈顶，而最近最久未使用的页面总是在栈底。</p>
<h4 id="4-Clock"><a href="#4-Clock" class="headerlink" title="4. Clock"></a>4. Clock</h4><p><img src="https://user-images.githubusercontent.com/18595460/40115969-be203032-5944-11e8-9f36-cfc7bf5426d2.png" alt="clock"></p>
<p>为每个页面设置一个<strong>访问位</strong>，当该页面被访问或首次调入内存时，将访问位置为 1。</p>
<p>首先，将内存中的所有页面链接成一个循环队列，当缺页中断发生时，检查当前指针所指向页面的访问位，如果访问位为 0，就将该页面换出；否则将该页的访问位设置为 0，给该页面第二次的机会，移动指针继续检查。</p>
<h3 id="“抖动”"><a href="#“抖动”" class="headerlink" title="“抖动”"></a>“抖动”</h3><ul>
<li><strong>根本原因</strong>：同时在系统中运行的进程太多，由此分配给每个进程的物理块太少，不能满足进程正常运行的基本要求；</li>
<li>其他原因：置换算法选择不当；全局置换使抖动传播；</li>
<li><strong>现象</strong>：致使每个进程在运行时，频繁出现缺页；</li>
<li><strong>后果</strong>：排队等待页面调入/调出的进程数目增加，处理机利用率极具下降，有效工作停滞。</li>
<li>预防方法：<ul>
<li>采取局部置换策略：缺页时只在分配给自己的内存空间进行置换，不从其他进程获得新的物理块，以限制抖动的传播；</li>
<li>把工作集算法融入到处理机调度中：工作集指近期进程访问页面集合；</li>
<li>利用“L=S”准则调节缺页率：L 是缺页之间的平均时间，S 是平均缺页服务时间；</li>
<li>挂起某些优先级低的进程。</li>
</ul>
</li>
</ul>
<h2 id="输入输出系统"><a href="#输入输出系统" class="headerlink" title="输入输出系统"></a>输入输出系统</h2><p>管理对象：I/O 设备、相应的设备控制器、通道。</p>
<p>主要任务：完成用户提出的 I/O 请求，提高 I/O 速率，以及提高设备的利用率，并能为更高层的进程方便地使用这些设备提供手段。</p>
<h3 id="I-O-系统的基本功能"><a href="#I-O-系统的基本功能" class="headerlink" title="I/O 系统的基本功能"></a>I/O 系统的基本功能</h3><ol>
<li>隐藏物理设备的细节；</li>
<li>与设备的无关性；</li>
<li>提高处理机和 I/O 设备的利用率；</li>
<li>对 I/O 设备进行控制；</li>
<li>确保对设备的正确共享；</li>
<li>错误处理。</li>
</ol>
<p>其中，对 I/O 设备进行控制有四种方式：</p>
<ol>
<li>采用轮询的可编程 I/O 方式；</li>
<li>采用中断的可编程 I/O 方式；</li>
<li>直接存储器访问方式；</li>
<li>I/O 通道方式。</li>
</ol>
<h3 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h3><p><strong>中断</strong>是指 CPU 对 I/O 设备发来的终端信号的一种响应。CPU 暂停正在执行的程序，保留 CPU 环境后，自动转去执行该 I/O 设备的中断处理程序。执行完后，再回到断点，继续执行原来的程序。</p>
<p>中断是<strong>多道程序</strong>实现的基础，因为进程之间的切换是通过中断来完成的；中断也是<strong>设备管理</strong>的基础，为了提高处理机的利用率和实现 CPU 与 I/O 设备并行执行，必须有中断的支持。</p>
<p>另外，还有<strong>异常</strong>（由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等）和<strong>陷入</strong>（在用户程序中使用系统调用）。</p>
<h3 id="系统调用与库函数"><a href="#系统调用与库函数" class="headerlink" title="系统调用与库函数"></a>系统调用与库函数</h3><p>由 OS 向用户提供的所有内核态的功能，用户进程（应用程序）都必须通过<strong>系统调用</strong>这个中介过程来获取。C 语言首先提供了与系统调用相对应的库函数。</p>
<h3 id="假脱机（SPOOLING）系统"><a href="#假脱机（SPOOLING）系统" class="headerlink" title="假脱机（SPOOLING）系统"></a>假脱机（SPOOLING）系统</h3><p>假脱机技术是对脱机输入/输出系统的模拟，建立在通道技术和多道程序技术的基础上，以高速随机外存（通常为磁盘）为后援存储器。通过假脱机技术，可<strong>将一台物理 I/O 设备虚拟为多台逻辑 I/O 设备</strong>，以允许多个用户共享一台物理 I/O 设备。</p>
<p><strong>原理</strong>：用多道程序中的两道分别模拟输入/输出时的外围控制机功能，在高速磁盘和低速 I/O 设备间传送数据。</p>
<p><strong>组成</strong>：</p>
<ol>
<li>输入井和输出井：在磁盘上开辟的两个存储区域，模拟脱机输入/输出时的磁盘；</li>
<li>输入缓冲区和输出缓冲区：在内存中开辟的两个缓冲区，用于缓和 CPU 和磁盘间速度不匹配的矛盾；</li>
<li>输入进程和输出进程：模拟脱机输入/输出时的外围控制机；</li>
<li>井管理程序：用于控制作业与磁盘井之间信息的交换。</li>
</ol>
<p><strong>特点</strong>：</p>
<ol>
<li>提高了 I/O 的速度；</li>
<li>将独占设备改造为共享设备；</li>
<li>实现了虚拟设备功能。</li>
</ol>
<h3 id="缓冲区"><a href="#缓冲区" class="headerlink" title="缓冲区"></a>缓冲区</h3><p>缓冲引入的原因：</p>
<ol>
<li>缓和 CPU 与 I/O 设备间速度不匹配的矛盾；</li>
<li>减少对 CPU 的中断频率，放宽对 CPU 中断响应时间的限制；</li>
<li>解决数据粒度不匹配的问题；</li>
<li>提高 CPU 和 I/O 设备之间的并行性。</li>
</ol>
<h3 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h3><p>磁盘访问时间包括<strong>寻道时间</strong>（主要）、<strong>旋转延迟时间</strong>和<strong>传输时间</strong>。当多个进程同时请求访问磁盘时，需要进行磁盘调度来控制对磁盘的访问。磁盘调度的目标是使磁盘的平均寻道时间最少。</p>
<h4 id="1-先来先服务（FCFS）-1"><a href="#1-先来先服务（FCFS）-1" class="headerlink" title="1. 先来先服务（FCFS）"></a>1. 先来先服务（FCFS）</h4><p>根据进程请求访问磁盘的先后次序来进行调度。优点是公平和简单，缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。</p>
<h4 id="2-最短寻道时间优先（SSTF）"><a href="#2-最短寻道时间优先（SSTF）" class="headerlink" title="2. 最短寻道时间优先（SSTF）"></a>2. 最短寻道时间优先（SSTF）</h4><p>要求访问的磁道与当前磁头所在磁道距离最近的优先进行调度。这种算法并不能保证平均寻道时间最短，但是比 FCFS 好很多。</p>
<p>会出现饥饿现象。当新进程请求访问的磁道与磁头所在磁道的距离总是比一个在等待的进程来的近，那么等待的进程会一直等待下去。</p>
<h4 id="3-扫描算法"><a href="#3-扫描算法" class="headerlink" title="3. 扫描算法"></a>3. 扫描算法</h4><p>在 SSTF 算法之上考虑了磁头的移动方向，要求所请求访问的磁道在磁头当前移动方向上才能够得到调度。因为考虑了移动方向，那么一个进程请求访问的磁道一定会得到调度。</p>
<p>当一个磁头自里向外移动时，移到最外侧会改变移动方向为自外向里，这种移动的规律类似于电梯的运行，因此又常称 SCAN 算法为电梯调度算法。</p>
<h4 id="4-循环扫描算法"><a href="#4-循环扫描算法" class="headerlink" title="4. 循环扫描算法"></a>4. 循环扫描算法</h4><p>对 SCAN 进行了改动，要求磁头始终沿着一个方向移动。</p>
<h2 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h2><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><p>由创建者所定义的、具有文件名的一组相关元素的集合。从逻辑结构角度分为<strong>有结构文件</strong>（由若干个相关记录组成）和<strong>无结构文件</strong>（被看成一个字符流），在文件系统中是一个最大的数据单位。</p>
<h3 id="文件目录"><a href="#文件目录" class="headerlink" title="文件目录"></a>文件目录</h3><ul>
<li>文件控制块（FCB）：OS 用于<strong>描述</strong>和<strong>控制</strong>文件的一个<strong>数据结构</strong>。</li>
<li>目录：文件控制块的有序集合。</li>
<li>索引节点：<strong>文件描述信息</strong>单独形成的数据结构（而不包含文件名）。由于检索目录文件只用到文件名，即用不到该文件的描述信息，因此检索目录时索引节点不用调入内存，从而大大节省了系统开销。</li>
</ul>
<h3 id="文件共享"><a href="#文件共享" class="headerlink" title="文件共享"></a>文件共享</h3><p>常用的两种文件共享方法：</p>
<ol>
<li>基于有向无环循环图（利用索引节点）；</li>
<li>利用符号链。</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>主要参考西安电子科技大学出版社《计算机操作系统（第四版）》。</p>
<p>其他参考资料：</p>
<ul>
<li><a href="https://github.com/CyC2018/Interview-Notebook/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md" target="_blank" rel="external">Interview-Notebook/notes/计算机操作系统.md</a></li>
<li><a href="https://wenku.baidu.com/view/e181715fc77da26924c5b023.html" target="_blank" rel="external">操作系统重点知识总结_百度文库</a></li>
<li><a href="http://www.baike.com/wiki/%E5%A4%84%E7%90%86%E6%9C%BA" target="_blank" rel="external">处理机_互动百科</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;操作系统引论&quot;&gt;&lt;a href=&quot;#操作系统引论&quot; class=&quot;headerlink&quot; title=&quot;操作系统引论&quot;&gt;&lt;/a&gt;操作系统引论&lt;/h2&gt;&lt;h3 id=&quot;操作系统的定义&quot;&gt;&lt;a href=&quot;#操作系统的定义&quot; class=&quot;headerlink&quot; title=&quot;操作系统的定义&quot;&gt;&lt;/a&gt;操作系统的定义&lt;/h3&gt;&lt;p&gt;定义一：是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义二&lt;/strong&gt;：是一组控制和管理计算机硬件和软件资源、合理地对各类作业进行调度以及方便用户使用的程序的集合。&lt;/p&gt;
&lt;h3 id=&quot;操作系统的作用&quot;&gt;&lt;a href=&quot;#操作系统的作用&quot; class=&quot;headerlink&quot; title=&quot;操作系统的作用&quot;&gt;&lt;/a&gt;操作系统的作用&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;作为用户与计算机硬件系统之间的接口；&lt;/li&gt;
&lt;li&gt;作为计算机系统资源的管理者；&lt;/li&gt;
&lt;li&gt;实现对计算机资源的抽象。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;操作系统的基本特征&quot;&gt;&lt;a href=&quot;#操作系统的基本特征&quot; class=&quot;headerlink&quot; title=&quot;操作系统的基本特征&quot;&gt;&lt;/a&gt;操作系统的基本特征&lt;/h3&gt;&lt;h4 id=&quot;1-并发&quot;&gt;&lt;a href=&quot;#1-并发&quot; class=&quot;headerlink&quot; title=&quot;1. 并发*&quot;&gt;&lt;/a&gt;1. 并发*&lt;/h4&gt;&lt;p&gt;两个或多个事件在同一时间&lt;strong&gt;间隔&lt;/strong&gt;内发生。&lt;/p&gt;
&lt;h4 id=&quot;2-共享&quot;&gt;&lt;a href=&quot;#2-共享&quot; class=&quot;headerlink&quot; title=&quot;2. 共享&quot;&gt;&lt;/a&gt;2. 共享&lt;/h4&gt;&lt;p&gt;系统中的资源可供多个并发执行的进程共同使用。&lt;/p&gt;
&lt;p&gt;两种共享方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;互斥共享&lt;/strong&gt;：共享的资源称为临界资源，同一时间只允许一个进程访问。需要用同步机制来实现对临界资源的访问；&lt;/li&gt;
&lt;li&gt;同时访问：微观上交替进行。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;3-虚拟&quot;&gt;&lt;a href=&quot;#3-虚拟&quot; class=&quot;headerlink&quot; title=&quot;3. 虚拟&quot;&gt;&lt;/a&gt;3. 虚拟&lt;/h4&gt;&lt;p&gt;把一个物理实体转换为多个逻辑实体。&lt;/p&gt;
&lt;p&gt;主要有两种虚拟技术：时分复用技术（如分时系统）、空分复用技术（如虚拟内存）。&lt;/p&gt;
&lt;h4 id=&quot;4-异步&quot;&gt;&lt;a href=&quot;#4-异步&quot; class=&quot;headerlink&quot; title=&quot;4. 异步&quot;&gt;&lt;/a&gt;4. 异步&lt;/h4&gt;&lt;p&gt;多个作业的执行顺序和每个作业的执行时间是不确定的。&lt;/p&gt;
&lt;h3 id=&quot;操作系统的主要功能&quot;&gt;&lt;a href=&quot;#操作系统的主要功能&quot; class=&quot;headerlink&quot; title=&quot;操作系统的主要功能&quot;&gt;&lt;/a&gt;操作系统的主要功能&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;处理器管理&lt;/strong&gt;：处理器的运行和分配，以进程为基本单位，因此也被看作进程管理。包括进程控制、进程同步、进程通信、进程调度；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;存储器管理&lt;/strong&gt;：内存分配、内存保护（不相互干扰）、地址映射（逻辑 -&amp;gt; 物理）、内存扩充（虚拟存储技术）；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;设备管理&lt;/strong&gt;：包括缓存管理（I/O 设备和 CPU 之间）、设备分配、设备处理；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文件管理&lt;/strong&gt;：包括文件存储空间的管理、目录管理、文件读写管理和保护；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供用户接口&lt;/strong&gt;：程序接口（如 API）和用户接口（如 GUI）。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="学科补完计划" scheme="http://kyonhuang.top/categories/%E5%AD%A6%E7%A7%91%E8%A1%A5%E5%AE%8C%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="学科复习笔记" scheme="http://kyonhuang.top/tags/%E5%AD%A6%E7%A7%91%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="操作系统" scheme="http://kyonhuang.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>《Recurrent Neural Network for Text Classification with Multi-Task Learning》阅读笔记</title>
    <link href="http://kyonhuang.top/1605-05101-notes/"/>
    <id>http://kyonhuang.top/1605-05101-notes/</id>
    <published>2018-05-10T14:02:13.000Z</published>
    <updated>2018-06-07T11:32:14.237Z</updated>
    
    <content type="html"><![CDATA[<p>原文链接：<a href="http://www.ijcai.org/Proceedings/16/Papers/408.pdf" target="_blank" rel="external">Recurrent Neural Network for Text Classification with Multi-Task Learning</a></p>
<p>作者：Pengfei Liu, Xipeng Qiu, Xuanjing Huang</p>
<p>单位：复旦大学 自然语言处理与深度学习组</p>
<p>文章来源：IJCAI 2016</p>
<p>简介：本文针对文本多分类任务，提出了基于 RNN 的三种不同的共享信息机制，在四个基准的文本分类任务中取得了较好的结果。</p>
<h2 id="研究概况"><a href="#研究概况" class="headerlink" title="研究概况"></a>研究概况</h2><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>假设多个任务之间具有相关性，<strong><a href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e5%a4%9a%e4%bb%bb%e5%8a%a1%e5%ad%a6%e4%b9%a0">多任务学习</a></strong>利用任务之间的相关性相互促进，通过并行学习任务来提高分类效果。这些模型的基本的多任务架构将共享一些较低的层以确定共同的特性。在共享层之后，每个特定任务单独使用一个输出层。</p>
<p><img src="https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Structuring_Machine_Learning_Projects/Shared-Representation.png" alt="Shared-Representation"></p>
<h3 id="前人工作和不足"><a href="#前人工作和不足" class="headerlink" title="前人工作和不足"></a>前人工作和不足</h3><p>基于神经网络的多任务学习已被用于解决 NLP 的各类任务。例如：</p>
<ul>
<li>使用一个对于输入单词的共享表示：用途是解决词性标注、语义角色标注等传统 NLP 任务。缺点是只有一张查找表是共享的、其他查找表和层是任务特定的，并且需要用基于窗口的方法处理长度不定的文本序列；</li>
<li>多任务 DNN 来学习表示：用途是解决查询分类和网络搜索排名任务。缺点是模型输入为词袋表示，损失了词序信息。</li>
</ul>
<p>不同于以上两种方法，本文的模型基于 RNN，对于建模变长文本序列更友好。</p>
<h3 id="本文工作"><a href="#本文工作" class="headerlink" title="本文工作"></a>本文工作</h3><p>基于 RNN，提出了三种不同的共享信息机制，可以将信息共享到特定任务层的共享层。整个网络都是在所有这些任务上共同训练的。模型在四个基准的文本分类任务上展示了很好的效果，超过了大多数的 state-of-the-art。</p>
<!--### 意义和创新点-->
<a id="more"></a>
<h2 id="具体细节"><a href="#具体细节" class="headerlink" title="具体细节"></a>具体细节</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/1605-05101/three-architectures.png" alt=""></p>
<ul>
<li>模型一（Uniform-layer Architecture）：对于每个分类任务，在每个输入 character 的 embedding vector 后拼上一个随机生成的可训练向量，表示该特定任务，所有任务共享 LSTM 层，最后一个 时刻的 hidden state 则作为输入传入 softmax；</li>
<li>模型二（Coupled-layer Architecture）：每个任务具有自己独立的 LSTM 层，但是每一时刻所有任务的 hidden state 则会和下一时刻的 character 一起作为输入，最后一个时刻的 hidden state 进行分类；</li>
<li>模型三（Shared-layer Architecture）：除了一个共享的 Bi-LSTM 层用于获取共享信息，每个任务有自己独立的 LSTM 层，LSTM 的输入包括每一时刻的 character 和 Bi-LSTM 的 hidden state。</li>
</ul>
<!--大概可以加公式？-->
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>对于模型一和模型三，具有一个共享层。在联合学习阶段之后可以进行<strong>微调（Fine Tuning）</strong>来进一步优化每个任务的性能。</p>
<p>对于模型三，共享层可以由无监督的预训练阶段初始化，用四个任务数据集进行语言模型的训练。</p>
<p>训练方法：</p>
<ol>
<li>随机选择一项任务；</li>
<li>从该任务中随机选择一个训练样本；</li>
<li>根据基于梯度的优化（paper 中使用 Adagrad update rule）来更新参数；</li>
<li>重复 1-3 步。</li>
</ol>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/1605-05101/datasets.png" alt=""></p>
<ul>
<li>SST-1：5 个情绪类别的电影影评，来自斯坦福情感数据库</li>
<li>SST-2：二分类电影影评，来自斯坦福数据库</li>
<li>SUBJ：主观性数据集，任务目的是将句子分为主观和客观</li>
<li>IMDB：二分类的电影影评，大多数评价为长句子</li>
</ul>
<h3 id="超参数与训练"><a href="#超参数与训练" class="headerlink" title="超参数与训练"></a>超参数与训练</h3><p>使用 word2vec 在维基语料获得词向量，字典规模约 500,000。词嵌入在训练过程中被微调以提高性能；其他参数在 [-0.1, 0.1] 的范围随机采样，超参数将选择在验证集上性能最好的一组。对于没有验证集的数据集使用 10 折交叉验证。</p>
<p>特定任务和共享层的嵌入大小为 64。对于模型一，每个单词有两个嵌入，大小都为 64。LSTM 的隐藏层大小为 50。初始学习率为 0.1。参数的正则化权值为 10^-5。</p>
<h3 id="结果比较"><a href="#结果比较" class="headerlink" title="结果比较"></a>结果比较</h3><p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/1605-05101/results-of-model-i.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/1605-05101/results-of-model-ii.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/1605-05101/results-of-model-iii.png" alt=""></p>
<h3 id="与-state-of-the-art-相比较"><a href="#与-state-of-the-art-相比较" class="headerlink" title="与 state-of-the-art 相比较"></a>与 state-of-the-art 相比较</h3><p>将模型三和下列模型进行比较：</p>
<!--* NBOW：对词向量求和，并应用一个非线性项，之后一个 softmax 分类层；
* MV-RNN：
* RNTN：
* DCNN：
* PV：
* Tree-LSTM：-->
<p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/1605-05101/compare-to-state-of-the-art.png" alt=""></p>
<p>paper 中的多任务模型和其他基于 RNN 的模型（例如 Tree-LSTM）是兼容的，可以合并以扩展。</p>
<h3 id="了解模型"><a href="#了解模型" class="headerlink" title="了解模型"></a>了解模型</h3><p>从 SST-2 的测试集中采样，看在单个 LSTM 和含共享层的 LSTM 中，句子中每个单词对预测的情绪分数的影响。具体方式是观察全局门（global gates）的激活值，这个值控制一个 LSTM 分享层到一个特定任务层的信号流，使我们能够了解神经元的行为。</p>
<p>例如，“marry”一词使得激活值升高，说明特定任务层从共享层得到很多信息，从而使预测更准确。</p>
<p>通过分析，单个 LSTM 无法捕捉到“but … higher than”的结构，但是 paper 中的模型对其敏感，说明共享层不仅增强了特定词的意义，并且帮助特定任务学到结构信息。</p>
<h3 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h3><p>该模型的错误案例可分为两种：</p>
<ol>
<li>一些含有非常复杂的结构的句子不能被适当处理，例如二次否定、虚拟语气。对于这些情况，在结构上可以做一些改进，比如基于树的 LSTM；</li>
<li>某些句子难以从书面意思判断其情绪，例如“I tried to read the time on my watch.”</li>
</ol>
<!--## 个人疑惑

state-of-the-art 是参考别人论文的数据，还是自己实现？如何保证自己编写程序实现的效果达到别人论文的水平（如何判断是自己的问题还是别人论文有误）？state-of-the-art 是选择数次实验的平均值还是数次实验中的最大值？多少次实验是足够的最低值？-->]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文链接：&lt;a href=&quot;http://www.ijcai.org/Proceedings/16/Papers/408.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Recurrent Neural Network for Text Classification with Multi-Task Learning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作者：Pengfei Liu, Xipeng Qiu, Xuanjing Huang&lt;/p&gt;
&lt;p&gt;单位：复旦大学 自然语言处理与深度学习组&lt;/p&gt;
&lt;p&gt;文章来源：IJCAI 2016&lt;/p&gt;
&lt;p&gt;简介：本文针对文本多分类任务，提出了基于 RNN 的三种不同的共享信息机制，在四个基准的文本分类任务中取得了较好的结果。&lt;/p&gt;
&lt;h2 id=&quot;研究概况&quot;&gt;&lt;a href=&quot;#研究概况&quot; class=&quot;headerlink&quot; title=&quot;研究概况&quot;&gt;&lt;/a&gt;研究概况&lt;/h2&gt;&lt;h3 id=&quot;研究背景&quot;&gt;&lt;a href=&quot;#研究背景&quot; class=&quot;headerlink&quot; title=&quot;研究背景&quot;&gt;&lt;/a&gt;研究背景&lt;/h3&gt;&lt;p&gt;假设多个任务之间具有相关性，&lt;strong&gt;&lt;a href=&quot;http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Structuring_Machine_Learning_Projects/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89?id=%e5%a4%9a%e4%bb%bb%e5%8a%a1%e5%ad%a6%e4%b9%a0&quot;&gt;多任务学习&lt;/a&gt;&lt;/strong&gt;利用任务之间的相关性相互促进，通过并行学习任务来提高分类效果。这些模型的基本的多任务架构将共享一些较低的层以确定共同的特性。在共享层之后，每个特定任务单独使用一个输出层。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Structuring_Machine_Learning_Projects/Shared-Representation.png&quot; alt=&quot;Shared-Representation&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;前人工作和不足&quot;&gt;&lt;a href=&quot;#前人工作和不足&quot; class=&quot;headerlink&quot; title=&quot;前人工作和不足&quot;&gt;&lt;/a&gt;前人工作和不足&lt;/h3&gt;&lt;p&gt;基于神经网络的多任务学习已被用于解决 NLP 的各类任务。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用一个对于输入单词的共享表示：用途是解决词性标注、语义角色标注等传统 NLP 任务。缺点是只有一张查找表是共享的、其他查找表和层是任务特定的，并且需要用基于窗口的方法处理长度不定的文本序列；&lt;/li&gt;
&lt;li&gt;多任务 DNN 来学习表示：用途是解决查询分类和网络搜索排名任务。缺点是模型输入为词袋表示，损失了词序信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不同于以上两种方法，本文的模型基于 RNN，对于建模变长文本序列更友好。&lt;/p&gt;
&lt;h3 id=&quot;本文工作&quot;&gt;&lt;a href=&quot;#本文工作&quot; class=&quot;headerlink&quot; title=&quot;本文工作&quot;&gt;&lt;/a&gt;本文工作&lt;/h3&gt;&lt;p&gt;基于 RNN，提出了三种不同的共享信息机制，可以将信息共享到特定任务层的共享层。整个网络都是在所有这些任务上共同训练的。模型在四个基准的文本分类任务上展示了很好的效果，超过了大多数的 state-of-the-art。&lt;/p&gt;
&lt;!--### 意义和创新点--&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://kyonhuang.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="自然语言处理" scheme="http://kyonhuang.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="多任务学习" scheme="http://kyonhuang.top/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="文本分类" scheme="http://kyonhuang.top/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    
      <category term="RNN" scheme="http://kyonhuang.top/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>记知识图谱前沿技术课程（武汉大学站）</title>
    <link href="http://kyonhuang.top/whu-KG-technology-course/"/>
    <id>http://kyonhuang.top/whu-KG-technology-course/</id>
    <published>2018-05-05T13:32:03.000Z</published>
    <updated>2018-05-10T14:17:30.091Z</updated>
    
    <content type="html"><![CDATA[<p>这周一（4月28日）参加了<a href="https://mp.weixin.qq.com/s?__biz=MzI0MTI1Nzk1MA==&amp;mid=2651676132&amp;idx=1&amp;sn=3965c4718e97cf4962301229c4fd877f&amp;chksm=f2f7a155c5802843c1ec73a120d6cbe506c819cf87f32b4f5fa68862dd6603a2edb66f10208b&amp;mpshare=1&amp;scene=23&amp;srcid=04209Zn8T1cUyBEYullCcwnB#rd" target="_blank" rel="external">知识图谱前沿技术课程暨学术研讨会（武汉大学站）</a>。本次研讨会邀请了很多著名学者和企业代表，结合知识图谱学界研究与业界应用的进展，系统地讲解知识图谱前沿技术及智能应用。</p>
<p>我之前对知识图谱了解甚少，但经过一整天的讲座学习，也接触到了知识图谱的理论知识和产业实际应用，感受到了其独特的魅力。在八场主题各异的讲座中，我认为复旦大学知识工场实验室的肖仰华教授所带来的《领域知识图谱落地实践中的问题与对策》既有对知识图谱技术的概述，也有足够的深度和思考空间。因此，我基于这场讲座的内容笔记，结合自己查找的其他资料做一个整理。</p>
<p>注：本文涉及的图片及资料均整理自肖仰华教授的讲座内容，版权归其所有。</p>
<a id="more"></a>
<h3 id="知识图谱的概念"><a href="#知识图谱的概念" class="headerlink" title="知识图谱的概念"></a>知识图谱的概念</h3><p>顾名思义，<strong>领域知识图谱（Domain-specific Knowledge Graph）</strong>即是特定领域的知识图谱。而<strong>知识图谱（Knowledge Graph）</strong>是以<strong>实体/概念</strong>为点、它们之间的<strong>语义关系</strong>为边的大规模<strong>语义网络</strong>。</p>
<p><img src="/images/KG/Knowledge-Graph.png" alt=""></p>
<p>传统的知识工程需要专家构建，代价高昂，规模有限；并且知识边界易于突破，难以适应大数据时代开放应用到规模化需求。而知识图谱富含<strong>实体、概念、属性、关系</strong>等信息，使得机器<strong>理解和解释</strong>成为可能。最重要的是，知识图谱可以满足大规模开放应用。</p>
<p>尽管肖教授表示“知识图谱引领知识工程复兴<br>”，他也同时提出了<strong>NoKG（Not only KG）</strong>一词，以表示解决问题的知识表示不只是知识图谱，因为知识图谱不好处理过程知识、决策知识等。</p>
<h3 id="领域知识图谱（DKG）与-通用知识图谱（GKG）的关系与区别"><a href="#领域知识图谱（DKG）与-通用知识图谱（GKG）的关系与区别" class="headerlink" title="领域知识图谱（DKG）与 通用知识图谱（GKG）的关系与区别"></a>领域知识图谱（DKG）与 通用知识图谱（GKG）的关系与区别</h3><p>两者在知识表示、获取与应用等方面有着显著的差异：</p>
<p><img src="/images/KG/DKG-GKG.png" alt=""></p>
<p>一个问题是，行业应用中的知识需求难以封闭于预设的领域知识边界内。因此，在做领域知识图谱时不可避免的需要通用知识图谱的支撑，为其提供高质量的事实和基本的领域纲要；反过来，领域知识图谱又对通用知识图谱有补充和完善。</p>
<h3 id="知识表示方式"><a href="#知识表示方式" class="headerlink" title="知识表示方式"></a>知识表示方式</h3><p><strong>符号表示</strong>和<strong>分布式表示</strong>是两种重要的知识表示方式。符号化表示的特点是可解释、可推理、面向人；分布式表示则难解释、难推理、面向机器，这是因为它是用数值表示的（和自然语言处理中的词嵌入有些类似）。</p>
<p><img src="/images/KG/Knowledge-representation.png" alt=""></p>
<h3 id="为何需要领域知识图谱？"><a href="#为何需要领域知识图谱？" class="headerlink" title="为何需要领域知识图谱？"></a>为何需要领域知识图谱？</h3><ul>
<li>将零碎的数据整合为聚合的知识，助力挖掘数据价值</li>
<li>将领域知识赋予机器，解放人类脑力，实现知识工作自动化</li>
<li>领域知识的积累和沉淀是未来智能化的必经之路</li>
</ul>
<h3 id="DKG-中知识如何表示"><a href="#DKG-中知识如何表示" class="headerlink" title="DKG 中知识如何表示"></a>DKG 中知识如何表示</h3><ul>
<li><strong>三元组（SPO）表示</strong>：&lt;七里香，填词，方文山&gt;</li>
<li><strong>时空语义扩展</strong>：从时间角度和空间角度进行表示</li>
<li><strong>跨媒体表示</strong>：文本、图片、视频</li>
</ul>
<h3 id="领域知识图谱构建的基本流程"><a href="#领域知识图谱构建的基本流程" class="headerlink" title="领域知识图谱构建的基本流程"></a>领域知识图谱构建的基本流程</h3><p><img src="/images/KG/DKG-construction.png" alt=""></p>
<h3 id="领域知识图谱的评价指标"><a href="#领域知识图谱的评价指标" class="headerlink" title="领域知识图谱的评价指标"></a>领域知识图谱的评价指标</h3><p>质量（准）、规模（全）、实时（新）</p>
<h3 id="领域知识图谱的数据库选型"><a href="#领域知识图谱的数据库选型" class="headerlink" title="领域知识图谱的数据库选型"></a>领域知识图谱的数据库选型</h3><p>进行数据库选型时，一般要考虑操作复杂度（是否包含全局计算、多步遍历和复杂子图）和知识库规模（节点、关系、密度）。当规模极高、操作极复杂时，由于知识图谱先天适用于图表示，因此一般使用 Graph DB（图数据库）。其他情境下，也可以选用 NoSQL DB 或者 MySQL 等 Relational DB。</p>
<h3 id="领域知识图谱的查询方式"><a href="#领域知识图谱的查询方式" class="headerlink" title="领域知识图谱的查询方式"></a>领域知识图谱的查询方式</h3><p>进行 DKG 的查询时，一般有 SPARQL 和 SQL 语句两种选择。SQL 的优点是简单且普及性高，但是表达能力相对较弱；而 SPARQL 表达能力强、可推理，但是较为复杂、难以书写，并且执行复杂查询的代价高昂。</p>
<h3 id="领域知识图谱如何应用？"><a href="#领域知识图谱如何应用？" class="headerlink" title="领域知识图谱如何应用？"></a>领域知识图谱如何应用？</h3><ul>
<li>智慧搜索：精准理解搜索意图、复杂多元对象搜索、多粒度（篇章、段落、语句）搜索、跨媒体搜索；</li>
<li>智能推荐：精确感知任务与场景；</li>
<li>智能问答：更自然的对话式人机交互取代关键词搜索；</li>
<li>智能解释：提高事实、关系、过程、结果的可解释性；</li>
<li>决策分析：隐层关系发现、深层关系推理助力智能系统决策。</li>
</ul>
<h3 id="领域知识图谱落地有哪些最佳实践？"><a href="#领域知识图谱落地有哪些最佳实践？" class="headerlink" title="领域知识图谱落地有哪些最佳实践？"></a>领域知识图谱落地有哪些最佳实践？</h3><ul>
<li><strong>应用引领</strong>：不要盲目建立知识图谱，否则易成“烂尾楼”</li>
<li><strong>避难就简</strong>：结构化 -&gt; 半结构化 -&gt; 非结构化，用最简单的开始实现</li>
<li><strong>避免从零开始</strong>：以通用图谱中的领域图谱作为种子</li>
<li><strong>跨领域迁移</strong>：从临近领域迁移</li>
</ul>
<h3 id="领域知识图谱还存在哪些挑战？"><a href="#领域知识图谱还存在哪些挑战？" class="headerlink" title="领域知识图谱还存在哪些挑战？"></a>领域知识图谱还存在哪些挑战？</h3><ul>
<li><strong>如何增强知识图谱的语义表示能力？</strong>：知识图谱只能表达简单关联事件，对于时空语义、跨媒体语义支撑力度不够；</li>
<li><strong>如何实现稀疏样本下的图谱自动构建？</strong>：领域样本缺失现象严重，手工构建代价高昂；稀疏样本下的高质量自动化构建缺乏有效手段；</li>
<li><strong>如何深化基于领域知识图谱智能应用？</strong>：领域知识图谱在行业的深入应用中仍缺乏有效手段，特别是推荐、推理与解释。</li>
</ul>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>可以看到，本场讲座的内容真的非常详尽。在听完讲座后，我个人还是非常看好知识图谱的发展前景的。</p>
<p>如果想要进一步了解知识图谱，也可以看以下资料：</p>
<ul>
<li><a href="https://www.jiqizhixin.com/articles/2017-03-20" target="_blank" rel="external">知识图谱研究进展 | 机器之心</a></li>
<li><a href="https://www.zhihu.com/question/52368821" target="_blank" rel="external">知识图谱怎样入门？ - 知乎</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这周一（4月28日）参加了&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI0MTI1Nzk1MA==&amp;amp;mid=2651676132&amp;amp;idx=1&amp;amp;sn=3965c4718e97cf4962301229c4fd877f&amp;amp;chksm=f2f7a155c5802843c1ec73a120d6cbe506c819cf87f32b4f5fa68862dd6603a2edb66f10208b&amp;amp;mpshare=1&amp;amp;scene=23&amp;amp;srcid=04209Zn8T1cUyBEYullCcwnB#rd&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;知识图谱前沿技术课程暨学术研讨会（武汉大学站）&lt;/a&gt;。本次研讨会邀请了很多著名学者和企业代表，结合知识图谱学界研究与业界应用的进展，系统地讲解知识图谱前沿技术及智能应用。&lt;/p&gt;
&lt;p&gt;我之前对知识图谱了解甚少，但经过一整天的讲座学习，也接触到了知识图谱的理论知识和产业实际应用，感受到了其独特的魅力。在八场主题各异的讲座中，我认为复旦大学知识工场实验室的肖仰华教授所带来的《领域知识图谱落地实践中的问题与对策》既有对知识图谱技术的概述，也有足够的深度和思考空间。因此，我基于这场讲座的内容笔记，结合自己查找的其他资料做一个整理。&lt;/p&gt;
&lt;p&gt;注：本文涉及的图片及资料均整理自肖仰华教授的讲座内容，版权归其所有。&lt;/p&gt;
    
    </summary>
    
      <category term="讲座心得记录" scheme="http://kyonhuang.top/categories/%E8%AE%B2%E5%BA%A7%E5%BF%83%E5%BE%97%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="自然语言处理" scheme="http://kyonhuang.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="讲座" scheme="http://kyonhuang.top/tags/%E8%AE%B2%E5%BA%A7/"/>
    
      <category term="知识图谱" scheme="http://kyonhuang.top/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
  </entry>
  
  <entry>
    <title>胶囊网络初探</title>
    <link href="http://kyonhuang.top/capsule-networks-intro/"/>
    <id>http://kyonhuang.top/capsule-networks-intro/</id>
    <published>2018-04-26T12:07:53.000Z</published>
    <updated>2018-05-29T12:01:07.130Z</updated>
    
    <content type="html"><![CDATA[<p>如果你有关注我的 Github，可以看到我和小伙伴们正在做一个<a href="https://github.com/bighuang624/sentiment-analysis-webapp" target="_blank" rel="external">中文短文本情感分析 web 应用</a>。恰逢 WWW 2018 收录了一篇<a href="https://dl.acm.org/citation.cfm?id=3186015" target="_blank" rel="external">《Sentiment Analysis by Capsules》</a>，借着这个机会了解一下“神经网络之父” Geoffrey Hinton 大神花费近十年心血的胶囊网络（Capsule Networks）。如果能够用于我们的应用中就更好了，即使因为缺少计算资源等原因而无法实现，了解前沿技术、吸收大牛思想也是极好的。</p>
<p>先简单介绍一下 Capsule。NIPS 2017 发表的<a href="https://arxiv.org/pdf/1710.09829v2.pdf" target="_blank" rel="external">《Dynamic Routing Between Capsules》</a>[1]使得这一概念开始走红，虽然 Capsule 本用于 CV 领域，不过目前也已经在各领域有了积极的尝试。Capsule 是 Hinton“反 CNN”的一面旗帜，他认为导致深度学习如火如荼的 CNN 其实有着重大的缺陷。我接下来就将介绍这个缺陷、Capsule 如何通过其工作原理避免这个缺陷、Capsule 的结构，以及 Capsule 的训练算法与损失函数等。不过因为篇幅有限，这篇文章暂时不会介绍 CapsNet 的具体架构，这部分可以看一下参考资料列的一些或者直接看原论文。顺便一提，Capsule 和胶囊两个词可能在本文中互有使用，但我实际上想用它们指同一个东西。</p>
<a id="more"></a>
<h2 id="CNN-的缺陷"><a href="#CNN-的缺陷" class="headerlink" title="CNN 的缺陷"></a>CNN 的缺陷</h2><p>如果你了解 CNN（不了解请移至<a href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Convolutional_Neural_Networks/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">《卷积神经网络 - 吴恩达《深度学习》系列课程笔记》</a>），你会知道 CNN 依靠卷积层检测图像中的特征。前几层学习一些例如边缘的简单特征，而较深的层组合简单特征形成更为复杂的特征，最后再将复杂特征组合并输出分类预测。</p>
<p>而在层与层之间，前一层的激活与下一层神经元的权重相乘并相加，接着传递到非线性激活函数。这种简单的加权和导致 <strong>CNN 难以察觉平移和旋转（以及类似变化）后图像的一致性</strong>，例如，将一张狗的照片旋转 5 度，训练好的 CNN 可能会认为两张图片都是狗，但是不会认为它们是同一只狗。</p>
<p>CNN 解决这个问题的方法是使用最大池化，对于一定区域内的特征取最大值，以此缓解一定的平移和旋转的影响（平均池化同理）。事实证明，CNN 的效果惊人，以至于“它表现如此优异是一场灾难”。引号内是 Hinton 的原话，因为他认为最大池化损失了很多有价值的信息。最重要的是，CNN 只考虑简单对象的存在，而<strong>没有考虑简单对象和复杂对象之间的空间层级关系</strong>。举个例子，对于 CNN 而言，下面两张图片都是一张脸，因为它们包含相似的部件，尽管我们知道散落的器官不能被称为脸。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2702529-5c96a8e0b1fb2b64.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="人脸.jpg"></p>
<p>以上问题导致的结果是，CNN 难以分类和辨识不同视角的同一物体。对于人类，即使你只看过几张自由女神像的照片，也能够轻松辨认不同角度的自由女神像。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2702529-252e3955a7502bb9.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="自由女神.jpg"></p>
<p>但对于 CNN，这个任务就非常困难了，因为它没有内建对三维空间的理解。它只能与以前训练过的照片进行对比，这导致训练 CNN 往往需要百万数量级的图像才能训练出较为精准的效果，并且当遇到角度奇怪的图像时分类正确率可能受到影响。最重要的是，我们知道神经网络本就是为了尽可能还原人脑的功能，但明显人类根本不需要对每个物体都看如此规模的图片才能学会辨认。</p>
<h2 id="Why-Capsule？"><a href="#Why-Capsule？" class="headerlink" title="Why Capsule？"></a>Why Capsule？</h2><p>基于以上分析，尽管目前 CNN 看似效果非常出色，但是它不会是未来。实际上，Hinton 早在 2011 年就提出 Capsule 的结构[2]，但是在当时还没有提出一种算法可以实现并成功学习胶囊网络。而在[1]中，Hinton 提出一种名为<strong>动态路由（Dynamic Routing）</strong>的算法解决了这个问题。</p>
<p>CNN 通过一层层的过滤，将信息一步步由下而上的进行抽象；而 Hinton 认为人类在识别图像时是遵循类似决策树的方式。Capsule 同样遵循这个结构的思路，每个活动的 Capsule 将选择一个上层的 Capsule 作为父节点。</p>
<p>Capsule 更好地建模神经网络中内部知识表示的分层关系，这使得训练它所需的数据量大大降低。关键的一点是，Capsule 背后的直觉非常简单优雅，易于理解。尽管目前训练胶囊网络速度比起已经成熟的深度学习模型来说要慢很多，但是假以时日，也许胶囊网络能够在更多训练集上快速高效训练。</p>
<h2 id="Capsule-的工作原理"><a href="#Capsule-的工作原理" class="headerlink" title="Capsule 的工作原理"></a>Capsule 的工作原理</h2><p>Capsule 的工作原理归纳成一句话就是，<strong>所有胶囊检测中的特征的状态的重要信息，都将以向量的形式（神经元输出的则是标量）被胶囊封装</strong>。</p>
<p>进一步来说，一个胶囊捕捉一个特征。胶囊将特征存在的<strong>概率</strong>作为其<strong>输出向量的长度</strong>进行编码，这与目前的神经元同理。而检测出的特征的<strong>状态</strong>被编码为该向量指向的<strong>方向</strong>（“实例参数”）。因此，当检测出的特征在图像中平移或旋转，向量长度没有改变（因为概率保持不变），但它的方向改变了。</p>
<p>从标量到向量，这是一个让人初次听闻时拍案叫绝、但仔细思考过后又觉得理所当然的改变。这种改变使得平移或旋转导致的“变化”与“不变”被转化为向量的长度与方向，从而自然分离开来，而不是像 CNN 使用最大池化一样将“变化”全部简单粗暴地抹平为“不变”。</p>
<h2 id="Capsule-的运算步骤"><a href="#Capsule-的运算步骤" class="headerlink" title="Capsule 的运算步骤"></a>Capsule 的运算步骤</h2><p><img src="https://upload-images.jianshu.io/upload_images/2702529-b09707696facdfda.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="胶囊vs人工神经元.jpg"></p>
<p>上图中左边为胶囊，右边为普通神经元。本质上，普通神经元的运算步骤分为 3 步：</p>
<ol>
<li>输入标量的标量加权；</li>
<li>对加权后的标量求和；</li>
<li>对和进行非线性变换生成新标量。</li>
</ol>
<p>而胶囊则在向量版的基础上有少许改动，共 4 步：</p>
<ol>
<li>输入向量的矩阵乘法；</li>
<li>输入向量的标量加权；</li>
<li>对加权后的向量求和；</li>
<li>对和进行非线性变换生成新向量。</li>
</ol>
<h3 id="输入向量的矩阵乘法"><a href="#输入向量的矩阵乘法" class="headerlink" title="输入向量的矩阵乘法"></a>输入向量的矩阵乘法</h3><p>上层胶囊的输入向量来自下层胶囊。这些向量相乘的权重矩阵 W 编码了低层特征和高层特征之间包括空间关系在内的重要关系。</p>
<p>我在这里有一个疑问：这个 W 怎么得到？如果是通过训练迭代得到，那么用的是什么算法？原 paper 对这点略过不表，有一篇文章说 W 是固定不变的，但是也没有说如何获得。如果有看到这篇文章并有答案的同学，欢迎评论指出或者邮件联系我。</p>
<h3 id="输入向量的标量加权"><a href="#输入向量的标量加权" class="headerlink" title="输入向量的标量加权"></a>输入向量的标量加权</h3><p>在这一步中，我们可能比较关心如何通过学习得到权重矩阵 W’。通常神经网络通过反向传播算法学习，而胶囊则使用<strong>动态路由算法</strong>。我们将在后文详细介绍动态路由算法，这里先简单介绍一下 W’ 中权重 cij 的一些性质：</p>
<ol>
<li>权重均为非负标量；</li>
<li>对每个低层胶囊 i，所有权重 cij 的总和等于 1；</li>
<li>对每个低层胶囊 i，权重的数量等于高层胶囊的数量。</li>
</ol>
<p>这三条性质均在表明，这里的权重表示概率。</p>
<h3 id="对加权后的向量求和"><a href="#对加权后的向量求和" class="headerlink" title="对加权后的向量求和"></a>对加权后的向量求和</h3><p>除开求的是向量的和（而非标量和），这一步与通常的神经网络没有区别。</p>
<h3 id="对和进行非线性变换生成新向量"><a href="#对和进行非线性变换生成新向量" class="headerlink" title="对和进行非线性变换生成新向量"></a>对和进行非线性变换生成新向量</h3><p>Capsule 使用了一个新颖的非线性激活函数——squash 函数。它可以压缩输入向量的长度，而不改变其方向。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2702529-bf5baae6af4e1020.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="squash.png"></p>
<p>容易看出，蓝色矩形部分将输入向量缩放至单位长度，而红色矩形部分进行额外的缩放操作。函数图像如下：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2702529-0b21e542874bff2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="suqash-function-graph.png"></p>
<p>总结来说，对于上一个胶囊层输出的所有胶囊向量，通过转换矩阵转换为更高层的胶囊向量，最后通过动态路由算法聚合成一个胶囊向量，最后通过 squash 激活函数输出最后结果。</p>
<h2 id="动态路由（Dynamic-Routing）算法"><a href="#动态路由（Dynamic-Routing）算法" class="headerlink" title="动态路由（Dynamic Routing）算法"></a>动态路由（Dynamic Routing）算法</h2><p>动态路由算法的思想是，低层胶囊将其输出发送给对此表示“同意”的高层胶囊。这种同意表现为<strong>向量的点积</strong>。</p>
<p>贴一张论文中对动态路由算法的伪代码描述：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2702529-b66e0182d94d57c0.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="伪代码.jpg"></p>
<p>我们只看几个算法中的关键点：</p>
<ul>
<li>第一行指明算法的输入：l 是低层的层数，\hat u 是低层输出的所有胶囊向量，r 是迭代次数。</li>
<li>第四行使用 Softmax 的原因是强制实施“对每个低层胶囊 i，所有权重 cij 的总和等于 1”这一条性质。</li>
<li>初始化时，所有 cij 均相等，说明底层胶囊被高层胶囊接受的概率相等。随着迭代，这种均匀分布将被改变。</li>
<li>第七行更新了权重，也是路由算法的本质所在。在这一步中，我们查看了每个高层胶囊 j，然后检查每个输入并根据公式更新相应的权重 bij。公式表明，胶囊 j 的当前输出和从低层胶囊 i 处接收的输入的点积，加上旧权重，等于新权重。点积检测胶囊的输入和输出之间的相似性。</li>
</ul>
<p>论文表示，通过在 MNIST 和 CIFAR 两个数据集上的检验，实践中建议使用 3 次迭代。更多的迭代容易导致过拟合。</p>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p><img src="https://upload-images.jianshu.io/upload_images/2702529-32d23ca1dcb57f67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="代价函数.png"></p>
<p>对于数字 c（或者说类别 c），代价函数如上图所示。MNIST 数据集中，当数字 c 与标签对应时，Tc = 1，否则为 0；m+ = 0.9，m- = 0.1。λ 取 0.5 以确保训练中的数值稳定性。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>了解 CapsNet 的具体架构有助于理解以上内容，所以我还是建议看一下原论文中这部分的内容。另外，虽然原论文相对于很多深度学习论文显得简洁而易于理解，但是有些细节并没有完全解释，我会试着再找一些资料阅读。我的下一个目标是阅读文章开头提到的《Sentiment Analysis by Capsules》。显然这篇新鲜出炉的 paper 没有什么辅助我理解的文章，我打算打印下来仔细读一读。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><h3 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h3><ul>
<li>[1] <a href="https://arxiv.org/pdf/1710.09829v2.pdf" target="_blank" rel="external">Dynamic Routing Between Capsules</a></li>
<li>[2] <a href="http://www.cs.utoronto.ca/~hinton/absps/transauto6.pdf?origin=publication_detail" target="_blank" rel="external">Transforming Autoencoders</a></li>
</ul>
<h3 id="文章"><a href="#文章" class="headerlink" title="文章"></a>文章</h3><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;mid=2247484099&amp;idx=1&amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;scene=21#wechat_redirect" target="_blank" rel="external">CapsNet入门系列之一：胶囊网络背后的直觉</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;mid=2247484165&amp;idx=1&amp;sn=0ca679e3a5f499f8d8addb405fe3df83&amp;chksm=eb4ee7c6dc396ed0a330fcac12690110bcaf9a8a10794dbc5e1a326c69ecbb140140f55fd6ba&amp;scene=21#wechat_redirect" target="_blank" rel="external">CapsNet入门系列之二：胶囊如何工作</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;mid=2247484433&amp;idx=1&amp;sn=3afe4605bc2501eebbc41c6dd1af9572&amp;chksm=eb4ee0d2dc3969c4619d6c1097d5c949c76c6c854e60d36eba4388da2c3855747818d062c90a&amp;scene=21#wechat_redirect" target="_blank" rel="external">CapsNet入门系列之三：囊间动态路由算法</a></li>
<li><a href="https://mp.weixin.qq.com/s/6CRSen8P6zKaMGtX8IRfqw" target="_blank" rel="external">CapsNet入门系列之四：胶囊网络架构</a></li>
<li><a href="https://blog.csdn.net/jessican_uestc/article/details/79587096" target="_blank" rel="external">初读Geoffrey Hinton颠覆之作《Dynamic Routing Between Capsules》 - CSDN博客</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/35409788" target="_blank" rel="external">胶囊网络（Capsule Network）在文本分类中的探索</a></li>
</ul>
<h3 id="开源代码"><a href="#开源代码" class="headerlink" title="开源代码"></a>开源代码</h3><ul>
<li><a href="https://github.com/Sarasra/models/tree/master/research/capsules" target="_blank" rel="external">Sarasra/models</a>：由《Dynamic Routing Between Capsules》第一作者编写</li>
<li><a href="https://github.com/llSourcell/capsule_networks" target="_blank" rel="external">llSourcell/capsule_networks</a></li>
<li><a href="https://github.com/XifengGuo/CapsNet-Keras" target="_blank" rel="external">XifengGuo/CapsNet-Keras</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果你有关注我的 Github，可以看到我和小伙伴们正在做一个&lt;a href=&quot;https://github.com/bighuang624/sentiment-analysis-webapp&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;中文短文本情感分析 web 应用&lt;/a&gt;。恰逢 WWW 2018 收录了一篇&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3186015&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《Sentiment Analysis by Capsules》&lt;/a&gt;，借着这个机会了解一下“神经网络之父” Geoffrey Hinton 大神花费近十年心血的胶囊网络（Capsule Networks）。如果能够用于我们的应用中就更好了，即使因为缺少计算资源等原因而无法实现，了解前沿技术、吸收大牛思想也是极好的。&lt;/p&gt;
&lt;p&gt;先简单介绍一下 Capsule。NIPS 2017 发表的&lt;a href=&quot;https://arxiv.org/pdf/1710.09829v2.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《Dynamic Routing Between Capsules》&lt;/a&gt;[1]使得这一概念开始走红，虽然 Capsule 本用于 CV 领域，不过目前也已经在各领域有了积极的尝试。Capsule 是 Hinton“反 CNN”的一面旗帜，他认为导致深度学习如火如荼的 CNN 其实有着重大的缺陷。我接下来就将介绍这个缺陷、Capsule 如何通过其工作原理避免这个缺陷、Capsule 的结构，以及 Capsule 的训练算法与损失函数等。不过因为篇幅有限，这篇文章暂时不会介绍 CapsNet 的具体架构，这部分可以看一下参考资料列的一些或者直接看原论文。顺便一提，Capsule 和胶囊两个词可能在本文中互有使用，但我实际上想用它们指同一个东西。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://kyonhuang.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="深度学习" scheme="http://kyonhuang.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="胶囊网络" scheme="http://kyonhuang.top/tags/%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Capsule" scheme="http://kyonhuang.top/tags/Capsule/"/>
    
      <category term="CapsNet" scheme="http://kyonhuang.top/tags/CapsNet/"/>
    
      <category term="Dynamic Routing" scheme="http://kyonhuang.top/tags/Dynamic-Routing/"/>
    
  </entry>
  
  <entry>
    <title>编译原理复习笔记</title>
    <link href="http://kyonhuang.top/fundamentals-of-compiling-notes/"/>
    <id>http://kyonhuang.top/fundamentals-of-compiling-notes/</id>
    <published>2018-04-11T06:32:42.000Z</published>
    <updated>2018-06-02T01:35:20.310Z</updated>
    
    <content type="html"><![CDATA[<p>开始学科复习。选择编译原理作为第一门复习的课程，因为其内容不算太多，大部分计算过程可以暂时不用记录和练习，而且没什么前置知识。</p>
<p>选用课本是上课时用的清华大学出版社《编译原理》（其实我觉得这本书里给部分概念下定义时没有做到简洁明了，挺难理解的）。以下是记录的笔记。不求全面，只求适合自己之后再次复习使用。</p>
<a id="more"></a>
<h2 id="编译程序与编译过程"><a href="#编译程序与编译过程" class="headerlink" title="编译程序与编译过程"></a>编译程序与编译过程</h2><h3 id="编译程序（Compiler）"><a href="#编译程序（Compiler）" class="headerlink" title="编译程序（Compiler）"></a>编译程序（Compiler）</h3><ul>
<li>从功能上看，一个编译程序就是一个语言翻译程序；</li>
<li>基本任务：将源语言程序翻译成等价的目标语言程序。</li>
<li>重要性：使多数计算机用户不必考虑与机器有关的繁琐细节，使程序员独立于机器。</li>
</ul>
<h3 id="解释程序（Interpreter）"><a href="#解释程序（Interpreter）" class="headerlink" title="解释程序（Interpreter）"></a>解释程序（Interpreter）</h3><p>以语言写的源程序作为输入，但不产生目标程序，而是边解释边执行源代码本身。</p>
<h3 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h3><ol>
<li><strong>词法分析</strong>：<ul>
<li>功能：从左到右扫描源程序，并将该字符串转换成单词（Token）串；同时，检查词法错误、进行标识符登记——符号表管理</li>
<li>工具：正规表达式、自动机</li>
</ul>
</li>
<li><strong>语法分析</strong>：<ul>
<li>功能：在词法分析的基础上将单词序列分解成各类语法短语；构造分析树，指出语法错误，指导翻译。</li>
</ul>
</li>
<li><strong>语义分析</strong>：<ul>
<li>功能：审查源程序有无语义错误，为代码生成阶段收集类型信息；</li>
</ul>
</li>
<li><strong>中间代码生成</strong>：<ul>
<li>功能：经过上述工作之后，将源程序变为独立于具体硬件的记号系统；</li>
</ul>
</li>
<li><strong>代码优化</strong>：<ul>
<li>对前一阶段产生的中间代码进行等价变换，以获取更高的执行效率（速度、空间）；</li>
<li>分为机器有关和机器无关</li>
</ul>
</li>
<li><strong>目标代码生成</strong>：<ul>
<li>功能：将中间代码转换成目标机上的<strong>机器指令代码或者汇编代码</strong>，完成最后的翻译，可以运行；</li>
</ul>
</li>
</ol>
<p><img src="https://user-images.githubusercontent.com/18595460/38497042-45ebb4d0-3c32-11e8-93a6-23fe52e5a752.png" alt="2018-04-09 20 01 19"></p>
<h3 id="翻译程序的结构"><a href="#翻译程序的结构" class="headerlink" title="翻译程序的结构"></a>翻译程序的结构</h3><p><img src="https://user-images.githubusercontent.com/18595460/38499719-0c12b9d0-3c3b-11e8-81ee-61f038b98d32.png" alt="default"></p>
<p>符号表管理、错误处理：前端后端都有出现。</p>
<p><strong>遍（pass）</strong>：</p>
<ul>
<li>对源程序或源程序的中间结果从头到尾扫描，并做相关的加工处理，生成新的中间结果或目标程序；</li>
<li>遍可以和阶段相对应，也可无关；</li>
<li>分遍可以使编译程序的结构清晰，但增加 I/O 时间；</li>
<li>影响分遍因素：内存不够、全局优化需要、某些语言需要（如名字先引用后定义）。</li>
</ul>
<h2 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h2><p>单词的形式化描工具：</p>
<ul>
<li>正规文法（3 型文法）</li>
<li>正规式（正则表达式）</li>
<li>自动机（DFA、NFA）</li>
</ul>
<h3 id="自动机"><a href="#自动机" class="headerlink" title="自动机"></a>自动机</h3><p><strong>确定的有穷自动机（DFA）</strong>和<strong>不确定的有穷自动机（NFA）</strong>的区别：确定性 =&gt; 对任何状态和输入符号，唯一地确定了下一个状态。</p>
<ul>
<li>NFA 转换为等价的 DFA：子集法</li>
<li>DFA 的化简</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/18595460/38499639-d58926e2-3c3a-11e8-820d-42f6984acc18.png" alt="dfa"></p>
<h2 id="文法与语言"><a href="#文法与语言" class="headerlink" title="文法与语言"></a>文法与语言</h2><p>产生式（又称规则）：a -&gt; b   左部 -&gt; 右部</p>
<p><strong>文法</strong>：</p>
<ul>
<li>阐明语法的一个工具。</li>
<li>作用：<ol>
<li>严格地定义句子的结构；</li>
<li>用适当条数的规则描述语言的全部句子。</li>
</ol>
</li>
<li>4 种文法类型：逐渐增加限制<ul>
<li>0 型文法：对于每个产生式 A -&gt; B，A 含至少一个非终结符</li>
<li>上下文有关的（1 型）：每个产生式均满足 |B| &gt;= |A|（除非 B 为空）</li>
<li>上下文无关的（2 型）：每个产生式均满足 A 是一个非终结符</li>
<li>正规文法（3 型）：每个产生式的形式都是 A -&gt; aB 或 A -&gt; a（A、B 都是非终结符，a 是终结符）</li>
</ul>
</li>
</ul>
<h3 id="上下文无关文法及其语法树"><a href="#上下文无关文法及其语法树" class="headerlink" title="上下文无关文法及其语法树"></a>上下文无关文法及其语法树</h3><ul>
<li>推导：不断替换文法产生式左部的非终结符号，直至全部将非终结符号替换为终结符号的过程</li>
<li><strong>最左推导</strong>：总是优先替换产生式左部最左侧的非终结符号</li>
<li><strong>最右推导</strong>：总是优先替换产生式左部最右侧的非终结符号（在形式语言中称为<strong>规范推导</strong>）</li>
<li>二义文法：存在某个句子对应两棵不同的语法树的文法</li>
</ul>
<h3 id="句型分析"><a href="#句型分析" class="headerlink" title="句型分析"></a>句型分析</h3><ul>
<li><strong>自上而下的分析方法</strong>：<ul>
<li>从文法的开始符号出发，反复使用各种产生式，寻找“匹配”于输入符号串的推导；</li>
<li>通过最左推导从顶部（根结点）开始构造 AST；</li>
<li>常用的分析器有递归下降语法分析器、LL 语法分析器。</li>
</ul>
</li>
<li><p><strong>自下而上的分析方法</strong>：</p>
<ul>
<li>从输入符号串开始，逐步进行“规约”，直至规约到文法的开始符号；</li>
<li>通过最右推导从底部（叶子结点）开始构造 AST；</li>
<li>常用的分析器有 LR 语法分析器、SLR 语法分析器、LALR 语法分析器。</li>
</ul>
</li>
<li><p>短语：一个句型的语法树中任一子树叶节点所组成的符号串都是该句型的短语。</p>
</li>
<li>直接短语：当子树不包含其他更小的子树时，该子树叶节点所组成的字符串就是该句型的直接短语。</li>
<li>句柄：句柄是最左边的直接短语。</li>
</ul>
<p>例子：</p>
<p><img src="https://user-images.githubusercontent.com/18595460/38556812-8941d1b2-3cfd-11e8-8d48-4d4bdff4fef4.png" alt="20161213185118430"></p>
<p>可得<code>S=(Sd(T)db)</code>为此文法的一个句型：</p>
<ul>
<li>短语：<code>S</code>，<code>(T)</code>，<code>b</code>，<code>Sd(T)</code>，<code>Sd(T)db</code>，<code>(Sd(T)db)</code></li>
<li>直接短语：<code>S</code>，<code>(T)</code>，<code>b</code></li>
<li>句柄：<code>S</code></li>
</ul>
<h2 id="自顶向下语法分析"><a href="#自顶向下语法分析" class="headerlink" title="自顶向下语法分析"></a>自顶向下语法分析</h2><ul>
<li>自顶向下的确定分析方法：<ul>
<li>优点：实现方法简单、直观，便于手工构造或自动生成语法分析器</li>
<li>缺点：对文法有一定限制 </li>
</ul>
</li>
<li>自顶向下的不确定分析方法：<ul>
<li>带回溯</li>
<li>实际上是一种穷举的试探方法，效率低，代价高，极少使用</li>
<li>文法不满足 LL(1) 时使用</li>
</ul>
</li>
</ul>
<h3 id="确定的自顶向下分析思想"><a href="#确定的自顶向下分析思想" class="headerlink" title="确定的自顶向下分析思想"></a>确定的自顶向下分析思想</h3><p>LL(1) 文法是能够使用确定的自顶向下分析技术的。</p>
<p>LL(1) 的含义：</p>
<ul>
<li>第 1 个 L 表明自顶向下分析是从左向右扫描输入串；</li>
<li>第 2 个 L 表明分析过程中将用最左推导；</li>
<li>1 表明只需向右看一个符号便可决定选择哪个产生式进行推导。</li>
</ul>
<h3 id="LL-1-文法的判别"><a href="#LL-1-文法的判别" class="headerlink" title="LL(1) 文法的判别"></a>LL(1) 文法的判别</h3><p><img src="https://user-images.githubusercontent.com/18595460/38565503-1138b43a-3d14-11e8-8275-9488c8675389.png" alt="2018-04-10 22 48 10"></p>
<p>具体见课本。</p>
<h3 id="某些非-LL-1-文法到-LL-1-文法的等价变换"><a href="#某些非-LL-1-文法到-LL-1-文法的等价变换" class="headerlink" title="某些非 LL(1) 文法到 LL(1) 文法的等价变换"></a>某些非 LL(1) 文法到 LL(1) 文法的等价变换</h3><p>若文法中含有直接或间接左递归，或含有左公共因子，则该文法肯定不是 LL(1) 文法。因此，要做某些非 LL(1) 文法到 LL(1) 文法的等价变换，需要：</p>
<ol>
<li>提取左公共因子；</li>
<li>消除左递归。</li>
</ol>
<p>具体操作见课本。</p>
<h2 id="自底向上语法分析"><a href="#自底向上语法分析" class="headerlink" title="自底向上语法分析"></a>自底向上语法分析</h2><ul>
<li>又称<strong>移进-归约分析</strong></li>
<li>实现思想：对输入符号串自左向右进行扫描，并将输入符逐个<strong>移进</strong>一个后进先出栈中，边移入边分析，一旦栈顶符号串形成某个句型的句柄或其他可归约串（对应某产生式的右部）时，就用该产生式的左部非终结符代替右部的文法符号串。这个行为称为一步<strong>归约</strong>。</li>
</ul>
<h2 id="LR-分析"><a href="#LR-分析" class="headerlink" title="LR 分析"></a>LR 分析</h2><p>LR 分析法是一种能根据当前分析栈中的符号串和向右顺序查看输入串的 k 个符号就可以唯一确定分析器的动作是移进还是归约、用哪个产生式归约，因而能够唯一地确定句柄。</p>
<p>内容太多，图太多，但是对现阶段的我不太重要，故略。如果有学弟学妹看到了，这章是重点，所有例题都要自己推一遍。</p>
<h2 id="语法制导的语义计算"><a href="#语法制导的语义计算" class="headerlink" title="语法制导的语义计算"></a>语法制导的语义计算</h2><p>两种重要的语义计算模型：</p>
<ul>
<li><strong>属性文法</strong>：在文法基础上，为文法符号关联有特定意义的<strong>属性</strong>，并为产生式关联相应的<strong>语义动作</strong>或<strong>条件谓词</strong>。</li>
<li>翻译模式：在形式上类似于属性文法，但允许由<code>{}</code>括起来的语义动作出现在产生式右端的任何位置，以此显式地表达属性计算的次序。</li>
</ul>
<h3 id="基于属性文法的语义计算"><a href="#基于属性文法的语义计算" class="headerlink" title="基于属性文法的语义计算"></a>基于属性文法的语义计算</h3><ul>
<li><strong>综合属性</strong>：产生式左部的非终结符的某个属性。计算时自底向上传递信息。</li>
<li><p><strong>继承属性</strong>：产生式右部某个文法符号的某个属性。计算时自顶向下传递信息。</p>
</li>
<li><p><strong>遍历分析树进行语义计算</strong></p>
<ul>
<li>可以通过标注来表示属性的计算结果</li>
<li>在语法分析<strong>遍</strong>之后进行，不能体现语法制导方法的优势</li>
<li>实际的编译程序中，语法制导的语义计算大都采用单遍的过程（语法分析过程中完成语义动作） =&gt; 不是所有属性文法都适合单遍的处理过程 =&gt; 受限的属性文法</li>
</ul>
</li>
</ul>
<p>受限的属性文法：</p>
<ul>
<li><strong>S-属性文法</strong>：只包含综合属性的属性文法</li>
<li><strong>L-属性文法</strong>：既可以包含综合属性，也可以包含继承属性，但要求产生式右端某文法符号的继承属性的计算只取决于该符号左边符号的属性（对于产生式左部的符号，只能是继承属性）</li>
<li>S-属性文法是 L-属性文法的一个特例。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开始学科复习。选择编译原理作为第一门复习的课程，因为其内容不算太多，大部分计算过程可以暂时不用记录和练习，而且没什么前置知识。&lt;/p&gt;
&lt;p&gt;选用课本是上课时用的清华大学出版社《编译原理》（其实我觉得这本书里给部分概念下定义时没有做到简洁明了，挺难理解的）。以下是记录的笔记。不求全面，只求适合自己之后再次复习使用。&lt;/p&gt;
    
    </summary>
    
      <category term="学科补完计划" scheme="http://kyonhuang.top/categories/%E5%AD%A6%E7%A7%91%E8%A1%A5%E5%AE%8C%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="学科复习笔记" scheme="http://kyonhuang.top/tags/%E5%AD%A6%E7%A7%91%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="编译技术" scheme="http://kyonhuang.top/tags/%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF/"/>
    
      <category term="编译原理" scheme="http://kyonhuang.top/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统演进简述</title>
    <link href="http://kyonhuang.top/evolution-of-distributed-systems/"/>
    <id>http://kyonhuang.top/evolution-of-distributed-systems/</id>
    <published>2018-04-09T07:02:14.000Z</published>
    <updated>2018-05-09T12:56:50.284Z</updated>
    
    <content type="html"><![CDATA[<p>“网络与分布式计算”课程布置了一个作业，要求写一篇题目为“构建分布式系统技术发展历史”的小论文。我个人以为“历史”二字应该是要我们去了解每项技术诞生的时间点，然而踏破铁鞋无处可觅。最后写成的文章主题，我个人认为比起“历史”来说，“演进过程”可能更为恰当。</p>
<p>事实上我们可能也更为注重演进过程，因为分布式系统的演进过程，就是一代代工程师们对抗随时代和应用自身发展而逐渐升高的访问量的一部血泪史。这个过程是每一个健康发展的网站都要经历的。</p>
<p>这次作业也给了我一个机会，去大致了解网站在发展过程中为了提升性能、简化部署、弹性扩展而做出的种种措施，受益匪浅。因此将文章放到博客上。</p>
<a id="more"></a>
<h2 id="单体应用架构"><a href="#单体应用架构" class="headerlink" title="单体应用架构"></a>单体应用架构</h2><p>在应用诞生初始，用户量、数据量规模都比较小。因此应用程序、数据库、文件等所有的资源都部署在同一台服务器上即可。这样的架构既简单实用、便于维护，成本又低，成为了这个时代的主流架构方式。在 2003 年淘宝最初上线的时候，就是以一套当时十分风靡的 LAMP 架构（Linux+Apache+MySQL+PHP）实现并部署的。</p>
<p>单体应用架构的特点就是功能和代码集中、一个发布包部署后运行在一个进程内的应用程序。</p>
<h2 id="垂直应用架构"><a href="#垂直应用架构" class="headerlink" title="垂直应用架构"></a>垂直应用架构</h2><p>随着应用的发展，用户访问量逐渐增加，单台服务器性能及存储空间不足，因此服务器的压力在访问高峰期会上升到比较高，响应时间逐渐变长。这时，工程师们考虑增加几台服务器，将应用程序、数据库、文件分别部署在独立的资源上。一个大的单体应用被拆分成若干个小的单体应用，这就是垂直应用架构。这种拆分方法内含分治的思想，即将一个大的问题按一定业务规则分成若干个小的问题，逐个解决。</p>
<p>通过采用垂直应用架构，应用服务和数据服务得以分离，并发处理能力和数据存储空间得到了很大改善。</p>
<h2 id="使用缓存改善性能"><a href="#使用缓存改善性能" class="headerlink" title="使用缓存改善性能"></a>使用缓存改善性能</h2><p>将大的单体应用拆分后，对业务有所了解和调查的工程师们发现，系统访问的特点遵循二八定律，即 80% 的业务访问集中在 20% 的数据上。那么，使用缓存技术将这 20% 访问较集中的数据缓存下来，就有助于减少数据库的访问次数，降低数据库的访问压力。同时，引入缓存也有助于降低存储成本，因为缓存+数据库服务器可以承担原本需要多台数据库服务器才能承担的请求量，因此节省了机器成本。</p>
<p>缓存分为本地缓存（Local Cache）和远程分布式缓存（Remote Distributed Cache）。本地缓存访问速度更快，但内存资源以及承载能力有限，存在与应用程序争用内存的情况。因此，分布式缓存在如今的大型网站中得到广泛的使用。</p>
<h2 id="使用应用服务器集群-amp-负载均衡"><a href="#使用应用服务器集群-amp-负载均衡" class="headerlink" title="使用应用服务器集群 &amp; 负载均衡"></a>使用应用服务器集群 &amp; 负载均衡</h2><p>虽然做了这么多工作，但是请求量还是水涨船高。当请求量达到需要排队等待的规模时，即使单台应用服务器性能强大，处理请求速度很快，响应速度也依然会变慢。这时，工程师们就要考虑使用多台服务器所组成的集群，通过向集群中追加资源，提升系统的并发处理能力，解决单台服务器处理能力和存储空间上限的问题。</p>
<p>在数据中心内部，外部请求首先被定向到<strong>负载均衡器</strong>，以主机当前的负载作为函数来在主机之间负载均衡。其作为中继站向外部提供服务，使得服务器的负载压力不再成为整个系统的瓶颈。负载均衡器同时也进行外部 IP 地址和内部适当主机 IP 地址的互相转换，防止客户直接接触主机，从而具有隐藏网络内部结构和防止客户直接与主机交互等安全性益处。</p>
<p>负载均衡的策略包括：</p>
<ul>
<li><p>轮询：每一次来自网络的请求轮流分配给内部中的服务器，从 1 至 N 然后重新开始。此种均衡算法适合于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。实现简单，但存在服务器的处理能力不同的情况；</p>
</li>
<li><p>权重：根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。考虑了服务器处理能力的不足；</p>
</li>
<li><p>随机均衡：把来自网络的请求随机分配给内部中的多个服务器。</p>
</li>
</ul>
<p>反向代理也是负载均衡的一种方法。反向代理指隐藏了真实的服务端，帮用户把请求转发到真实的服务器那里去。Nginx 就是性能非常好的反向代理服务器，可以用来做负载均衡。它会将请求在读取完整之前缓冲，这样交给后端的就是一个完整的 HTTP 请求，而不是断断续续的传递（互联网上连接速度一般比较慢），以此减少网络 IO 次数，从而提高后端的效率。</p>
<h2 id="数据库读写分离"><a href="#数据库读写分离" class="headerlink" title="数据库读写分离"></a>数据库读写分离</h2><p>在一系列架构的增强后，用户量增加所带来的系统瓶颈可能转移到数据库上。每次读和写的操作都要经过同一个数据库服务器，在大量用户访问的情况下，资源竞争激烈。数据库的并发量有限，在保证数据库事务的 ACID 特性（原子性、一致性、隔离性和持久性）时难免发生阻塞。</p>
<p>为了保证数据库的高可用性，工程师们将数据库进行读写分离，写操作全部引入主库，读操作引入从库。这种做法极大程度地缓解了数据库锁之间的竞争，提高了并发吞吐量和负载能力。当然，读写分离架构适用的应用中，由于读库需要不断做批量的更新操作，读操作不应要求数据强一致，即对数据的实时性要求并没有那么高。</p>
<h2 id="CDN-加速和反向代理"><a href="#CDN-加速和反向代理" class="headerlink" title="CDN 加速和反向代理"></a>CDN 加速和反向代理</h2><p>鉴于网站的访问速度基于页面包含的内容传输到用户电脑的速度，如果用户到服务器的链路之间有一段比较缓慢的话，整体访问速度会受到很大的影响。因此，让用户从就近的服务器获取网页内容是一个理想的选择。</p>
<p>对于业务加载需要的一些不经常改变的静态数据（一般是 css 和 js 文件），可以考虑将其缓存到 CDN 服务器上，而不是每次都到应用服务器进行获取。CDN（内容分发网络）是运营商提供的服务，服务器部署在机房，可以根据用户访问的链路直接选择最近的 CDN 服务器，将已缓存的静态数据返回，以加快静态数据加载速度。这样可以减少服务器的压力，并解决不同地区访问速度差距较大的问题。</p>
<h2 id="分布式数据库"><a href="#分布式数据库" class="headerlink" title="分布式数据库"></a>分布式数据库</h2><p>就在工程师们忙碌的时候，数据量仍然随着业务的发展在悄无声息地增长。数据库读写分离最终也将无法满足业务需求，因此需要将数据库再次拆分。比较常用的数据库拆分手段是<strong>业务垂直分库</strong>，因为不同业务中表和表之间的数据大多没有关联，因此可以将不同的业务数据库部署在不同的物理服务器上。</p>
<p>如果单表数据规模非常庞大，还需要使用分布式数据库来支撑，即对这些表进行水平拆分，将同一个表中的数据拆分到两个甚至多个数据库中。</p>
<h2 id="使用-NoSQL-和搜索引擎"><a href="#使用-NoSQL-和搜索引擎" class="headerlink" title="使用 NoSQL 和搜索引擎"></a>使用 NoSQL 和搜索引擎</h2><p>随着业务越来越复杂，对数据存储和检索的需求也越来越复杂，系统需要采用一些非关系型数据库如 NoSQL 和分数据库查询技术如搜索引擎。应用服务器通过统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。</p>
<h2 id="业务拆分"><a href="#业务拆分" class="headerlink" title="业务拆分"></a>业务拆分</h2><p>为了应对日益复杂的业务场景，通常使用分而治之的手段将整个系统业务分成不同的产品线，应用之间通过超链接建立关系，也可以通过消息队列进行数据分发，当然更多的还是通过访问同一个数据存储系统来构成一个关联的完整系统。</p>
<p>业务拆分包括纵向拆分和横向拆分：</p>
<ul>
<li><p>纵向拆分：将一个大应用拆分为多个小应用，如果新业务较为独立，那么就直接将其设计部署为一个独立的 Web 应用系统。纵向拆分相对较为简单，通过梳理业务，将较少相关的业务剥离即可。</p>
</li>
<li><p>横向拆分：将复用的业务拆分出来，独立部署为分布式服务，新增业务只需要调用这些分布式服务。横向拆分需要识别可复用的业务，设计服务接口，规范服务依赖关系。</p>
</li>
</ul>
<h2 id="其他问题：异步、冗余、自动化"><a href="#其他问题：异步、冗余、自动化" class="headerlink" title="其他问题：异步、冗余、自动化"></a>其他问题：异步、冗余、自动化</h2><p>在漫长的演变过程中，除开以上，分布式系统的构建还有一些值得考虑的问题：</p>
<ul>
<li><p>异步：将一个复杂的业务操作转换为多个阶段操作，每个阶段的操作通过消息队列进行异步处理。可以理解为生产者-消费者模式，好处是加快系统响应速度和消除并发高峰。Node.js 正是因为其为异步而生，才逐渐成为服务端开发的选择之一。</p>
</li>
<li><p>冗余：为抵抗一些不可控因素，如自然灾害（火灾、地震）等因素导致系统不可用，应考虑异地建立容灾中心，实时备份数据。</p>
</li>
<li><p>自动化：自动化包括监控、告警、失效转移恢复、降级等功能，这些功能让系统在无人值守的情况下仍可以正常运行。</p>
</li>
</ul>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>每个小节看似容易理解，真正想要实现起来都是学问，更别谈考虑每个细节，选择最好的方式。之前看《淘宝技术这十年》，里面谈到淘宝作为中国互联网前几个称得上是超大规模的互联网系统，其发展历程中遇到了很多前人根本没有遇到过的问题。淘宝的一代代工程师们或主动或被动的开始进行一次次技术变革，这才造就了如今双十一每秒巨额的并发量。也因此，大麦、12306 等短时间要接受大量访问的网站时常瘫痪，也情有可原。架构是一门学问，想真正将每个环节都研究透彻，不是简简单单看几篇文章，做一个总结就够了的，需要和业务紧密结合。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://blog.csdn.net/yuxin6866/article/details/53038840" target="_blank" rel="external">分布式架构的演进，分析的很详细，很到位 - CSDN博客</a></li>
<li><a href="https://blog.csdn.net/world6/article/details/72803089?locationNum=12&amp;fps=1" target="_blank" rel="external">All-In-One到SOA的分布式架构演进 - CSDN博客</a></li>
<li><a href="https://blog.csdn.net/xinzun/article/details/79412150" target="_blank" rel="external">分布式系统漫谈【壹】_发展历程 - CSDN博客</a></li>
<li><a href="https://www.zhihu.com/question/60199333" target="_blank" rel="external">为什么数据库读写分离能提高数据库的性能？ - 知乎</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;“网络与分布式计算”课程布置了一个作业，要求写一篇题目为“构建分布式系统技术发展历史”的小论文。我个人以为“历史”二字应该是要我们去了解每项技术诞生的时间点，然而踏破铁鞋无处可觅。最后写成的文章主题，我个人认为比起“历史”来说，“演进过程”可能更为恰当。&lt;/p&gt;
&lt;p&gt;事实上我们可能也更为注重演进过程，因为分布式系统的演进过程，就是一代代工程师们对抗随时代和应用自身发展而逐渐升高的访问量的一部血泪史。这个过程是每一个健康发展的网站都要经历的。&lt;/p&gt;
&lt;p&gt;这次作业也给了我一个机会，去大致了解网站在发展过程中为了提升性能、简化部署、弹性扩展而做出的种种措施，受益匪浅。因此将文章放到博客上。&lt;/p&gt;
    
    </summary>
    
      <category term="架构笔记" scheme="http://kyonhuang.top/categories/%E6%9E%B6%E6%9E%84%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="分布式系统" scheme="http://kyonhuang.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="分布式架构" scheme="http://kyonhuang.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>数据清理 5 天挑战</title>
    <link href="http://kyonhuang.top/5-days-data-cleaning/"/>
    <id>http://kyonhuang.top/5-days-data-cleaning/</id>
    <published>2018-03-30T03:14:21.000Z</published>
    <updated>2018-03-30T03:16:25.120Z</updated>
    
    <content type="html"><![CDATA[<p>偶然看到了 Kaggle 的数据清理 5 天挑战，大致看了一下，还是比较实用的。因此全部做完后记录一下。不是很想在无谓的整理上花太多时间，因此各类标题直接使用原文中的英文标题，用于串联内容的文字较少，且代码不一定完整（主要是缺少导入包和数据的语句）。如果你希望能够全面地了解这 5 次挑战的内容，以下是 Kaggle 上原 kernel 的地址：</p>
<ul>
<li>Day 1: <a href="https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values" target="_blank" rel="external">Data Cleaning Challenge: Handling missing values | Kaggle</a></li>
<li>Day 2: <a href="https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data" target="_blank" rel="external">Data Cleaning Challenge: Scale and Normalize Data | Kaggle</a></li>
<li>Day 3: <a href="https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/" target="_blank" rel="external">Data Cleaning Challenge: Parsing Dates | Kaggle</a></li>
<li>Day 4: <a href="https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/" target="_blank" rel="external">Data Cleaning Challenge: Character Encodings | Kaggle</a></li>
<li>Day 5: <a href="https://www.kaggle.com/rtatman/data-cleaning-challenge-inconsistent-data-entry" target="_blank" rel="external">Data Cleaning Challenge: Inconsistent Data Entry | Kaggle</a></li>
</ul>
<a id="more"></a>
<h2 id="Handling-missing-values"><a href="#Handling-missing-values" class="headerlink" title="Handling missing values"></a>Handling missing values</h2><h3 id="Take-a-first-look-at-the-data"><a href="#Take-a-first-look-at-the-data" class="headerlink" title="Take a first look at the data"></a>Take a first look at the data</h3><p>看一下数据的前几行有没有缺失值。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">nfl_data.sample(<span class="number">5</span>)</div><div class="line"><span class="comment"># 使用 nfl_data.head() 效果相同</span></div></pre></td></tr></table></figure>
<h4 id="See-how-many-missing-data-points-we-have"><a href="#See-how-many-missing-data-points-we-have" class="headerlink" title="See how many missing data points we have"></a>See how many missing data points we have</h4><p>统计每种属性包含的缺失值的数量：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># get the number of missing data points per column</span></div><div class="line">missing_values_count = nfl_data.isnull().sum()</div><div class="line"></div><div class="line"><span class="comment"># look at the # of missing points in the first ten columns</span></div><div class="line">missing_values_count[<span class="number">0</span>:<span class="number">10</span>]</div></pre></td></tr></table></figure>
<p>看一看缺失值占总体数量的百分比：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># how many total missing values do we have?</span></div><div class="line">total_cells = np.product(nfl_data.shape)</div><div class="line">total_missing = missing_values_count.sum()</div><div class="line"></div><div class="line"><span class="comment"># percent of data that is missing</span></div><div class="line">(total_missing/total_cells) * <span class="number">100</span></div></pre></td></tr></table></figure>
<h4 id="Figure-out-why-the-data-is-missing"><a href="#Figure-out-why-the-data-is-missing" class="headerlink" title="Figure out why the data is missing"></a>Figure out why the data is missing</h4><p>分析数据缺失的原因以及缺失对数据分析所造成的影响被称为<strong>“data intution”</strong>，决定了是否需要填充该缺失，以及填充的策略。</p>
<p>面对数据缺失，一个必须要考虑的问题是：</p>
<blockquote>
<p>某个数据的缺失是因为它没有被记录还是根本不存在？</p>
</blockquote>
<p>对于根本不存在的缺失数据，没有必要对其进行操作；而没有被记录的缺失值，则应该基于同行同列的其他值来猜想其可能的值，尝试进行填充。</p>
<p>例如，<code>Street Number Suffix</code>应该是其本身不存在，而<code>Zipcode</code>则应该是没有记录。</p>
<h3 id="Drop-missing-values"><a href="#Drop-missing-values" class="headerlink" title="Drop missing values"></a>Drop missing values</h3><p>移除包含缺失值的<strong>行</strong>是可行的，但是如果缺失值较多且分布较散，可能导致所有的数据全部被移除：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nfl_data.dropna()</div></pre></td></tr></table></figure>
<p>也可以移除包含至少一个缺失值的<strong>列</strong>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">columns_with_na_dropped = nfl_data.dropna(axis=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<h3 id="Filling-in-missing-values-automatically"><a href="#Filling-in-missing-values-automatically" class="headerlink" title="Filling in missing values automatically"></a>Filling in missing values automatically</h3><p>将某个数值型属性的缺失值全部补 0：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># get a small subset of the NFL dataset</span></div><div class="line">subset_nfl_data = nfl_data.loc[:, <span class="string">'EPA'</span>:<span class="string">'Season'</span>].head()</div><div class="line">subset_nfl_data</div></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># replace all NA's with 0</span></div><div class="line">subset_nfl_data.fillna(<span class="number">0</span>)</div></pre></td></tr></table></figure>
<p>若存在字符串类型的数据，也可以通过<code>method = &#39;bfill&#39;</code>，选择将空值置为与它相邻的下一行对应的数据，没有下一行数据就置为 0：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># replace all NA's the value that comes directly after it in the same column, </span></div><div class="line"><span class="comment"># then replace all the reamining na's with 0</span></div><div class="line">subset_nfl_data.fillna(method = <span class="string">'bfill'</span>, axis=<span class="number">0</span>).fillna(<span class="number">0</span>)</div></pre></td></tr></table></figure>
<h2 id="Scale-and-Normalize-Data"><a href="#Scale-and-Normalize-Data" class="headerlink" title="Scale and Normalize Data"></a>Scale and Normalize Data</h2><p>主要搞清两个概念：</p>
<ul>
<li>scaling（缩放）: change the <strong>range</strong> of data</li>
<li>normalize（标准化）: change the <strong>shape of the distribution</strong> of data，即将数据尽可能地描述为正态分布。常用于 t-tests, ANOVAs, linear regression, linear discriminant analysis (LDA) and Gaussian naive Bayes</li>
</ul>
<h3 id="import-packages"><a href="#import-packages" class="headerlink" title="import packages"></a>import packages</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># for Box-Cox Transformation</span></div><div class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</div><div class="line"></div><div class="line"><span class="comment"># for min_max scaling</span></div><div class="line"><span class="keyword">from</span> mlxtend.preprocessing <span class="keyword">import</span> minmax_scaling</div><div class="line"></div><div class="line"><span class="comment"># plotting modules</span></div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div></pre></td></tr></table></figure>
<h3 id="Scale"><a href="#Scale" class="headerlink" title="Scale"></a>Scale</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># select the usd_goal_real column</span></div><div class="line">usd_goal = kickstarters_2017.usd_goal_real</div><div class="line"></div><div class="line"><span class="comment"># scale the goals from 0 to 1</span></div><div class="line">scaled_data = minmax_scaling(usd_goal, columns = [<span class="number">0</span>])</div><div class="line"></div><div class="line"><span class="comment"># plot the original &amp; scaled data together to compare</span></div><div class="line">fig, ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>)</div><div class="line">sns.distplot(kickstarters_2017.usd_goal_real, ax=ax[<span class="number">0</span>])</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">"Original Data"</span>)</div><div class="line">sns.distplot(scaled_data, ax=ax[<span class="number">1</span>])</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">"Scaled data"</span>)</div></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/18595460/38077516-c4b4a1c0-336b-11e8-9f14-8cdbf6ec6919.png" alt="scale"></p>
<h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>使用 Box-Cox 转换法：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># get the index of all positive pledges (Box-Cox only takes postive values)</span></div><div class="line">index_of_positive_pledges = kickstarters_2017.usd_pledged_real &gt; <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment"># get only positive pledges (using their indexes)</span></div><div class="line">positive_pledges = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]</div><div class="line"></div><div class="line"><span class="comment"># normalize the pledges (w/ Box-Cox)</span></div><div class="line">normalized_pledges = stats.boxcox(positive_pledges)[<span class="number">0</span>]</div><div class="line"></div><div class="line"><span class="comment"># plot both together to compare</span></div><div class="line">fig, ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>)</div><div class="line">sns.distplot(positive_pledges, ax=ax[<span class="number">0</span>])</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">"Original Data"</span>)</div><div class="line">sns.distplot(normalized_pledges, ax=ax[<span class="number">1</span>])</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">"Normalized data"</span>)</div></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/18595460/38077612-1e69eb80-336c-11e8-8783-7cd178cfecef.png" alt="normalize"></p>
<h2 id="Parsing-Dates"><a href="#Parsing-Dates" class="headerlink" title="Parsing Dates"></a>Parsing Dates</h2><h3 id="Get-our-environment-set-up"><a href="#Get-our-environment-set-up" class="headerlink" title="Get our environment set up"></a>Get our environment set up</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> datetime</div></pre></td></tr></table></figure>
<h3 id="Check-the-data-type-of-our-date-column"><a href="#Check-the-data-type-of-our-date-column" class="headerlink" title="Check the data type of our date column"></a>Check the data type of our date column</h3><p>pandas 用<code>object</code>表示各类数据类型，一般含有字符串。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">landslides[<span class="string">'date'</span>].dtype</div><div class="line"><span class="comment"># dtype('O')</span></div><div class="line"><span class="comment"># 'O' 表示 'object'</span></div></pre></td></tr></table></figure>
<h3 id="Convert-our-date-columns-to-datetime"><a href="#Convert-our-date-columns-to-datetime" class="headerlink" title="Convert our date columns to datetime"></a>Convert our date columns to datetime</h3><p>将字符串转化为 datetime 时，要注明原字符串在表示日期时所遵循的格式，例如：</p>
<ul>
<li>1/17/07 has the format “%m/%d/%y”</li>
<li>17-1-2007 has the format “%d-%m-%Y”</li>
</ul>
<p>可以看到，<code>%y</code>代表 2 个数字表示的年份，<code>%Y</code>代表 4 个数字表示的年份。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">landslides[<span class="string">'date_parsed'</span>] = pd.to_datetime(landslides[<span class="string">'date'</span>], format = <span class="string">"%m/%d/%y"</span>)</div></pre></td></tr></table></figure>
<p>补充：由于数据中还有个别不是 “month/day/four-digit year” 格式，直接转换的话会报错，Pandas 提供了一个可选的参数 errors，传入 errors=’coerce’，当遇到不能转换的数据就会将其置为 NaN，我们之后再对其进行手工处理。但如果我们不设定 format，这个错误就会被忽略，不过就无法得到特定格式的日期数据了，可能影响之后分析工作。详见<a href="https://zhuanlan.zhihu.com/p/35058099" target="_blank" rel="external">Kaggle 数据清洗挑战 Day 3 - 快速解析日期（date）数据</a></p>
<h3 id="Select-just-the-day-of-the-month-from-our-column"><a href="#Select-just-the-day-of-the-month-from-our-column" class="headerlink" title="Select just the day of the month from our column"></a>Select just the day of the month from our column</h3><p>在处理后的数据中按 month 选取 day：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">day_of_month_landslides = landslides[<span class="string">'date_parsed'</span>].dt.day</div></pre></td></tr></table></figure>
<h3 id="Plot-the-day-of-the-month-to-check-the-date-parsing"><a href="#Plot-the-day-of-the-month-to-check-the-date-parsing" class="headerlink" title="Plot the day of the month to check the date parsing"></a>Plot the day of the month to check the date parsing</h3><p>可视化，用于确认没有搞混“月“和”日“：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># remove na's</span></div><div class="line">day_of_month_landslides = day_of_month_landslides.dropna()</div><div class="line"></div><div class="line"><span class="comment"># plot the day of the month</span></div><div class="line">sns.distplot(day_of_month_landslides, kde=<span class="keyword">False</span>, bins=<span class="number">31</span>)</div></pre></td></tr></table></figure>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p><a href="https://www.kaggle.com/residentmario/time-series-plotting-optional" target="_blank" rel="external">时间序列可视化</a></p>
<h2 id="Character-Encodings"><a href="#Character-Encodings" class="headerlink" title="Character Encodings"></a>Character Encodings</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># helpful character encoding module</span></div><div class="line"><span class="keyword">import</span> chardet</div></pre></td></tr></table></figure>
<h3 id="What-are-encodings"><a href="#What-are-encodings" class="headerlink" title="What are encodings?"></a>What are encodings?</h3><p>UTF-8 天下第一！</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># start with a string</span></div><div class="line">before = <span class="string">"This is the euro symbol: €"</span></div><div class="line"></div><div class="line"><span class="comment"># check to see what datatype it is</span></div><div class="line">type(before)</div><div class="line"><span class="comment">#str</span></div></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">after = before.encode(<span class="string">"utf-8"</span>, errors = <span class="string">"replace"</span>)</div><div class="line"></div><div class="line"><span class="comment"># check the type</span></div><div class="line">type(after)</div><div class="line"><span class="comment"># bytes</span></div><div class="line"></div><div class="line"><span class="comment"># take a look at what the bytes look like</span></div><div class="line">after</div><div class="line"><span class="comment"># b'This is the euro symbol: \xe2\x82\xac'</span></div></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># convert it back to utf-8</span></div><div class="line">print(after.decode(<span class="string">"utf-8"</span>))</div><div class="line"><span class="comment"># This is the euro symbol: €</span></div></pre></td></tr></table></figure>
<h3 id="Reading-in-files-with-encoding-problems"><a href="#Reading-in-files-with-encoding-problems" class="headerlink" title="Reading in files with encoding problems"></a>Reading in files with encoding problems</h3><p>读取非 UTF-8 编码的文件会出错。先试着读取前几行看一下能不能判断编码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># look at the first ten thousand bytes to guess the character encoding</span></div><div class="line"><span class="keyword">with</span> open(<span class="string">"../input/kickstarter-projects/ks-projects-201801.csv"</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> rawdata:</div><div class="line">    result = chardet.detect(rawdata.read(<span class="number">10000</span>))</div><div class="line"></div><div class="line"><span class="comment"># check what the character encoding might be</span></div><div class="line">print(result)</div></pre></td></tr></table></figure>
<p>判断为 Windows-1252 编码。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># read in the file with the encoding detected by chardet</span></div><div class="line">kickstarter_2016 = pd.read_csv(<span class="string">"../input/kickstarter-projects/ks-projects-201612.csv"</span>, encoding=<span class="string">'Windows-1252'</span>)</div><div class="line"></div><div class="line"><span class="comment"># look at the first few lines</span></div><div class="line">kickstarter_2016.head()</div></pre></td></tr></table></figure>
<h3 id="Saving-your-files-with-UTF-8-encoding"><a href="#Saving-your-files-with-UTF-8-encoding" class="headerlink" title="Saving your files with UTF-8 encoding"></a>Saving your files with UTF-8 encoding</h3><p>默认以 UTF-8 编码保存。</p>
<h2 id="Inconsistent-Data-Entry"><a href="#Inconsistent-Data-Entry" class="headerlink" title="Inconsistent Data Entry"></a>Inconsistent Data Entry</h2><p>将包括加了空格、大小写不一致、个别拼写错误等类型的不同值整理为一致。</p>
<h3 id="Import"><a href="#Import" class="headerlink" title="Import"></a>Import</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> fuzzywuzzy</div><div class="line"><span class="keyword">from</span> fuzzywuzzy <span class="keyword">import</span> process</div><div class="line"><span class="keyword">import</span> chardet</div></pre></td></tr></table></figure>
<h3 id="Do-some-preliminary-text-pre-processing"><a href="#Do-some-preliminary-text-pre-processing" class="headerlink" title="Do some preliminary text pre-processing"></a>Do some preliminary text pre-processing</h3><p>看一看有哪些值：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># get all the unique values in the 'City' column</span></div><div class="line">cities = suicide_attacks[<span class="string">'City'</span>].unique()</div><div class="line"></div><div class="line"><span class="comment"># sort them alphabetically and then take a closer look</span></div><div class="line">cities.sort()</div><div class="line">cities</div></pre></td></tr></table></figure>
<p>去空格、全部调小写：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># convert to lower case</span></div><div class="line">suicide_attacks[<span class="string">'City'</span>] = suicide_attacks[<span class="string">'City'</span>].str.lower()</div><div class="line"><span class="comment"># remove trailing white spaces</span></div><div class="line">suicide_attacks[<span class="string">'City'</span>] = suicide_attacks[<span class="string">'City'</span>].str.strip()</div></pre></td></tr></table></figure>
<h3 id="Use-fuzzy-matching-to-correct-inconsistent-data-entry"><a href="#Use-fuzzy-matching-to-correct-inconsistent-data-entry" class="headerlink" title="Use fuzzy matching to correct inconsistent data entry"></a>Use fuzzy matching to correct inconsistent data entry</h3><p><code>fuzzywuzzy</code>包可以帮助辨认那些拼写接近的字符串。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># get the top 10 closest matches to "d.i khan"</span></div><div class="line">matches = fuzzywuzzy.process.extract(<span class="string">"d.i khan"</span>, cities, limit=<span class="number">10</span>, scorer=fuzzywuzzy.fuzz.token_sort_ratio)</div><div class="line"></div><div class="line"><span class="comment"># take a look at them</span></div><div class="line">matches</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">[('d. i khan', 100),</div><div class="line"> ('d.i khan', 100),</div><div class="line"> ('d.g khan', 88),</div><div class="line"> ('khanewal', 50),</div><div class="line"> ('sudhanoti', 47),</div><div class="line"> ('hangu', 46),</div><div class="line"> ('kohat', 46),</div><div class="line"> ('dara adam khel', 45),</div><div class="line"> ('chaman', 43),</div><div class="line"> ('mardan', 43)]</div><div class="line">'''</div></pre></td></tr></table></figure>
<p>可以考虑写一个函数做总体的转化：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># function to replace rows in the provided column of the provided dataframe</span></div><div class="line"><span class="comment"># that match the provided string above the provided ratio with the provided string</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">replace_matches_in_column</span><span class="params">(df, column, string_to_match, min_ratio = <span class="number">90</span>)</span>:</span></div><div class="line">    <span class="comment"># get a list of unique strings</span></div><div class="line">    strings = df[column].unique()</div><div class="line">    </div><div class="line">    <span class="comment"># get the top 10 closest matches to our input string</span></div><div class="line">    matches = fuzzywuzzy.process.extract(string_to_match, strings, </div><div class="line">                                         limit=<span class="number">10</span>, scorer=fuzzywuzzy.fuzz.token_sort_ratio)</div><div class="line"></div><div class="line">    <span class="comment"># only get matches with a ratio &gt; 90</span></div><div class="line">    close_matches = [matches[<span class="number">0</span>] <span class="keyword">for</span> matches <span class="keyword">in</span> matches <span class="keyword">if</span> matches[<span class="number">1</span>] &gt;= min_ratio]</div><div class="line"></div><div class="line">    <span class="comment"># get the rows of all the close matches in our dataframe</span></div><div class="line">    rows_with_matches = df[column].isin(close_matches)</div><div class="line"></div><div class="line">    <span class="comment"># replace all rows with close matches with the input matches </span></div><div class="line">    df.loc[rows_with_matches, column] = string_to_match</div><div class="line">    </div><div class="line">    <span class="comment"># let us know the function's done</span></div><div class="line">    print(<span class="string">"All done!"</span>)</div></pre></td></tr></table></figure>
<p>之后只需要对那些疑似相同的字符串逐个调用该函数即可：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># use the function we just wrote to replace close matches to "d.i khan" with "d.i khan"</span></div><div class="line">replace_matches_in_column(df=suicide_attacks, column=<span class="string">'City'</span>, string_to_match=<span class="string">"d.i khan"</span>)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;偶然看到了 Kaggle 的数据清理 5 天挑战，大致看了一下，还是比较实用的。因此全部做完后记录一下。不是很想在无谓的整理上花太多时间，因此各类标题直接使用原文中的英文标题，用于串联内容的文字较少，且代码不一定完整（主要是缺少导入包和数据的语句）。如果你希望能够全面地了解这 5 次挑战的内容，以下是 Kaggle 上原 kernel 的地址：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Day 1: &lt;a href=&quot;https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Data Cleaning Challenge: Handling missing values | Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Day 2: &lt;a href=&quot;https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Data Cleaning Challenge: Scale and Normalize Data | Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Day 3: &lt;a href=&quot;https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Data Cleaning Challenge: Parsing Dates | Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Day 4: &lt;a href=&quot;https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Data Cleaning Challenge: Character Encodings | Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Day 5: &lt;a href=&quot;https://www.kaggle.com/rtatman/data-cleaning-challenge-inconsistent-data-entry&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Data Cleaning Challenge: Inconsistent Data Entry | Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="数据科学笔记" scheme="http://kyonhuang.top/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://kyonhuang.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="数据科学" scheme="http://kyonhuang.top/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
      <category term="数据清理" scheme="http://kyonhuang.top/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>记 CIPS 青工委武汉大学系列讲座</title>
    <link href="http://kyonhuang.top/whu-CIPS-academic-salon/"/>
    <id>http://kyonhuang.top/whu-CIPS-academic-salon/</id>
    <published>2018-03-24T11:39:29.000Z</published>
    <updated>2018-05-10T15:53:02.236Z</updated>
    
    <content type="html"><![CDATA[<p>趁着余兴未尽，来将今天早上参加的讲座记录一下。很幸运周四在教学楼下看到了这次活动的海报。本次系列讲座是 CIPS 青工委（中国中文信息学会青年工作委员会）在武汉大学的一次活动，主持人是武大的李晨亮老师，嘉宾包括清华的刘洋老师、刘知远老师、张敏老师，天津大学的张鹏老师和北大的严睿老师。五名老师在其所关注的细分领域各有建树，全是自然语言处理和信息检索领域的大牛。接下来以老师报告的顺序大概介绍一下各位老师的报告内容，和我对各位老师的感受。因为我忘记带拍照用的手机了，因此没有照片，而且笔记也不完整，部分理解可能有偏差，尽请见谅。</p>
<p>2018.04.03 更新：更新上周五中科院自动化所刘康老师的讲座笔记。</p>
<a id="more"></a>
<h2 id="刘洋《基于深度学习的机器翻译》"><a href="#刘洋《基于深度学习的机器翻译》" class="headerlink" title="刘洋《基于深度学习的机器翻译》"></a>刘洋《基于深度学习的机器翻译》</h2><p>首先是委员会主任刘洋老师的报告。PPT 与他主页上 <a href="http://nlp.csai.tsinghua.edu.cn/~ly/talks/cwmt2016_ly_v3_160826.pptx" target="_blank" rel="external">Advances in Neural Machne Translation</a> 的内容有 70% 是一致的，可以据此了解一下。</p>
<p>刘洋老师主要介绍了机器翻译的发展，从规则机器翻译 -&gt; 统计机器翻译 -&gt; 神经机器翻译，人们关注的重点也从规则到特征，最后变到架构。他认为神经机器翻译的可研究方向还包括架构学习（让机器学习架构来得到表现更好的，而非人类手工调整）、先验知识融合、单词学习、高效算法、可解释性等等。</p>
<p>总体来说，刘洋老师的报告是五场报告中最容易理解的，他在其中加入了很多例子帮助理解，而非一味堆积 paper 成果。</p>
<p>有观众提出问题，认为目前的机器翻译还缺少和人的感觉相配的评价指标。例如，如果机器将人名翻译错误，相似度降低很少，但是用户的使用体验就很差。另外，机器翻译用于商业时达成度不够。刘洋老师也认同目前存在这问题。</p>
<p>刘洋老师真人比主页上的照片看起来帅一些，年轻一些。另外，坐在我前面一排的小朋友应该是刘洋老师的儿子，整个讲座过程中都非常安静，很难得，也显出刘洋老师家教有方。</p>
<h2 id="严睿《人工智能在人机对话系统中的技术现状与挑战》"><a href="#严睿《人工智能在人机对话系统中的技术现状与挑战》" class="headerlink" title="严睿《人工智能在人机对话系统中的技术现状与挑战》"></a>严睿《人工智能在人机对话系统中的技术现状与挑战》</h2><p>严睿老师主要介绍了人机对话的一些现状，包括：</p>
<ul>
<li><p>分类：</p>
<ul>
<li>按领域：开放领域 / 垂直领域：医疗、金融、法律…</li>
<li>按回复方式：检索式（目前业界主流） / 生成式（下一代潮流：深度学习加持） / 综合式</li>
<li>主动 / 被动</li>
<li>…</li>
</ul>
</li>
<li><p>算法：</p>
<ul>
<li>上下文信息</li>
<li>知识库信息（世界知识）</li>
<li>语意逻辑信息 </li>
</ul>
</li>
<li><p>挑战：</p>
<ul>
<li>源自人类认知直觉的剖析</li>
<li>相关性、趣味性、信息量、情感化</li>
</ul>
</li>
</ul>
<p>另外，介绍了较多的 paper 的工作。</p>
<p>严睿老师语速比较快，给我的感觉是思路很活跃。另外，讲完后不久他就离场了，不知道是不是去看樱花去了，哈哈。</p>
<h2 id="张敏《用户满意的异质可解释的推荐：THUIR工作进展》"><a href="#张敏《用户满意的异质可解释的推荐：THUIR工作进展》" class="headerlink" title="张敏《用户满意的异质可解释的推荐：THUIR工作进展》"></a>张敏《用户满意的异质可解释的推荐：THUIR工作进展》</h2><p>张敏老师主要介绍了自己所在的 THUIR 研究组对于推荐系统的一些工作，包括：</p>
<ol>
<li>可解释推荐。</li>
<li>时间对推荐的影响（也算是可解释性）：ARIMA 时间序列模型。</li>
<li>社会关系对推荐的影响（抑制的信息）：不认识不代表负类，而是在之后会认识的概率上在进行标识。并且也使用了迁移学习。</li>
<li>用户满意度：多样性 vs 满意度。</li>
<li>用户理解：群体推荐的公平性和满意度。</li>
</ol>
<p>张敏老师的工作应该是五场报告中我最感兴趣的。活动后我斗胆去询问她是否还有学硕或者直博的名额，可惜她的名额已经满了（抢手到可怕），让我给她发邮件看研究组里另外两位老师是否还有名额。（更新：张老师课题组名额全满了）</p>
<h2 id="张鹏《量子力学启发的信息检索和自然语言处理》"><a href="#张鹏《量子力学启发的信息检索和自然语言处理》" class="headerlink" title="张鹏《量子力学启发的信息检索和自然语言处理》"></a>张鹏《量子力学启发的信息检索和自然语言处理》</h2><p>张鹏老师研究的问题比较新颖，将深度学习和量子计算结合起来。他所在的 TJU’s Quantum IR/NLP group 应该在这方面做了不少工作，但是我们可能就对这个方向不是很了解了。讲着讲着薛定谔的猫也出来了，有点懵…唯一一个报告完后没有学生提问的。老师人还是很和蔼的。</p>
<h2 id="刘知远《知识表示学习及其应用》"><a href="#刘知远《知识表示学习及其应用》" class="headerlink" title="刘知远《知识表示学习及其应用》"></a>刘知远《知识表示学习及其应用》</h2><p>最后是知乎网红刘知远老师。PPT 和他主页上的<a href="http://thunlp.org/~lzy/talks/nrl2017.pdf" target="_blank" rel="external">社会计算与表示学习</a> 前一半内容基本相同，后一半是介绍自己的近期工作。</p>
<p>刘老师首先介绍了知识图谱实体与关系。知识图谱的典型表示方案是基于符号表示的三元组（RDF），但是无法有效计算实体间的语义关系，解决方案是将知识映射到低维向量空间。</p>
<p>之后，介绍了 TransE：将关系表示为从 head 到 tail 的翻译操作，和融合文本和知识进行关系抽取等。具体内容可以看 PPT，个人水平有限，难以总结。</p>
<p>老师目前主要关注大规模知识图谱的应用，包括关系抽取、实体对齐（不同领域的知识图谱的结合）、实体分类等。介绍了开源平台：<a href="http://openke.thunlp.org/" target="_blank" rel="external">http://openke.thunlp.org/</a>。顺便一提，刘老师凌晨两点发了一条微博，表示整理了自己的一些工作，开源了相关代码，赞！</p>
<p>未来工作方向：</p>
<ul>
<li>利用表示学习技术将知识图谱用于相关领域（信息检索、推荐系统）</li>
<li>利用表示学习技术改进知识获取能力（富语境信息抽取、开放关系抽取、开放事件抽取）</li>
</ul>
<p>刘知远老师在知乎上对于学术科研写了不少回答，对我很有帮助。个人关注了他的微博和知乎。不过现场感觉刘老师比知乎上给人的感觉要更有威慑力一些…</p>
<h2 id="刘康《基于弱标注的大规模知识抽取》"><a href="#刘康《基于弱标注的大规模知识抽取》" class="headerlink" title="刘康《基于弱标注的大规模知识抽取》"></a>刘康《基于弱标注的大规模知识抽取》</h2><p>在第一次讲座后一周，中科院自动化所的刘康老师也来到武大，对知识抽取的现状以及研究组在这方面的工作进行了介绍。以下是一个比较抽象的笔记：</p>
<p>非结构化文本 =&gt; 知识</p>
<p>知识图谱类型：</p>
<ol>
<li>实体 - 实体(三元组) 头实体-关系-尾实体</li>
<li>事件为中心：可能有一个事件和多个实体</li>
</ol>
<p>构建知识图谱：</p>
<ul>
<li>关系抽取 / 事件抽取：动词作为触发词    挑战：开放的关系</li>
<li><ol>
<li>在一句话中确定两个实体的关系（和分类任务相似）</li>
</ol>
</li>
<li><ol>
<li>不给定具体上下文，要求一对实体的关系（方法：在文本中回标）</li>
</ol>
</li>
</ul>
<p>特征表示：</p>
<ul>
<li>用 DL（CNN）</li>
<li>刘老师的工作：<ul>
<li>Position Embeddings：记录实体的相对位置 </li>
<li>Dynamic Multi-Pooling and Piece-wise MaxPooling：每一段做一个最大池化</li>
</ul>
</li>
</ul>
<p>自动标注大量训练数据：</p>
<ul>
<li>回标：将已找到的实体三元组在文本中回找，所有对应的语句都可以当作正样本 =&gt; 问题：关系可能不一样</li>
<li>以上策略不能用于以事件为中心的知识：找不到事件所具体对应的字符串</li>
<li>动词作为触发词，找其他实体 =&gt; 问题：在一句话中不会有全部的实体 =&gt; 找关键的 arguments（实体） =&gt; 如何找 key arguments？TF-IDF、相似度…</li>
</ul>
<p>训练策略：如何减少噪声的影响？</p>
<ul>
<li>Multi-Instance Learning</li>
<li>Attention </li>
<li>transE：三元组中，实体为点，关系为向量</li>
</ul>
<p>最新的工作：强化学习</p>
<p>落地：从金融、法律公告中抽取结构化的知识</p>
<ul>
<li>文本分类（分析具体是哪种类型的事件 -&gt; Event Identification -&gt; 没记下来…</li>
</ul>
<p>老师展示了一个根据以上想法已经成型的 Web 应用。</p>
<h2 id="总体感受"><a href="#总体感受" class="headerlink" title="总体感受"></a>总体感受</h2><p>各位老师都介绍了各自研究的领域、面临的问题以及目前的一些工作，让我能够在走上学术之路前能够充分了解自然语言处理和信息检索的一些研究方向，对我有很大的启发。</p>
<p>现场的人数还是比较多的，临时换了一个更大的教室。刘知远老师报告时统计了一下在场的本科生，包括我在内的大约 10 人。让我没有想到的是，在场很多的研究生确实对不同老师的方向各有见解，提出了比较有深度的问题。武大啥时候冒出这么多自然语言处理方向的研究生啊，以前完全不知道，原来计院卧虎藏龙。</p>
<p>也不知道该怎么结束这篇博文了。给大家欣赏一下我下午摄影实习照的樱花好了。</p>
<p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/sakura/1.jpg"></p>
<p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/sakura/2.jpg"></p>
<p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/sakura/3.jpg"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;趁着余兴未尽，来将今天早上参加的讲座记录一下。很幸运周四在教学楼下看到了这次活动的海报。本次系列讲座是 CIPS 青工委（中国中文信息学会青年工作委员会）在武汉大学的一次活动，主持人是武大的李晨亮老师，嘉宾包括清华的刘洋老师、刘知远老师、张敏老师，天津大学的张鹏老师和北大的严睿老师。五名老师在其所关注的细分领域各有建树，全是自然语言处理和信息检索领域的大牛。接下来以老师报告的顺序大概介绍一下各位老师的报告内容，和我对各位老师的感受。因为我忘记带拍照用的手机了，因此没有照片，而且笔记也不完整，部分理解可能有偏差，尽请见谅。&lt;/p&gt;
&lt;p&gt;2018.04.03 更新：更新上周五中科院自动化所刘康老师的讲座笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="讲座心得记录" scheme="http://kyonhuang.top/categories/%E8%AE%B2%E5%BA%A7%E5%BF%83%E5%BE%97%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="自然语言处理" scheme="http://kyonhuang.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="讲座" scheme="http://kyonhuang.top/tags/%E8%AE%B2%E5%BA%A7/"/>
    
      <category term="CIPS 青工委" scheme="http://kyonhuang.top/tags/CIPS-%E9%9D%92%E5%B7%A5%E5%A7%94/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle Titanic 生存预测--特征工程</title>
    <link href="http://kyonhuang.top/kaggle-titanic-1/"/>
    <id>http://kyonhuang.top/kaggle-titanic-1/</id>
    <published>2018-02-26T11:12:03.000Z</published>
    <updated>2018-06-21T14:19:14.690Z</updated>
    
    <content type="html"><![CDATA[<p>注册著名的数据科学竞赛平台 Kaggle 四个多月了，当初是为了要一份数据集，而一直没有参加比赛。这个寒假终于按耐不住，决定拿入门级的 Titanic: Machine Learning from Disaster 打响革命第一枪。</p>
<p>Titanic 生存预测比赛是一个二分类问题。题目提供了一份乘客名单，包含了乘客的名字、性别、年龄、船票等级等信息，以及是否成功获救的标记，最终需要提交一份对测试集中的乘客是否成功获救的 csv 文件。</p>
<p>经过了四次提交，最后我的 Public Score 暂时定格在 0.80861，这个成绩目前在前 7%。这篇博文主要简述一下我所做的尝试和改进，并对最后一次换用 XGBoost 所得到的最好成绩的代码进行一个详细的说明，也是对相似题目处理流程的一个总结。</p>
<p><img src="/images/Titanic-public-score.jpg" alt="Titanic-public-score"></p>
<a id="more"></a>
<h2 id="过程简述"><a href="#过程简述" class="headerlink" title="过程简述"></a>过程简述</h2><h3 id="第一次提交"><a href="#第一次提交" class="headerlink" title="第一次提交"></a>第一次提交</h3><p>在探索数据后，我决定选用以下特征进行预测<code>&#39;Pclass&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;Embarked&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;</code>。其中 Age、Embarked 和 Fare 有缺失，考虑使用出现频率最高的值来填充 Embarked 特征（类别型）的缺失值，使用平均值来填充 Age 和 Fare 特征（数值型）的缺失值。而类别特征不能直接作为输入，因此采用 DictVectorizer 对特征抽取和特征向量化。</p>
<p>最后使用 RandomForest 分类器来进行预测。Public Score 为 0.73205。</p>
<h3 id="第二次提交"><a href="#第二次提交" class="headerlink" title="第二次提交"></a>第二次提交</h3><p>Fare 只有一个缺失，而 Age 存在 86 个缺失值。因此，直接使用平均值来填充 Age 的缺失值可能对预测结果影响较大。我将 Age 从选取的有效特征中剔除，其他不变，Public Score 提高到 0.75598。</p>
<h3 id="第三次提交"><a href="#第三次提交" class="headerlink" title="第三次提交"></a>第三次提交</h3><p>在对别人分享的 kernel 进行学习后，这次我做了比较详细的特征工程（具体操作在下一节），并且进行了 sklearn 中常用分类器效果的比较，最终选用了 SVC 分类器。本次的 Public Score 提高到 0.79904。</p>
<h2 id="代码详述"><a href="#代码详述" class="headerlink" title="代码详述"></a>代码详述</h2><p>这里针对最后一次提交对应的代码进行一个说明总结。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> re <span class="keyword">as</span> re</div><div class="line"></div><div class="line"><span class="keyword">import</span> warnings</div><div class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'../input/train.csv'</span>, header=<span class="number">0</span>, dtype=&#123;<span class="string">'Age'</span>: np.float64&#125;)</div><div class="line">test = pd.read_csv(<span class="string">'../input/test.csv'</span>, header=<span class="number">0</span>, dtype=&#123;<span class="string">'Age'</span>: np.float64&#125;)</div><div class="line">full_data = [train, test]</div></pre></td></tr></table></figure>
<p>我们可以通过<code>info</code>方法来大致地了解训练集和测试集：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(train.info())</div><div class="line">print(test.info())</div></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;</div><div class="line">RangeIndex: 891 entries, 0 to 890</div><div class="line">Data columns (total 12 columns):</div><div class="line">PassengerId    891 non-null int64</div><div class="line">Survived       891 non-null int64</div><div class="line">Pclass         891 non-null int64</div><div class="line">Name           891 non-null object</div><div class="line">Sex            891 non-null object</div><div class="line">Age            714 non-null float64</div><div class="line">SibSp          891 non-null int64</div><div class="line">Parch          891 non-null int64</div><div class="line">Ticket         891 non-null object</div><div class="line">Fare           891 non-null float64</div><div class="line">Cabin          204 non-null object</div><div class="line">Embarked       889 non-null object</div><div class="line">dtypes: float64(2), int64(5), object(5)</div><div class="line">memory usage: 83.6+ KB</div><div class="line">None</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;</div><div class="line">RangeIndex: 418 entries, 0 to 417</div><div class="line">Data columns (total 11 columns):</div><div class="line">PassengerId    418 non-null int64</div><div class="line">Pclass         418 non-null int64</div><div class="line">Name           418 non-null object</div><div class="line">Sex            418 non-null object</div><div class="line">Age            332 non-null float64</div><div class="line">SibSp          418 non-null int64</div><div class="line">Parch          418 non-null int64</div><div class="line">Ticket         418 non-null object</div><div class="line">Fare           417 non-null float64</div><div class="line">Cabin          91 non-null object</div><div class="line">Embarked       418 non-null object</div><div class="line">dtypes: float64(2), int64(4), object(5)</div><div class="line">memory usage: 36.0+ KB</div><div class="line">None</div></pre></td></tr></table></figure>
<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><h4 id="Pclass"><a href="#Pclass" class="headerlink" title="Pclass"></a>Pclass</h4><p>Pclass 特征没有缺失值，因此可以通过<code>groupby</code>函数来计算船舱每一档的生还率：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(train[[<span class="string">'Pclass'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'Pclass'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>可以看到结果显示船舱档位和生还率还是有较大联系的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">   Pclass  Survived</div><div class="line">0       1  0.629630</div><div class="line">1       2  0.472826</div><div class="line">2       3  0.242363</div></pre></td></tr></table></figure>
<h4 id="Sex"><a href="#Sex" class="headerlink" title="Sex"></a>Sex</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(train[[<span class="string">'Sex'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'Sex'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>可以看到女性的生还率更高：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">      Sex  Survived</div><div class="line">0  female  0.742038</div><div class="line">1    male  0.188908</div></pre></td></tr></table></figure>
<h4 id="SibSp-and-Parch"><a href="#SibSp-and-Parch" class="headerlink" title="SibSp and Parch"></a>SibSp and Parch</h4><p>这两个特征是船上表亲和直亲数量。通过这两个特征可以创造一个新的特征 - Family Size：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    dataset[<span class="string">'FamilySize'</span>] = dataset[<span class="string">'SibSp'</span>] + dataset[<span class="string">'Parch'</span>] + <span class="number">1</span></div><div class="line">print(train[[<span class="string">'FamilySize'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'FamilySize'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>可以看到生还率和家庭成员数不是单纯的线性关系：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">   FamilySize  Survived</div><div class="line">0           1  0.303538</div><div class="line">1           2  0.552795</div><div class="line">2           3  0.578431</div><div class="line">3           4  0.724138</div><div class="line">4           5  0.200000</div><div class="line">5           6  0.136364</div><div class="line">6           7  0.333333</div><div class="line">7           8  0.000000</div><div class="line">8          11  0.000000</div></pre></td></tr></table></figure>
<p>我们可以再创建一个新特征 IsAlone，用来表示是否是单独出行：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    dataset[<span class="string">'IsAlone'</span>] = <span class="number">0</span></div><div class="line">    dataset.loc[dataset[<span class="string">'FamilySize'</span>] == <span class="number">1</span>, <span class="string">'IsAlone'</span>] = <span class="number">1</span></div><div class="line">print(train[[<span class="string">'IsAlone'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'IsAlone'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">   IsAlone  Survived</div><div class="line">0        0  0.505650</div><div class="line">1        1  0.303538</div></pre></td></tr></table></figure>
<p>现在特征值对结果的影响就比较明显了。</p>
<h4 id="Embarked"><a href="#Embarked" class="headerlink" title="Embarked"></a>Embarked</h4><p>注意 Embarked 特征有极少的缺失值，对于类别特征，可以考虑用最频繁的特征值进行填充：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'Embarked'</span>].value_counts()</div></pre></td></tr></table></figure>
<p>可以看到，最频繁的特征值为<code>S</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">S    644</div><div class="line">C    168</div><div class="line">Q     77</div><div class="line">Name: Embarked, dtype: int64</div></pre></td></tr></table></figure>
<p>因此，我们用<code>S</code>对缺失值进行填充：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    dataset[<span class="string">'Embarked'</span>] = dataset[<span class="string">'Embarked'</span>].fillna(<span class="string">'S'</span>)</div><div class="line">print(train[[<span class="string">'Embarked'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'Embarked'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>结果如下。可以看到明显的区别：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">  Embarked  Survived</div><div class="line">0        C  0.553571</div><div class="line">1        Q  0.389610</div><div class="line">2        S  0.339009</div></pre></td></tr></table></figure>
<h4 id="Fare"><a href="#Fare" class="headerlink" title="Fare"></a>Fare</h4><p>测试集中 Fare 特征有一个缺失值。对于数值特征，可以用中位数（或者平均值）填充缺失值：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    dataset[<span class="string">'Fare'</span>] = dataset[<span class="string">'Fare'</span>].fillna(train[<span class="string">'Fare'</span>].median())</div></pre></td></tr></table></figure>
<p>因为每个 Fare 的值对应的样本数量太少，因此我们考虑划分区间。这里，我根据每个区间的样本数量将样本划分为四个区间，形成新特征 CategoricalFare：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'CategoricalFare'</span>] = pd.qcut(train[<span class="string">'Fare'</span>], <span class="number">4</span>)</div><div class="line">print(train[[<span class="string">'CategoricalFare'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'CategoricalFare'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">   CategoricalFare  Survived</div><div class="line">0   (-0.001, 7.91]  0.197309</div><div class="line">1   (7.91, 14.454]  0.303571</div><div class="line">2   (14.454, 31.0]  0.454955</div><div class="line">3  (31.0, 512.329]  0.581081</div></pre></td></tr></table></figure>
<h4 id="Age"><a href="#Age" class="headerlink" title="Age"></a>Age</h4><p>之前提到过，Age 特征的缺失值太多，不能简单的用平均值或者中位数进行填充。这里，我们不再简单的舍弃 Age 特征，而是换用不同的填充思路 - <strong>根据已有数据的平均值和标准差随机生成填充数</strong>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    age_avg = dataset[<span class="string">'Age'</span>].mean()</div><div class="line">    age_std = dataset[<span class="string">'Age'</span>].std()</div><div class="line">    age_null_count = dataset[<span class="string">'Age'</span>].isnull().sum()</div><div class="line">    </div><div class="line">    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)</div><div class="line">    dataset[<span class="string">'Age'</span>][np.isnan(dataset[<span class="string">'Age'</span>])] = age_null_random_list</div><div class="line">    dataset[<span class="string">'Age'</span>] = dataset[<span class="string">'Age'</span>].astype(int)</div></pre></td></tr></table></figure>
<p>同样，将数据划分为区间。这里我按等区间跨度划分，生成新特征 CategoricalAge：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'CategoricalAge'</span>] = pd.cut(train[<span class="string">'Age'</span>], <span class="number">5</span>)</div><div class="line"></div><div class="line">print(train[[<span class="string">'CategoricalAge'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'CategoricalAge'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">  CategoricalAge  Survived</div><div class="line">0  (-0.08, 16.0]  0.504274</div><div class="line">1   (16.0, 32.0]  0.345372</div><div class="line">2   (32.0, 48.0]  0.394422</div><div class="line">3   (48.0, 64.0]  0.434783</div><div class="line">4   (64.0, 80.0]  0.090909</div></pre></td></tr></table></figure>
<p>也有别的填充思路，例如用<code>Sex, Title, Pclass</code>三个特征构建随机森林模型，来生成填充值。</p>
<h4 id="Name"><a href="#Name" class="headerlink" title="Name"></a>Name</h4><p>姓名是我们一开始忽略掉的特征。实际上，通过人名前的头衔也可以进行分析：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_title</span><span class="params">(name)</span>:</span></div><div class="line">    title_search = re.search(<span class="string">' ([A-Za-z]+)\.'</span>, name)</div><div class="line">    <span class="keyword">if</span> title_search:</div><div class="line">        <span class="keyword">return</span> title_search.group(<span class="number">1</span>)</div><div class="line">    <span class="keyword">return</span> <span class="string">''</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Name'</span>].apply(get_title)</div><div class="line">    </div><div class="line">print(pd.crosstab(train[<span class="string">'Title'</span>], train[<span class="string">'Sex'</span>]))</div></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">Sex       female  male</div><div class="line">Title                 </div><div class="line">Capt           0     1</div><div class="line">Col            0     2</div><div class="line">Countess       1     0</div><div class="line">Don            0     1</div><div class="line">Dr             1     6</div><div class="line">Jonkheer       0     1</div><div class="line">Lady           1     0</div><div class="line">Major          0     2</div><div class="line">Master         0    40</div><div class="line">Miss         182     0</div><div class="line">Mlle           2     0</div><div class="line">Mme            1     0</div><div class="line">Mr             0   517</div><div class="line">Mrs          125     0</div><div class="line">Ms             1     0</div><div class="line">Rev            0     6</div><div class="line">Sir            0     1</div></pre></td></tr></table></figure>
<p>由于存在一些次数较少的头衔，我们将头衔分类，把部分含义相近的头衔归在一起：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace([<span class="string">'Lady'</span>, <span class="string">'Countess'</span>, <span class="string">'Capt'</span>, <span class="string">'Col'</span>, <span class="string">'Sir'</span>, <span class="string">'Don'</span>, <span class="string">'Dr'</span>, <span class="string">'Major'</span>, <span class="string">'Rev'</span>, <span class="string">'Jonkheer'</span>, <span class="string">'Dona'</span>], <span class="string">'Rare'</span>)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace(<span class="string">'Mlle'</span>, <span class="string">'Miss'</span>)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace(<span class="string">'Ms'</span>, <span class="string">'Miss'</span>)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace(<span class="string">'Mme'</span>, <span class="string">'Mrs'</span>)</div><div class="line">    </div><div class="line">print(train[[<span class="string">'Title'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'Title'</span>], as_index=<span class="keyword">False</span>).mean())</div></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">    Title  Survived</div><div class="line">0  Master  0.575000</div><div class="line">1    Miss  0.702703</div><div class="line">2      Mr  0.156673</div><div class="line">3     Mrs  0.793651</div><div class="line">4    Rare  0.347826</div></pre></td></tr></table></figure>
<h3 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h3><p>sklearn 要求数据都是数值型的，因此要进行数据的清理和转换。也可以用各种包内现成的算法，例如<code>pd.get_dummies()</code>。这里我们就简单的自己动手来将数据映射为数值：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将数据映射为数值</span></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> full_data:</div><div class="line">    <span class="comment"># Mapping Sex</span></div><div class="line">    dataset[<span class="string">'Sex'</span>] = dataset[<span class="string">'Sex'</span>].map( &#123;<span class="string">'female'</span>: <span class="number">0</span>, <span class="string">'male'</span>: <span class="number">1</span>&#125; ).astype(int)</div><div class="line">    </div><div class="line">    <span class="comment"># Mapping titles</span></div><div class="line">    title_mapping = &#123;<span class="string">"Mr"</span>: <span class="number">1</span>, <span class="string">"Miss"</span>: <span class="number">2</span>, <span class="string">"Mrs"</span>: <span class="number">3</span>, <span class="string">"Master"</span>: <span class="number">4</span>, <span class="string">"Rare"</span>: <span class="number">5</span>&#125;</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].map(title_mapping)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].fillna(<span class="number">0</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># Mapping Embarked</span></div><div class="line">    dataset[<span class="string">'Embarked'</span>] = dataset[<span class="string">'Embarked'</span>].map( &#123;<span class="string">'S'</span>: <span class="number">0</span>, <span class="string">'C'</span>: <span class="number">1</span>, <span class="string">'Q'</span>: <span class="number">2</span>&#125; ).astype(int)</div><div class="line">    </div><div class="line">    <span class="comment"># Mapping Fare</span></div><div class="line">    dataset.loc[ dataset[<span class="string">'Fare'</span>] &lt;= <span class="number">7.91</span>, <span class="string">'Fare'</span>] 						        = <span class="number">0</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Fare'</span>] &gt; <span class="number">7.91</span>) &amp; (dataset[<span class="string">'Fare'</span>] &lt;= <span class="number">14.454</span>), <span class="string">'Fare'</span>] = <span class="number">1</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Fare'</span>] &gt; <span class="number">14.454</span>) &amp; (dataset[<span class="string">'Fare'</span>] &lt;= <span class="number">31</span>), <span class="string">'Fare'</span>]   = <span class="number">2</span></div><div class="line">    dataset.loc[ dataset[<span class="string">'Fare'</span>] &gt; <span class="number">31</span>, <span class="string">'Fare'</span>] 							        = <span class="number">3</span></div><div class="line">    dataset[<span class="string">'Fare'</span>] = dataset[<span class="string">'Fare'</span>].astype(int)</div><div class="line">    </div><div class="line">    <span class="comment"># Mapping Age</span></div><div class="line">    dataset.loc[ dataset[<span class="string">'Age'</span>] &lt;= <span class="number">16</span>, <span class="string">'Age'</span>] 					       = <span class="number">0</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Age'</span>] &gt; <span class="number">16</span>) &amp; (dataset[<span class="string">'Age'</span>] &lt;= <span class="number">32</span>), <span class="string">'Age'</span>] = <span class="number">1</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Age'</span>] &gt; <span class="number">32</span>) &amp; (dataset[<span class="string">'Age'</span>] &lt;= <span class="number">48</span>), <span class="string">'Age'</span>] = <span class="number">2</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Age'</span>] &gt; <span class="number">48</span>) &amp; (dataset[<span class="string">'Age'</span>] &lt;= <span class="number">64</span>), <span class="string">'Age'</span>] = <span class="number">3</span></div><div class="line">    dataset.loc[ dataset[<span class="string">'Age'</span>] &gt; <span class="number">64</span>, <span class="string">'Age'</span>]                           = <span class="number">4</span></div></pre></td></tr></table></figure>
<h3 id="特征选取"><a href="#特征选取" class="headerlink" title="特征选取"></a>特征选取</h3><p>我们将一些无用的特征去掉，只保留部分原始特征和我们生成的新特征：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Feature Selection</span></div><div class="line">drop_elements = [<span class="string">'PassengerId'</span>, <span class="string">'Name'</span>, <span class="string">'Ticket'</span>, <span class="string">'Cabin'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'FamilySize'</span>]</div><div class="line">train = train.drop(drop_elements, axis = <span class="number">1</span>)</div><div class="line">train = train.drop([<span class="string">'CategoricalAge'</span>, <span class="string">'CategoricalFare'</span>], axis = <span class="number">1</span>)</div><div class="line"></div><div class="line">test  = test.drop(drop_elements, axis = <span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="keyword">print</span> (train.head(<span class="number">10</span>))</div><div class="line"></div><div class="line">train = train.values</div><div class="line">test  = test.values</div></pre></td></tr></table></figure>
<p>打印的结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">   Survived  Pclass  Sex  Age  Fare  Embarked  IsAlone  Title</div><div class="line">0         0       3    1    1     0         0        0      1</div><div class="line">1         1       1    0    2     3         1        0      3</div><div class="line">2         1       3    0    1     1         0        1      2</div><div class="line">3         1       1    0    2     3         0        0      3</div><div class="line">4         0       3    1    2     1         0        1      1</div><div class="line">5         0       3    1    1     1         2        1      1</div><div class="line">6         0       1    1    3     3         0        1      1</div><div class="line">7         0       3    1    0     2         0        0      4</div><div class="line">8         1       3    0    1     1         0        0      3</div><div class="line">9         1       2    0    0     2         1        0      3</div></pre></td></tr></table></figure>
<h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><p>首先生成训练集的特征和标记：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">X = train[<span class="number">0</span>::, <span class="number">1</span>::]</div><div class="line">y = train[<span class="number">0</span>::, <span class="number">0</span>]</div></pre></td></tr></table></figure>
<p>引入并初始化 xgboost：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</div><div class="line">xgbc = XGBClassifier()</div></pre></td></tr></table></figure>
<p>我们先使用 5 折交叉验证来看一看 xgboost 算法的预测效果如何：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> cross_val_score</div><div class="line"><span class="comment"># 使用 5 折交叉验证</span></div><div class="line">cross_val_score(xgbc, X, y, cv=<span class="number">5</span>).mean()</div></pre></td></tr></table></figure>
<p>结果为 0.80595516611715701，还不错。之后就可以正式的训练和预测了：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">xgbc.fit(X, y)</div><div class="line">xgbc_y_predict = xgbc.predict(test)</div><div class="line"></div><div class="line">test_data = pd.read_csv(<span class="string">'../input/test.csv'</span>, header=<span class="number">0</span>, dtype=&#123;<span class="string">'Age'</span>: np.float64&#125;)</div><div class="line">xgbc_submission = pd.DataFrame(&#123;</div><div class="line">    <span class="string">'PassengerId'</span>: test_data[<span class="string">'PassengerId'</span>],</div><div class="line">    <span class="string">'Survived'</span>: xgbc_y_predict</div><div class="line">&#125;)</div><div class="line">xgbc_submission.to_csv(<span class="string">'xgbc_submission.csv'</span>, index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<h3 id="分类器比较"><a href="#分类器比较" class="headerlink" title="分类器比较"></a>分类器比较</h3><p>尽管这一次我直接选用了 XGBoost，但是我还是想把第三次提交时所用的分类器比较代码贴一下。首先是引入所有参与比较的分类器（全部是 sklearn 包中的），以及用于可视化的 matplotlib 和 seaborn。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, log_loss</div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier</div><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</div><div class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div></pre></td></tr></table></figure>
<p>初始化各分类器，并使用数据集划分函数 StratifiedShuffleSplit：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">classifiers = [</div><div class="line">    KNeighborsClassifier(<span class="number">3</span>),</div><div class="line">    SVC(probability=<span class="keyword">True</span>),</div><div class="line">    DecisionTreeClassifier(),</div><div class="line">    RandomForestClassifier(),</div><div class="line">    AdaBoostClassifier(),</div><div class="line">    GradientBoostingClassifier(),</div><div class="line">    GaussianNB(),</div><div class="line">    LinearDiscriminantAnalysis(),</div><div class="line">    QuadraticDiscriminantAnalysis(),</div><div class="line">    LogisticRegression()</div><div class="line">]</div><div class="line"></div><div class="line">log_cols = [<span class="string">'Classifier'</span>, <span class="string">'Accuracy'</span>]</div><div class="line">log = pd.DataFrame(columns=log_cols)</div><div class="line"></div><div class="line">sss = StratifiedShuffleSplit(n_splits=<span class="number">10</span>, test_size=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</div><div class="line"></div><div class="line">X = train[<span class="number">0</span>::, <span class="number">1</span>::]</div><div class="line">y = train[<span class="number">0</span>::, <span class="number">0</span>]</div><div class="line"></div><div class="line">acc_dict = &#123;&#125;</div></pre></td></tr></table></figure>
<p>分别计算各分类器的准确率：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> sss.split(X, y):</div><div class="line">    X_train, X_test = X[train_index], X[test_index]</div><div class="line">    y_train, y_test = y[train_index], y[test_index]</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> clf <span class="keyword">in</span> classifiers:</div><div class="line">        name = clf.__class__.__name__</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line">        train_predictions = clf.predict(X_test)</div><div class="line">        acc = accuracy_score(y_test, train_predictions)</div><div class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> acc_dict:</div><div class="line">            acc_dict[name] += acc</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            acc_dict[name] = acc</div><div class="line"></div><div class="line"><span class="keyword">for</span> clf <span class="keyword">in</span> acc_dict:</div><div class="line">    acc_dict[clf] = acc_dict[clf] / <span class="number">10.0</span></div><div class="line">    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)</div><div class="line">    log = log.append(log_entry)</div><div class="line">    </div><div class="line">plt.xlabel(<span class="string">'Accuracy'</span>)</div><div class="line">plt.title(<span class="string">'Classifier Accuracy'</span>)</div><div class="line"></div><div class="line">sns.set_color_codes(<span class="string">'muted'</span>)</div><div class="line">sns.barplot(x=<span class="string">'Accuracy'</span>, y=<span class="string">'Classifier'</span>, data=log, color=<span class="string">'b'</span>)</div></pre></td></tr></table></figure>
<p>这里的指标其实有更好的选择，因为当训练集中大量例子属于某一个类时，分类器可能通过简单地全部预测为较大类来达到更高的准确率。用 F1 Score，即精确率和召回率的调和平均数会更为科学。</p>
<p>比较结果如图：</p>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAg8AAAEWCAYAAADhFHRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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%0A" alt=""></p>
<p>根据这幅图，第三次提交时我选用了效果相对较好的 SVC 分类器。</p>
<h3 id="思考与总结"><a href="#思考与总结" class="headerlink" title="思考与总结"></a>思考与总结</h3><h4 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h4><p>在上述代码中我们基本没有进行数据可视化，一是因为这次的数据还是比较容易去分析，不太需要数据可视化；二是我对 matplotlib、seaborn 的使用还不太熟练。</p>
<p>实际上，数据可视化是数据科学的核心技术之一。有效的数据可视化可以帮助深入地研究变量，因此通过数据可视化来对数据集和单独的特征进行了解应该成为机器学习项目的第一步。如果想要了解如何在这个项目中使用数据可视化进行分析，可以在最下面的参考资料中查看别人的方案；如果想全面的学习数据可视化，Kaggle 也提供了数据可视化的<a href="https://www.kaggle.com/learn/data-visualisation" target="_blank" rel="external">课程</a>。</p>
<h4 id="关于缺失值"><a href="#关于缺失值" class="headerlink" title="关于缺失值"></a>关于缺失值</h4><p>不同的机器学习模型对缺失值的敏感度不同。实际上，xgboost 对缺失值有默认的处理方法。根据作者 Tianqi Chen 在论文中的介绍，xgboost 把缺失值当做稀疏矩阵来对待，本身的在节点分裂时不考虑的缺失值的数值。缺失值数据会被分到左子树和右子树分别计算损失，选择较优的那一个。如果训练中没有数据缺失，预测时出现了数据缺失，那么默认被分类到右子树。</p>
<p>根据知乎上<a href="https://www.zhihu.com/question/58230411" target="_blank" rel="external">怎么理解决策树、xgboost能处理缺失值？而有的模型(svm)对缺失值比较敏感呢?</a>问题赞同数最高的回答，有一些经验法则可供参考：</p>
<ol>
<li>树模型对于缺失值的敏感度较低，大部分时候可以在数据有缺失时使用。</li>
<li>涉及到距离度量（distance measurement）时，如计算两个点之间的距离，缺失数据就变得比较重要。因为涉及到“距离”这个概念，那么缺失值处理不当就会导致效果很差，如 K 近邻算法（KNN）和支持向量机（SVM）。</li>
<li>线性模型的代价函数（loss function）往往涉及到距离（distance）的计算，计算预测值和真实值之间的差别，这容易导致对缺失值敏感。</li>
<li>神经网络的鲁棒性强，对于缺失数据不是非常敏感，但一般没有那么多数据可供使用。</li>
<li>贝叶斯模型对于缺失数据也比较稳定，数据量很小的时候首推贝叶斯模型。</li>
</ol>
<p>总结来看，对于有缺失值的数据在经过缺失值处理后：</p>
<ul>
<li>数据量很小，用朴素贝叶斯</li>
<li>数据量适中或者较大，用树模型，优先 xgboost</li>
<li>数据量较大，也可以用神经网络</li>
<li>避免使用距离度量相关的模型，如 KNN 和 SVM</li>
</ul>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>亲自参加一次比赛才发觉 Kaggle 是好文明，像我这种菜鸡可以通过高质量的比赛了解到数据分析的很多基本流程和方法，收获的经验远不是书上例题所能比的。而且社区讨论里面个个都是人才，分享的经验技巧又干货满满，我超喜欢里面的。</p>
<p>这篇博文主要整理一开始所用的基本方法，以及通过特征工程实现的改良。下一步我打算试着去用模型集成去进一步提高预测准确率，并且进行总结。</p>
<p><strong>18.03.25 补充：</strong>尝试了模型集成，但是效果没有提升（反而降了），猜想是因为 xgboost 的效果已经足够好。系列的下篇搁置中…</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/31743196" target="_blank" rel="external">Kaggle Titanic 生存预测 – 详细流程吐血梳理</a>：推荐阅读第四部分“变量转换”</li>
<li><a href="https://zhuanlan.zhihu.com/p/33733586" target="_blank" rel="external">Kaggle Titanic 生存预测(Top1.4%)完整代码分享</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27550334" target="_blank" rel="external">分分钟，杀入Kaggle TOP 5% 系列（1）</a></li>
<li><a href="https://www.kaggle.com/sinakhorami/titanic-best-working-classifier" target="_blank" rel="external">Titanic best working Classifier | Kaggle</a></li>
</ul>
<p>最后推荐一下这个 kernel：<a href="https://www.kaggle.com/kanncaa1/data-sciencetutorial-for-beginners/notebook" target="_blank" rel="external">Data ScienceTutorial for Beginners
</a>。包含了包括数据可视化、Python 基本语法、pandas 基本用法等 Kaggle 比赛所需要的基础知识。很全面，而且主要的数据集是精灵宝可梦数据，加分。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;注册著名的数据科学竞赛平台 Kaggle 四个多月了，当初是为了要一份数据集，而一直没有参加比赛。这个寒假终于按耐不住，决定拿入门级的 Titanic: Machine Learning from Disaster 打响革命第一枪。&lt;/p&gt;
&lt;p&gt;Titanic 生存预测比赛是一个二分类问题。题目提供了一份乘客名单，包含了乘客的名字、性别、年龄、船票等级等信息，以及是否成功获救的标记，最终需要提交一份对测试集中的乘客是否成功获救的 csv 文件。&lt;/p&gt;
&lt;p&gt;经过了四次提交，最后我的 Public Score 暂时定格在 0.80861，这个成绩目前在前 7%。这篇博文主要简述一下我所做的尝试和改进，并对最后一次换用 XGBoost 所得到的最好成绩的代码进行一个详细的说明，也是对相似题目处理流程的一个总结。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Titanic-public-score.jpg&quot; alt=&quot;Titanic-public-score&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://kyonhuang.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://kyonhuang.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="特征工程" scheme="http://kyonhuang.top/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
      <category term="Kaggle" scheme="http://kyonhuang.top/tags/Kaggle/"/>
    
      <category term="Titanic 生存预测" scheme="http://kyonhuang.top/tags/Titanic-%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>寒假总结及新学期展望</title>
    <link href="http://kyonhuang.top/2018-new-term/"/>
    <id>http://kyonhuang.top/2018-new-term/</id>
    <published>2018-02-23T03:24:11.000Z</published>
    <updated>2018-06-30T08:56:11.259Z</updated>
    
    <content type="html"><![CDATA[<p>还有几天寒假就结束了。这个寒假没有干太多事，主要是准备美赛，以及继续了解一些机器学习的东西。剩余的时间放松了一下，补了一些不错的电影、日剧、轻小说。在这里把自己的寒假生活总结一下，然后展望一下接下来非常重要的一个学期，确定一个大致的目标，以鼓励自己更高效地学习、生活。</p>
<a id="more"></a>
<h2 id="美赛总结"><a href="#美赛总结" class="headerlink" title="美赛总结"></a>美赛总结</h2><p>这个寒假第一次参加了美国大学生数学建模比赛。虽然赛前也做了一些知识储备，看了很多经验贴，比赛时才发觉完全力不从心。开始时三个人雄心壮志意气风发，做题时无从下手备受煎熬，整天在多个美赛交流群吹水交换段子和表情包，最后变成按时提交就心满意足；尽管如此，我第二晚熬到一点多，第三晚熬到四点，最后一晚只睡了一个半小时，这个痛苦的过程明年也不打算再尝试了，哈哈。</p>
<p>虽然这次美赛的经历不能算成功，但是我也不是特别在意。如果学弟学妹想要参加美赛并且认真考虑争取奖项，我认为最重要的还是团结合作，一鼓作气。美赛是三个人的团队合作，每个人应该各有所长，应该要有对数学建模比较了解并有经验的，要有编程水平较好的，要有英文写作水平较好的。尽管这么说，美赛毕竟是很多建模参赛者的第一站（以及最后一站），还是一个学习的过程，水平不足也不必太过焦虑，只要在赛前半个月确定大致分工，各自抽出时间做知识补强即可。我觉得<strong>比较重要，也是我们团队比较遗憾的一点是</strong>，我们团队没有参加学校的模拟赛，最后也没有在学校一起参加比赛，而是在各自家中网上交流。事实证明，在一起面对面参赛更有助于团队交流和工作，并对团队的积极性有着极大地提高。</p>
<p>至于要了解哪方面的知识，做哪些准备，数学家和数学中国论坛都有很多经验贴，稍微看几篇即可。这次我也了解了很多数学建模的算法，有些和机器学习领域也有共通，也算是宝贵收获之一。另外也算是稍许接触了论文写作。最后希望还是要有个稍微好点的成绩，以告慰熬过的那些夜、死过的那些脑细胞。</p>
<p>补充：拿了 H 奖，肯定不算理想，但是基本算是和做出的东西相配吧。</p>
<h2 id="读观后感"><a href="#读观后感" class="headerlink" title="读观后感"></a>读观后感</h2><p>美赛完赛后实在是心力交瘁，加上上学期各方面压力还是有一些大，决定给自己放个假，好好放松一下。除开看球赛、追番（今年的一月真的是最强一月，佳作辈出），我还补了一些不错的电影、日剧、轻小说，有一些感想不吐不快。</p>
<ul>
<li><p><strong>日剧《四重奏》</strong>：我查了一下豆瓣的评分，这部剧的口碑非常好，于是一口气补完了。四个蹩脚的音乐爱好者怀揣着各自的故事，生活在同一个屋檐下，相互靠近，相互依偎，拉出一曲酸甜苦辣的四重奏。才能与平庸，兴趣与谋生，爱情与婚姻，关于这些主题的探讨让这部剧非常有意思。感觉用梵高在那封著名的信里写的话来描述我对这部剧的感触再合适不过：“也许在我们的灵魂中有一团烈火，但没有一个人前来取暖。过路人只看见烟囱中冒出的一缕青烟，便接着走自己的路去了。那么，听我说，应该怎么办呢？难道不应该守护着心中的这团火，保持自己的热情，耐心等待着有人前来取暖的时刻吗？”</p>
</li>
<li><p><strong>电影《爱乐之城》</strong>：我极少去电影院，很多电影都是在假期看的。这部盛名在外的《爱乐之城》让我心念已久，最终也确实打动了我。《樱花庄的宠物女孩》小说的最后一卷和这部电影有相似之处，很多读者不能理解空太和真白的冲突到底在哪里、为何分开，其实在生活面前，他人眼中的天才也不过是普通人，没有能力兼顾梦想和爱情，这不是两个人单纯的坚持就能够解决的问题。只不过，樱花庄的故事最终给了一个 HE，而爱乐之城的两个人相忘于江湖。电影最后的一段蒙太奇是点睛之笔，曾经沧海难为水，枕边人是梦中人，我们也曾经有美好的可能。我也很喜欢这部电影的配乐，已经在网易云开始循环了。最后，这部确实适合很适合上映时情侣在电影院一起观看啊，气哭。</p>
</li>
<li><p><strong>轻小说《哥布林杀手》</strong>：这部轻小说刚刚传出动画化的消息，不过一石激起千层浪，小说（其实主要是漫画）的某些情节引起了很多群众的讨论。虽然哥布林杀手这种不好高骛远、沉稳谨慎、一心消灭所有哥布林的反龙傲天式男主角在如今套板式的奇幻类轻小说中十分稀缺，不过比起小说的内容，我更想简单聊一些别的。这部小说是作者跑团的衍生品，很久之前在读《红龙》时我就对跑团有点兴趣了，这次借此机会一鼓作气去了解了跑团、TRPG、D20、龙与地下城。不得不说，游戏也是人类文化史上不可磨灭的一部分，尽管可能没有机会去跑一次团，但我也会继续去了解这些有魅力的另类文化。</p>
</li>
<li><p><strong>剧场版《东离剑游纪之生死一剑》</strong>：当初的《东离剑游纪》我是按时追完一集没落。这次 B 站买下了这部剧场版的版权，上线时间恰好和美赛撞车，比赛一完我就迫不及待的看完了。我只能说，这部剧场版实在是太赞了！看了我博客个人介绍的朋友应该了解到我是虚渊玄老师的铁粉，而作为霹雳布袋戏的忠实迷笛，这次老虚的剧本既具有服务观众的娱乐性，又有与古龙一脉相承的武侠风。而老虚的最大特点也没有落下，那就是在其笔下散发着独特魅力的绝望与悲剧。辅以泽野弘之的配乐、霹雳的精彩制作，这是一部我个人能给出满分的作品！当然，如果要推荐给其他人，我认为首先要能够欣赏布袋戏（当时《东离剑游纪》的 TV 版我看到有些人不太能够接受这一表现形式）；另外，虽然不必补《东离剑游纪》也能享受这部剧场版，但是如果先看完了《东离剑游纪》，那么观看这一部《生死一剑》，尤其是在后一半的剧情会享受到更多的乐趣。最后，这部剧场版的片尾剪辑了一些布袋剧的拍摄记录，看完后我对包括操偶师在内的所有制作人员抱有了更深的敬意，他们的匠心造就了精彩的历部霹雳布袋戏。也希望布袋戏这一传统艺术形式能够借着这股东风有更好的发展，在国际上有更大的影响力。</p>
</li>
</ul>
<h2 id="新学期展望"><a href="#新学期展望" class="headerlink" title="新学期展望"></a>新学期展望</h2><ul>
<li><p><strong>课业</strong>：下学期还有几门必修课，还是必须要拿到满绩。课余时间除了保证运动外要自觉去图书馆，集中精力，提高学习效率。</p>
</li>
<li><p><strong>作息与锻炼</strong>：这个假期过得有些日夜颠倒，生活作息不太健康。加上也没怎么运动，因此身体和精神状态也不太好。新学期一是要保持一个相对规律的生活作息，二是要下决心来制定一个减肥的目标，控制饮食，定期测量。最重要的是积极锻炼，每天保持一定的活动量，球队那边也要跟着训练，争取打上今年的振兴杯。</p>
</li>
<li><p><strong>机器学习</strong>：目前感觉算是一只脚踏入了机器学习的大门了。自己对这个领域还是比较感兴趣的，寒假也抽时间做了一下 Kaggle 的 Titanic 生存预测比赛，这几天写总结性的文章，可惜是没有读太多书。接下来的计划是先把周志华《机器学习》通读一遍，主要是理解各算法，然后努力结合《统计学习方法》把重要的算法推一遍。同时去看 CV、NLP 的东西，主要先是把吴恩达《深度学习》系列课程的最后两门课学完，然后争取参加一次 Kaggle 的相关比赛。之后再确定接下来的学习路径。</p>
</li>
<li><p><strong>算法</strong>：继续每天至少一道 LeetCode，另外根据《算法导论》、《算法竞赛入门经典（第 2 版）》重点复习竞赛常用算法。</p>
</li>
<li><p><strong>专业复习</strong>：每周复习一门重要的专业课（高数、线代、离散、概率论、操作系统、数据结构与算法、数据库、计算机网络），将主要知识点形成可供再次查阅的纸质笔记。</p>
</li>
<li><p><strong>paper</strong>：根据实验室任务和自己的学习进度主动读 paper，要锻炼自己这方面的能力，并做好笔记。</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;还有几天寒假就结束了。这个寒假没有干太多事，主要是准备美赛，以及继续了解一些机器学习的东西。剩余的时间放松了一下，补了一些不错的电影、日剧、轻小说。在这里把自己的寒假生活总结一下，然后展望一下接下来非常重要的一个学期，确定一个大致的目标，以鼓励自己更高效地学习、生活。&lt;/p&gt;
    
    </summary>
    
      <category term="翻滚吧大学生" scheme="http://kyonhuang.top/categories/%E7%BF%BB%E6%BB%9A%E5%90%A7%E5%A4%A7%E5%AD%A6%E7%94%9F/"/>
    
    
      <category term="随笔" scheme="http://kyonhuang.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
      <category term="总结" scheme="http://kyonhuang.top/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="目标" scheme="http://kyonhuang.top/tags/%E7%9B%AE%E6%A0%87/"/>
    
      <category term="学习之路" scheme="http://kyonhuang.top/tags/%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/"/>
    
      <category term="观后感" scheme="http://kyonhuang.top/tags/%E8%A7%82%E5%90%8E%E6%84%9F/"/>
    
  </entry>
  
  <entry>
    <title>《C 程序设计语言》读书笔记</title>
    <link href="http://kyonhuang.top/C-programming-language-notes/"/>
    <id>http://kyonhuang.top/C-programming-language-notes/</id>
    <published>2018-02-02T11:25:32.000Z</published>
    <updated>2018-02-08T01:45:30.460Z</updated>
    
    <content type="html"><![CDATA[<p>我所在的专业没有开设 C 语言的课程，而大一虽然有开设 C++，但一是两门语言还是有一些区别，二是也过去了一年，很多东西都差不多忘干净了。这学期的系统级程序设计课程（即著名的“csapp”）和 C 语言密不可分，因此我借来了《C 程序设计语言》来补一补相关知识，并记了一些笔记。最终这门课拿了满绩，还是对得起自己的付出。</p>
<p>我认为《C 程序设计语言》是一本很好的 C 语言入门书籍，简洁清晰。这里的笔记也都是 C 语言最基础的语法。越往深里学，越会感觉 C 语言和计算机系统的相辅相成，博大精深，也越烧脑。但是现在都必须要按需所学了，还是希望有机会能够继续深入挖掘 C 语言的精粹。</p>
<a id="more"></a>
<h2 id="序与引言"><a href="#序与引言" class="headerlink" title="序与引言"></a>序与引言</h2><p>C 语言的 ANSI 标准的目的是制定“一个无歧义性的且<strong>与具体机器无关</strong>的 C 语言定义”。比起之前的标准，ANSI 标准要求对变量进行正确的声明和显式的强制类型转换，并为 C 语言定义了一个函数库。</p>
<p>指针提供了与具体机器无关的地址算术运算。</p>
<p>编译的<strong>预处理阶段</strong>将对程序文本进行<strong>宏替换</strong>、<strong>包含其他源文件</strong>以及进行<strong>条件编译</strong>。</p>
<p>C 语言不提供直接处理诸如字符串、集合、列表或数组等符合对象的操作。所有高层的机制必须由显式调用的函数提供。</p>
<h2 id="第-1-章-导言"><a href="#第-1-章-导言" class="headerlink" title="第 1 章  导言"></a>第 1 章  导言</h2><h3 id="符号常量"><a href="#符号常量" class="headerlink" title="符号常量"></a>符号常量</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> 名字 替换文本</span></div><div class="line"></div><div class="line"><span class="comment">// 如：</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span>  LOWER  0</span></div></pre></td></tr></table></figure>
<p><code>#define</code>指令行的末尾没有分号。</p>
<h3 id="参数－传值调用"><a href="#参数－传值调用" class="headerlink" title="参数－传值调用"></a>参数－传值调用</h3><p>在 C 语言中，所有函数参数都是“<strong>通过值</strong>”传递的。也就是说，传递给被调用函数的参数值存放在临时变量中。被调用函数不能直接修改主调函数中变量的值，而只能修改其私有的临时副本的值。</p>
<p>必要时，也可以让函数能够修改主调函数中的变量。这种情况下，调用者需要向被调用函数提供设置值的变量的<strong>地址</strong>（从技术角度看，地址就是指向变量的<strong>指针</strong>），而被调用函数则需要将对应的参数声明为指针类型，并通过它间接访问变量。</p>
<p>当<strong>把数组名作为参数时</strong>，传递给函数的值是<strong>数组起始元素的位置或地址</strong>——它并不复制数组元素本身。在被调用函数中，可以通过数组下标访问或<em>修改</em>数组元素的值。</p>
<h3 id="字符数组"><a href="#字符数组" class="headerlink" title="字符数组"></a>字符数组</h3><p>当在 C 语言程序中出现类似<code>&quot;hello\n&quot;</code>的字符串常量时，它将以字符数组的形式存储，数组的各元素分别存储字符串的各个字符，并<strong>以<code>\0</code>标志字符串的结束</strong>。因此，存储字符串的物理存储单元数比括在双引号中的字符数多一个。</p>
<h3 id="外部变量与作用域"><a href="#外部变量与作用域" class="headerlink" title="外部变量与作用域"></a>外部变量与作用域</h3><p>函数在使用外部变量之前，必须要知道外部变量的名字。如果在外部变量的作用范围内就无所谓，<strong>而如果在另外一个文件中使用，则需要在函数中使用 extern 类型的声明</strong>。</p>
<p>人们通常把变量和函数的 extern 声明放在一个单独的文件中（习惯上称之为头文件），并在每个源文件的开头使用<code>#include</code>语句将所要用的头文件包含进来。</p>
<p>为了与老版本的 C 语言程序兼容，ANSI C 语言把空参数表看成老版本 C 语言的声明方式，并且对参数表不再进行任何检查。<strong>在 ANSI C 中，如果要声明空参数表，则必须使用关键字 void 进行显式声明</strong>。</p>
<p>请注意分以下两个概念：</p>
<ul>
<li>定义（define）：创建变量或分配存储单元；</li>
<li>声明（declaration）：说明变量的性质，但并不分配存储单元。</li>
</ul>
<h2 id="第-2-章-类型、运算符和表达式"><a href="#第-2-章-类型、运算符和表达式" class="headerlink" title="第 2 章  类型、运算符和表达式"></a>第 2 章  类型、运算符和表达式</h2><h3 id="数据类型及长度"><a href="#数据类型及长度" class="headerlink" title="数据类型及长度"></a>数据类型及长度</h3><p>short 类型通常为 16 位，long 类型通常为 32 位，int 类型可以为 16 位或 32 位。各编译器可以根据硬件特性自主选择合适的类型长度。</p>
<p>类型限定符 signed 与 unsigned 可用于限定 char 类型或任何整型。unsigned 类型的数总是正值或 0，而 signed 类型的数可为负值。例如对于 8 位的 char 对象，则 unsigned char 类型变量的取值范围为 0 ~ 255，而 signed char 类型变量的取值范围 -128 ~ 127（在采用对二的补码的机器上）。不带限定符的 char 类型对象是否带符号取决于具体机器，但可打印字符总是正值。</p>
<h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><p>无符号整数常量以字母 u 或 U 结尾。后缀 ul 或 UL 表明是 unsigned long 类型。</p>
<p>没有后缀的浮点数常量为 double 类型。后缀 f 或 F 表示 float 类型，而后缀 l 或 L 则表示 long double 类型。</p>
<p>字符常量<code>\0</code>表示值为 0 的字符，也就是空字符（null）。</p>
<h3 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h3><p>对数组而言，const 限定符指定数组所有元素的值都不能被修改。const 限定符也可配合数组参数使用，以表明函数不能修改数组元素的值。</p>
<h3 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h3><p>取模运算符 % 不能应用于 float 或 double 类型。</p>
<h3 id="关系运算符与逻辑运算符"><a href="#关系运算符与逻辑运算符" class="headerlink" title="关系运算符与逻辑运算符"></a>关系运算符与逻辑运算符</h3><p>关系运算符<code>&gt;</code> <code>&gt;=</code> <code>&lt;</code> <code>&lt;=</code>的优先级比算术运算符低。</p>
<p>不等于运算符<code>!=</code>的优先级比赋值运算符<code>=</code>的优先级要高。</p>
<h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><h4 id="字符型转换为整型"><a href="#字符型转换为整型" class="headerlink" title="字符型转换为整型"></a>字符型转换为整型</h4><p>C 语言没有指定 char 类型的变量是无符号变量（unsigned）还是带符号变量（signed）。当把一个 char 类型的值转换为 int 类型的值时，对于不同的机器，其结果有可能为负整数，这反映了不同机器结构之间的区别。</p>
<p>在某些机器中，如果 char 类型值的最左一位为 1，则转换为负整数（进行“符号扩展”）。而在另一些机器中，会在 char 类型值的左边添加 0，这样导致的转换结果值总是正值。</p>
<p>为了保证程序的可移植性，如果要在 char 类型的变量中存储非字符数据，最好指定 signed 或 unsigned 限定符。</p>
<h4 id="转换规则"><a href="#转换规则" class="headerlink" title="转换规则"></a>转换规则</h4><p>详见附录 A.6</p>
<p>表达式中 float 类型的操作数不会自动转换为 double 类型，这种设计考虑到节省空间和机器执行时间的需要。</p>
<p>在把参数传递给函数时也可能进行类型转换。在没有函数原型的情况下，char 与 short 类型都将被转换为 int 类型，float 类型也将被转换为 double 类型。因此，即使调用函数的参数为 char 或 float 类型，我们也把函数参数声明为 int 或 double 类型。</p>
<h3 id="按位运算符"><a href="#按位运算符" class="headerlink" title="按位运算符"></a>按位运算符</h3><p>C 语言提供了 6 个只能作用于整型操作数（带符号或无符号的 char、short、int 与 long 类型）的操作运算符。</p>
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>&amp;</code></td>
<td style="text-align:center">按位与（AND）</td>
</tr>
<tr>
<td style="text-align:center"><code>｜</code></td>
<td style="text-align:center">按位或（OR）</td>
</tr>
<tr>
<td style="text-align:center"><code>^</code></td>
<td style="text-align:center">按位异或（XOR）</td>
</tr>
<tr>
<td style="text-align:center"><code>&lt;&lt;</code></td>
<td style="text-align:center">左移</td>
</tr>
<tr>
<td style="text-align:center"><code>&gt;&gt;</code></td>
<td style="text-align:center">右移</td>
</tr>
<tr>
<td style="text-align:center"><code>~</code></td>
<td style="text-align:center">按位求反（一元运算符）</td>
</tr>
</tbody>
</table>
<p>按位与运算符<code>&amp;</code>常用于屏蔽某些二进制位，例如<code>n = n &amp; 0177</code>将 n 中除 7 个低二进制位外的其他各位均置为 0（注意 0177 是八进制，转换为二进制位 1111111）。</p>
<p>按位或运算符<code>|</code>常用于将某些二进制位置为 1，例如<code>x = x | SET_ON;</code>将 x 中对应于 SET_ON 中为 1 的那些二进制位置为 1。 </p>
<p>在对 unsigned 类型的无符号值进行右移位时，左边空出的部分用 0 填补；当对 signed 类型的带符号值进行右移时，某些机器将对左边空出的部分用符号位填补（即“算术移位”，正负不变），而另一些机器则对左边空出的部分用 0 填补（即“逻辑移位”，取绝对值）。</p>
<p>一元运算符<code>~</code>用于求整数的二进制反码，例如<code>x = x &amp; ~077</code>将把 x 的最后六位设置为 0（注意 077 是八进制，转换为二进制位 111111）。</p>
<h2 id="第-4-章-函数与程序结构"><a href="#第-4-章-函数与程序结构" class="headerlink" title="第 4 章  函数与程序结构"></a>第 4 章  函数与程序结构</h2><h3 id="作用域规则"><a href="#作用域规则" class="headerlink" title="作用域规则"></a>作用域规则</h3><p>由于 C 语言不允许在一个函数中定义其他函数，因此函数本身是“外部的”。外部变量或函数的作用域从声明它的地方开始，到其所在的（待编译的）文件的末尾结束。</p>
<p>如果要在外部变量的定义之前使用该变量，或者外部变量的定义与变量的使用不在同一个源文件中，则必须在相应的变量声明中强制性使用关键字 extern。</p>
<p>外部变量的定义中必须指定数组的长度，但 extern 声明则不一定要指定数组的长度。</p>
<h3 id="静态变量"><a href="#静态变量" class="headerlink" title="静态变量"></a>静态变量</h3><p>用 static 声明限定外部变量与函数，可以<strong>将其后声明的对象的作用域限定为被编译源文件的剩余部分</strong>。</p>
<p>static 也可用于声明内部变量。static 类型的内部变量与自动变量不同的是，不管其所在函数是否被调用，它一直存在，而不像自动变量那样，随着所在函数的被调用和退出而存在和消失。换句话说，<strong>static 类型的内部变量是一种只能在某个特定函数中使用但一直占据存储空间的变量</strong>。</p>
<h3 id="寄存器变量"><a href="#寄存器变量" class="headerlink" title="寄存器变量"></a>寄存器变量</h3><p>register 声明只适用于自动变量以及函数的形式参数，它告诉编译器，它所声明的变量在程序中使用频率较高，可以放在寄存器中。然而，编译器可以忽略过量的或不支持的寄存器变量声明，所以每个函数中实际只有很少的变量可以保存在寄存器中，且只允许某些类型的变量。无论寄存器变量实际是不是存放在寄存器中，它的地址都不能访问。</p>
<h3 id="程序块结构"><a href="#程序块结构" class="headerlink" title="程序块结构"></a>程序块结构</h3><p><strong>C 语言有块作用域</strong>。在<code>{</code>和<code>}</code>构成的程序块中，局部变量（块开头声明的变量）可以隐藏程序块外同名的变量。自动变量（包括形式参数）也可以隐藏同名的外部变量与函数。</p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>在不进行显式初始化的情况下，<strong>外部变量和静态变量</strong>都将被初始化为 0，而<strong>自动变量和寄存器变量</strong>的初值则没有定义（即初值为无用的信息）。</p>
<p>对于<strong>外部变量与静态变量</strong>来说，初始化表达式必须是<strong>常量表达式</strong>，且只初始化一次。</p>
<p>对于<strong>自动变量和寄存器变量</strong>来说，初始化表达式可以不是<strong>常量表达式</strong>；表达式中可以包含任意在此表达式之前已经定义的值，包括函数调用。</p>
<h3 id="C-预处理器"><a href="#C-预处理器" class="headerlink" title="C 预处理器"></a>C 预处理器</h3><p>从概念上讲，预处理器是编译过程中单独执行的第一个步骤。</p>
<h4 id="文件包含"><a href="#文件包含" class="headerlink" title="文件包含"></a>文件包含</h4><p><code>#include &quot;文件名&quot;</code>或<code>#include &lt;文件名&gt;</code>的行都被替换为由<em>文件名</em>指定的文件的内容。<code>#include &quot;文件名&quot;</code>在源文件所在位置查找该文件；没有找到或<code>#include &lt;文件名&gt;</code>则根据相应规则查找该文件。</p>
<h4 id="宏替换"><a href="#宏替换" class="headerlink" title="宏替换"></a>宏替换</h4><p>想将一个较长的宏定义分成若干行，需要在持续的行末尾加上一个反斜杠符<code>\</code>。</p>
<p>宏定义也可以带参数，例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> max(A, B)  ((A) &gt; (B) ? (A) : (B))</span></div><div class="line"></div><div class="line"><span class="comment">// 使用语句</span></div><div class="line">x = max(p+q, r+s);</div><div class="line"><span class="comment">// 将被替换为</span></div><div class="line"><span class="comment">// x = ((p+q) &gt; (r+s) ? (p+q) : (r+s));</span></div></pre></td></tr></table></figure>
<p>可以看到，要适当使用圆括号以保证计算次序的正确性。</p>
<p>可以通过<code>#undef</code>指令取消名字的宏定义。</p>
<p>如果在替换文本中，参数名以<code>#</code>作为前缀则结果将被扩展为由实际参数替换该参数的带引号的字符串。例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> dprint(expr) printf(#expr <span class="meta-string">" = %g\n"</span>, expr)</span></div><div class="line"></div><div class="line"><span class="comment">// 使用语句</span></div><div class="line">dprint(x/y);</div><div class="line"><span class="comment">// 该宏将被扩展为</span></div><div class="line"><span class="comment">// dprint("x/y" " = %g\n", x/y)</span></div></pre></td></tr></table></figure>
<p>预处理器运算符<code>##</code>为宏扩展提供了一种连接实际参数的手段。如果替换文本中的参数与<code>##</code>相邻，则该参数将被实际参数替换，<code>##</code>与前后的空白符将被删除，并对替换后的结果重新扫描。例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> paste(front, back) front ## back</span></div></pre></td></tr></table></figure>
<p>因此，宏调用<code>paste(name, 1)</code>的结果将建立记号<code>name1</code>。</p>
<h4 id="条件包含"><a href="#条件包含" class="headerlink" title="条件包含"></a>条件包含</h4><p><code>#if</code>语句对其中的常量整型表达式（其中不能包含<code>sizeof</code>、类型转换运算符或<code>enum</code>常量）进行求值，若该表达式的值不等于 0，则包含其后的各行，直到遇到<code>#endif</code>、<code>#elif</code>或<code>#else</code>语句为止。</p>
<p>在<code>#if</code>语句中可以使用表达式<code>defined(名字)</code>，当名字已经定义时其值为 1，否则为 0。</p>
<p>C 语言专门定义了两个预处理语句<code>#ifdef</code>与<code>#ifndef</code>，它们用来测试某个名字是否已经定义。</p>
<h2 id="第-5-章-函数与程序结构"><a href="#第-5-章-函数与程序结构" class="headerlink" title="第 5 章  函数与程序结构*"></a>第 5 章  函数与程序结构*</h2><p><strong>指针</strong>是一种<strong>保存变量地址</strong>的变量。</p>
<p>ANSI C 使用类型<code>void*</code>（指向<code>void</code>的指针）代替<code>char*</code>作为通用指针的类型。</p>
<h3 id="指针与地址"><a href="#指针与地址" class="headerlink" title="指针与地址"></a>指针与地址</h3><p>指针是能够存放一个地址的一组存储单元（通常是两个或四个字节）。</p>
<p>一元运算符<code>&amp;</code>可用于<strong>取一个对象的地址</strong>。因此，下列语句：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">p = &amp;c;</div></pre></td></tr></table></figure>
<p>将把 c 的地址赋值给变量 p，我们称 p 为“指向” c 的指针。地址运算符<code>&amp;</code>只能应用于<strong>内存</strong>中的对象，即变量和数组元素。它不能作用于表达式、常量或 register 类型的变量。</p>
<p>一元运算符<code>*</code>是<strong>间接寻址</strong>或<strong>间接引用</strong>运算符。<strong>当它作用于指针时，将访问指针所指向的对象</strong>。如果指针 ip 指向整型变量 x，那么在 x 可以出现的任何上下文中都可以使用<code>*ip</code>代替：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> x = <span class="number">1</span>, y = <span class="number">2</span>, z[<span class="number">10</span>];</div><div class="line"><span class="keyword">int</span> *ip;    <span class="comment">/* ip 是指向 int 类型的指针 */</span></div><div class="line"></div><div class="line">ip = &amp;x;    <span class="comment">/* ip 现在指向 x */</span></div><div class="line">y = *ip;    <span class="comment">/* y 的值现在为 1 */</span></div><div class="line">*ip = <span class="number">0</span>;    <span class="comment">/* x 的值现在为 0 */</span></div><div class="line">ip = &amp;z[<span class="number">0</span>];    <span class="comment">/* ip 现在指向 z[0] */</span></div></pre></td></tr></table></figure>
<p>注意：类似<code>*</code>和<code>++</code>这样的一元运算符遵循<strong>从右至左</strong>的结合顺序。例如，语句<code>(*ip)++</code>中的圆括号是必需的，否则该表达式将对 ip 进行加一运算，而不是对 ip 指向的对象进行加一运算。</p>
<h3 id="指针和函数参数"><a href="#指针和函数参数" class="headerlink" title="指针和函数参数"></a>指针和函数参数</h3><p>C 语言是以<strong>传值</strong>的方式将参数值传递给被调用函数，因此被调用函数不能直接修改主调函数中变量的值。但指针参数使得被调用函数能够访问和修改主调函数中对象的值。</p>
<p>由于一元运算符<code>&amp;</code>用来取变量的地址，这样<code>&amp;a</code>就是一个指向变量 a 的指针。</p>
<h3 id="指针和数组"><a href="#指针和数组" class="headerlink" title="指针和数组"></a>指针和数组</h3><p><strong>数组名所代表的就是该数组最开始的一个元素的地址</strong>，所以，赋值语句<code>pa = &amp;a[0]</code>也可以写成<code>pa = a</code>。<code>*(pa+1)</code>引用的是数组元素<code>a[1]</code>的内容。<code>&amp;a[i]</code>和<code>a+i</code>的含义也是相同的。</p>
<p>但是，数组名和指针之间有一个不同之处。<strong>指针是一个变量，而数组名不是</strong>。因此，类似于<code>a = pa</code>和<code>a++</code>形式的语句是非法的。</p>
<p>如果将数组名传递给函数，函数可以根据情况判定是按照数组处理还是按照指针处理。</p>
<h3 id="地址算术运算"><a href="#地址算术运算" class="headerlink" title="地址算术运算"></a>地址算术运算</h3><p>C 语言保证，0 永远不是有效的数据地址。因此，若需要返回指针的函数返回 0，则表示发生了异常事件。</p>
<p>指针与整数之间不能相互转换，但 0 是唯一的例外：常量 0 可以赋值给指针，指针也可以和常量 0 进行比较。程序中经常用符号 NULL 代替常量 0，这样便于更清晰地说明常量 0 是指针的一个特殊值。</p>
<p>如果指针 p 和 q 指向同一个数组的成员，那么它们之间就可以进行关系比较运算。同时，这两个指针的减法运算也有意义：若 p &lt; q，那么 q-p+1 就是位于 p 和 q 指向的元素之间的元素的数目。 </p>
<p><strong>有效的指针运算</strong>包括：</p>
<ul>
<li><strong>相同类型</strong>指针之间的赋值运算（两个指针之一是<code>void*</code>类型的情况除外）；</li>
<li>指针同整数之间的加法或减法运算；</li>
<li>指向<strong>相同数组</strong>中元素的两个指针间的减法或比较运算；</li>
<li>将指针赋值为 0 或指针与 0 之间的比较运算。</li>
</ul>
<h3 id="字符指针与函数"><a href="#字符指针与函数" class="headerlink" title="字符指针与函数"></a>字符指针与函数</h3><p>字符串常量是一个字符数组。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">printf</span>(<span class="string">"hello, world\n"</span>);</div></pre></td></tr></table></figure>
<p>当类似于这样的一个字符串出现在程序中时，实际上是通过<strong>字符指针</strong>访问该字符串的。在上述语句中，<code>printf</code>接受的是<strong>一个指向字符数组第一个字符的指针</strong>。也就是说，字符串常量可通过一个指向其第一个元素的指针访问。</p>
<p>语句<code>pmessage = &quot;now is the time&quot;;</code>将把一个指向该字符数组的指针赋值给<code>pmessage</code>。<strong>该过程并没有进行字符串的复制，而只是涉及到指针的操作。</strong>C 语言没有提供将整个字符串作为一个整体进行处理的运算符。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">char</span> amessage[] = <span class="string">"now is the time"</span>;    <span class="comment">/* 定义一个数组 */</span></div><div class="line"><span class="keyword">char</span> *pmessage = <span class="string">"now is the time"</span>;     <span class="comment">/* 定义一个指针 */</span></div></pre></td></tr></table></figure>
<p>上述声明中，数组中单个字符可以进行修改，但<code>amessage</code>始终指向同一个存储位置；另一方面，<code>pmessage</code>是一个指针，之后可以被修改以指向其他地址，但如果试图修改字符串的内容，结果是没有定义的。</p>
<h3 id="指针数组以及指向指针的指针"><a href="#指针数组以及指向指针的指针" class="headerlink" title="指针数组以及指向指针的指针"></a>指针数组以及指向指针的指针</h3><p>由于<strong>指针本身也是变量</strong>，所以它们也可以像其他变量一样存储在数组中。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">char</span> *lineptr[MAXLINES]</div></pre></td></tr></table></figure>
<p>表示<code>lineptr</code>是一个<strong>指针数组</strong>。详细地说，它是一个具有 MAXLINES 个元素的一维数组，其中数组的每个元素是一个指向字符类型对象的指针。也就是说，<code>lineptr[i]</code>是一个字符指针，而<code>*lineptr[i]</code>是该指针指向的第 i 个文本行的首字母。</p>
<p>每执行一次自增运算，都使得<code>*lineptr</code>指向下一行。</p>
<h3 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组*"></a>多维数组*</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">daytab[i][j]    <span class="comment">/* [行][列] */</span></div></pre></td></tr></table></figure>
<p>如果将二维数组作为参数传递给函数，那么在函数的参数声明中必须<strong>指明数组的列数</strong>。数组的行数没有太大关系，因为函数调用时传递的是一个指针，它指向由行向量构成的一维数组。因此：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">f(<span class="keyword">int</span> daytab[<span class="number">2</span>][<span class="number">13</span>]) &#123; ... &#125;</div></pre></td></tr></table></figure>
<p>也可以写成：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">f(<span class="keyword">int</span> daytab[][<span class="number">13</span>]) &#123; ... &#125;</div></pre></td></tr></table></figure>
<p>还可以写成：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">f(<span class="keyword">int</span> (*daytab)[<span class="number">13</span>]) &#123; ... &#125;</div></pre></td></tr></table></figure>
<p>这种声明形式表明参数是一个指针，它指向具有 13 个整型元素的一维数组（包裹在外的第二维数组的首地址）。因为<strong>方括号<code>[]</code>的优先级高于<code>*</code>的优先级</strong>，所以上述声明中必须使用圆括号。如果去掉括号，则声明变为</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> *daytab[<span class="number">13</span>]</div></pre></td></tr></table></figure>
<p>相当于声明了一个数组，该数组有 13 个元素，其中每个元素都是一个指向整型对象的指针。</p>
<p>一般来说，除数组的第一维（下标）可以不指定大小外，其余各维都必须明确指定大小。</p>
<h3 id="指针与多维数组"><a href="#指针与多维数组" class="headerlink" title="指针与多维数组"></a>指针与多维数组</h3><p>假如有下面两个定义：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> a[<span class="number">10</span>][<span class="number">20</span>];</div><div class="line"><span class="keyword">int</span> *b[<span class="number">10</span>];</div></pre></td></tr></table></figure>
<p>从语法角度讲，<code>a[3][4]</code>和<code>b[3][4]</code>都是对一个 int 对象的合法应用。但 a 是一个真正的二维数组，它分配了 200 个 int 类型长度的存储空间；</p>
<p>而对于 b 来说，该定义仅仅分配了 10 个指针，并且没有对它们初始化。假定 b 的每个元素都指向一个具有 20 个元素的数组，那么编译器就要为它分配 200 个 int 类型长度的存储空间以及 10 个指针的存储空间。</p>
<p>指针数组的一个重要优点在于，数组的每一行长度可以不同。</p>
<h3 id="命令行参数"><a href="#命令行参数" class="headerlink" title="命令行参数"></a>命令行参数</h3><p>根据 C 语言的约定，<code>argv[0]</code>的值是启动该程序的程序名，因此<code>argc</code>的值至少为 1。ANSI 标准要求<code>argv[argc]</code>的值必须为一空指针。</p>
<h3 id="指向函数的指针"><a href="#指向函数的指针" class="headerlink" title="指向函数的指针"></a>指向函数的指针</h3><p>在 C 语言中，函数本身不是变量，但<strong>可以定义指向函数的指针</strong>。</p>
<p>和数组名一样，当一个变量为函数的地址时，前面不需要加上取地址符<code>&amp;</code>；</p>
<p>由于任何类型的指针都可以转换为<code>void *</code>类型，并且在将它转换为原来的类型时不会丢失信息，所以，调用函数时可以将参数强制转换为<code>void*</code>类型。比较函数的参数也要执行这种类型的转换。这种转换通常不会影响到数据的实际表示，但要确保编译器不会报错。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> (*comp)(<span class="keyword">void</span> *, <span class="keyword">void</span> *)</div></pre></td></tr></table></figure>
<p>表明<code>comp</code>是一个<strong>指向函数的指针</strong>，该函数具有两个<code>void*</code>类型的参数，其返回值类型为<code>int</code>。<code>*comp</code>代表一个函数。</p>
<h3 id="复杂声明"><a href="#复杂声明" class="headerlink" title="复杂声明"></a>复杂声明</h3><p>C 语言的复杂声明容易让人混淆，因为 C 语言的声明不能从左至右阅读，并且使用了太多的圆括号。例如下面两个声明：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* f: 是一个函数，它返回一个指向 int 类型的指针 */</span></div><div class="line"><span class="function"><span class="keyword">int</span> *<span class="title">f</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line"><span class="comment">/* pf: 是一个指向函数的指针，该函数返回一个 int 类型的对象 */</span></div><div class="line"><span class="keyword">int</span> (*pf)();</div></pre></td></tr></table></figure>
<p>他们之间的含义差别说明：<code>*</code>是一个前缀运算符，其优先级低于<code>()</code>。</p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>ANSI 标准在结构方面最主要的变化是定义了结构的赋值操作–结构可以拷贝、赋值、传递给函数，函数也可以返回结构类型的返回值。</p>
<h3 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">point</span> &#123;</span></div><div class="line">    <span class="keyword">int</span> x;</div><div class="line">    <span class="keyword">int</span> y;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>关键字 struct 引入结构声明。结构声明由包含在花括号内的一系列声明组成。关键字 struct 后面的名字是可选的，称为<strong>结构标记</strong>。结构标记用于为结构命名，在定义后，结构标记就代表花括号内的声明，可以用它作为该声明的简写形式。</p>
<p>结构中定义的变量称为<strong>成员</strong>。<strong>结构成员、结构标记和普通变量（即非成员）可以采用相同的名字</strong>，因为通过上下文分析总可以对它们进行区分，因此不会冲突。另外，不同结构中的成员可以使用相同的名字。</p>
<p>struct 声明定义了一种数据类型。在标志结构成员表结束的右花括号之后可以跟一个变量表，这与其他基本类型的变量声明是相同的。例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> &#123;</span> ... &#125; x, y, z;</div></pre></td></tr></table></figure>
<p>如果结构声明的后面<strong>不带变量表</strong>，则<strong>不需要为它分配存储空间</strong>，它仅仅描述了一个结构的模版或轮廓。但是，如果结构声明中带有标记，那么在以后定义结构实例时便可使用该标记定义，例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">point</span> <span class="title">pt</span>;</span></div></pre></td></tr></table></figure>
<p>结构的<strong>初始化</strong>可以在定义的后面使用初值表进行，初值表中同每个成员对应的初值必须是常量表达式，例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">point</span> <span class="title">maxpt</span> = &#123;</span> <span class="number">320</span>, <span class="number">200</span> &#125;;</div></pre></td></tr></table></figure>
<p>自动结构也可以通过赋值初始化，还可以通过调用返回相应类型结构的函数进行初始化。</p>
<h3 id="结构和函数"><a href="#结构和函数" class="headerlink" title="结构和函数"></a>结构和函数</h3><p>如果传递给函数的结构很大，使用<strong>指针</strong>方式的效率通常比复制整个结构的效率要高。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">point</span> <span class="title">origin</span>, *<span class="title">pp</span>;</span></div><div class="line"></div><div class="line">pp = &amp;origin;</div><div class="line"><span class="built_in">printf</span>(<span class="string">"origin is (%d,%d)\n"</span>, (*pp).x, (*pp).y);</div></pre></td></tr></table></figure>
<p>其中，<code>(*pp).x</code>中的圆括号是必须的，因为结构成员运算符<code>.</code>的优先级高于<code>*</code>的优先级。</p>
<p>鉴于结构指针的使用频率非常高，为了使用方便，C 语言对于使用指向结构的指针 p 引用相应结构成员提供另一种简写方式：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">p-&gt;结构成员</div></pre></td></tr></table></figure>
<h3 id="类型定义（typedef）"><a href="#类型定义（typedef）" class="headerlink" title="类型定义（typedef）"></a>类型定义（typedef）</h3><p>typedef 声明并没有创建一个新类型，只是为某个已存在的类型增加了一个新的名称而已。实际上，typedef 类似于 #define 语句，但由于 typedef 是由编译器解释的，因此它的文本替换功能要超过预处理器的能力。</p>
<p>除了使表达方式更简洁之外，使用 typedef 还有两个重要原因：</p>
<ol>
<li>使程序参数化，以提高程序的可移植性；</li>
<li>为程序提供更好的说明。</li>
</ol>
<h2 id="联合"><a href="#联合" class="headerlink" title="联合"></a>联合</h2><p><strong>联合</strong>是可以（在不同时刻）保存不同类型和长度的对象的变量，编译器负责跟踪对象的长度和对齐要求。联合提供了一种方式，以在单块存储区中管理不同类型的数据，而不需要在程序中嵌入任何同机器有关的信息。</p>
<p>联合的目的：一个变量可以合法地保存多种数据类型中任何一种类型的对象。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">union</span> u_tag &#123;</div><div class="line">    <span class="keyword">int</span> ival;</div><div class="line">    <span class="keyword">float</span> fval;</div><div class="line">    <span class="keyword">char</span> *sval;</div><div class="line">&#125; u;</div></pre></td></tr></table></figure>
<p>变量 u 必须足够大，以保存这 3 种类型中最大的一种，具体长度同具体的实现有关。</p>
<p>实际上，联合就是一个结构，它的所有成员相对于基地址的偏移量都为 0，此结构空间要大到足够容纳最“宽”的成员，并且，其对齐方式要适合于联合中所有类型的成员。对联合允许的操作与对结构允许的操作相同。</p>
<p>联合只能用其第一个成员类型的值进行初始化。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我所在的专业没有开设 C 语言的课程，而大一虽然有开设 C++，但一是两门语言还是有一些区别，二是也过去了一年，很多东西都差不多忘干净了。这学期的系统级程序设计课程（即著名的“csapp”）和 C 语言密不可分，因此我借来了《C 程序设计语言》来补一补相关知识，并记了一些笔记。最终这门课拿了满绩，还是对得起自己的付出。&lt;/p&gt;
&lt;p&gt;我认为《C 程序设计语言》是一本很好的 C 语言入门书籍，简洁清晰。这里的笔记也都是 C 语言最基础的语法。越往深里学，越会感觉 C 语言和计算机系统的相辅相成，博大精深，也越烧脑。但是现在都必须要按需所学了，还是希望有机会能够继续深入挖掘 C 语言的精粹。&lt;/p&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="http://kyonhuang.top/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="读书笔记" scheme="http://kyonhuang.top/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="C 语言" scheme="http://kyonhuang.top/tags/C-%E8%AF%AD%E8%A8%80/"/>
    
  </entry>
  
  <entry>
    <title>吴恩达《深度学习》系列课程个人笔记</title>
    <link href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/"/>
    <id>http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/</id>
    <published>2018-01-14T08:50:29.000Z</published>
    <updated>2018-05-10T15:51:14.964Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/Andrew-Ng-Deep-Learning-notes.png" alt="Andrew-Ng-Deep-Learning-notes"></p>
<p>早在吴恩达（deeplearning.ai）的《深度学习》系列课程在网易云课堂刚刚发布时，它就已经躺在我的计划列表中了。当时还没有特别坚定说要深入学习这方面的知识，因此搁置了一段时间。这几个月终于下定决心，排除万难，开始对这个系列的课程进行学习。</p>
<p>这个系列的课程给我的感觉是，对 DL 新人，以及像我这样数学不是非常好的学习者非常友好。吴恩达老师真正做到了深入浅出，但又没有抛弃那些重要的细节。在我一边看视频，一边想看看花书对应章节时，发现晦涩到根本看不动。而这个系列的课程作为入门启蒙，是再合适不过的。</p>
<p>另外，这个系列课程的作业全都是精心设计过的，虽然难度不大，但对巩固视频所学知识、帮助理解细节非常有帮助。如果只是听课而不独立完成作业，我认为和没有学过没有什么区别。我也打算过一段时间再重新将这些作业再写一遍。</p>
<p>在学习的同时，像网上很多同学一样，我也记录了自己的笔记，并将其发布在 Github 上。因为在 Github 上，在 md 文件中用 LaTex 写的公式不能正常显示，之前都是用 MacDown 由 md 文件生成 html，虽然公式可以看了，但是不太美观。之后，我恰好发现了 docsify ，一个可以由 md 文件动态生成文档网站的库。于是折腾了一会，将自己的笔记全部用它生成，最终效果如题图所示，非常美观（虽然折腾的途中也踩了几个小坑）。</p>
<p>因为在学习的过程中，我也看了很多网上的笔记。它们对我起到了很大的帮助，因此我也想将我的笔记分享出来，也许能够帮助到其他的同学。两周前在学完前两门课时，我在知乎的专栏发了一篇<a href="https://zhuanlan.zhihu.com/p/32527718" target="_blank" rel="external">文章</a>（即这篇博文的前身）。到目前为止，知乎的文章收获了 147 个赞，而 Github 上的 repo 得到了 42 个 star。这对我简直是受宠若惊。因此，即使这两周是考试周，我还是抽出时间学完了第三门课，并更新了笔记。一方面，这个系列课程的内容确实非常吸引我，另一方面，也是很多同道中人的认可对我有着很大的鼓励。</p>
<p>第四门课是有关计算机视觉和卷积神经网络的。我们知道近年来深度学习的爆红很大程度上是缘于 2012 年 ImageNet 图像识别比赛中 Hinton 课题组构建的 CNN 网络 AlexNet 有着碾压级的表现，因此我对这门课也是非常期待，希望能够在寒假结束前完成对这门课的学习。</p>
<p>最后，再次将笔记的 Github 的 repo 地址公布如下：</p>
<ul>
<li>笔记：<a href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/">吴恩达《深度学习》系列课程笔记</a></li>
<li>Github 仓库（包含写完的作业）：<a href="https://github.com/bighuang624/Andrew-Ng-Deep-Learning-notes" target="_blank" rel="external">bighuang624/Andrew-Ng-Deep-Learning-notes</a></li>
</ul>
<p>欢迎查阅，欢迎在 Issues 中交流或提出意见，更欢迎 star 一下以兹鼓励！</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/bighuang624/bighuang624.github.io/master/images/Andrew-Ng-Deep-Learning-notes.png&quot; alt=&quot;Andre
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://kyonhuang.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="深度学习" scheme="http://kyonhuang.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达" scheme="http://kyonhuang.top/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    
  </entry>
  
  <entry>
    <title>用浏览器也能挖矿！把力量借给我吧</title>
    <link href="http://kyonhuang.top/miner-for-my-website/"/>
    <id>http://kyonhuang.top/miner-for-my-website/</id>
    <published>2018-01-12T08:46:36.000Z</published>
    <updated>2018-02-05T02:03:31.326Z</updated>
    
    <content type="html"><![CDATA[<p>18.02.05 更新：<strong>挖矿现已停止，一是因为用部分浏览器访问本博客时会因为挖矿被拦截，二是避免对各位读者的电脑造成损伤。因此，下述文字仅是对这次尝试的一个小介绍。</strong></p>
<hr>
<p>昨天读到了余博伦老师的<a href="https://zhuanlan.zhihu.com/p/32853925" target="_blank" rel="external">前端开发者转行挖矿的特别技巧</a>一文，觉得很有意思，于是在 <a href="https://coinhive.com/" target="_blank" rel="external">Coinhive</a> 上折腾了几个小时。通过加了几行 JavaScript 代码，尝试在本博客开启挖门罗币的功能。这意味着，当你阅读本博客的同时，你电脑的 CPU 在帮我做一些计算。我把浏览器挖矿的线程调整有 70% 的空闲时间（即速度只有满速的 30%），因此一般来说对你的电脑运行不会有什么大的影响。而使用手机浏览本博客不会启动挖矿，避免因性能较差而导致手机发热。</p>
<p>其实，由于本博客目前的日均 PV 只有 10 左右，因此实际上在限速后基本挖不了多少。但是这是一次非常有趣的尝试，而且，因为暂时没找到申请 Google 账号以开启 Google Analysis 的方法，我也通过把 Coinhive Dashboard 当作一个更好的访问数据统计，间接了解本博客活跃时段。</p>
<p><img src="/images/miner/Coinhive-Dashboard-Analysis.png" alt="Coinhive-Dashboard-Analysis"></p>
<p>通过这种方式，<strong>阅读本博客进行阅读、学习的行为本身，成为一种对博主的赞赏与激励</strong>，我认为这是一种很有趣的互惠形式的探索。尽管实质上的经济影响极小，但是<strong>你的帮助会鼓励我更勤奋地写高质量的博客</strong>，也为我接触了解现在炙手可热的加密货币提供了途径和动力。</p>
<p><strong>你可以拉到页面最下方查看挖矿的速度和总量</strong>。如果你想对浏览器挖矿有个更直观的感受的话，你可以通过下面这个最简单的实例来查看每秒钟计算出的 hash 数等数据，还可以调整参数以了解其对挖矿速度的影响。</p>
<p><script src="https://authedmine.com/lib/simple-ui.min.js" async></script></p>
<div class="coinhive-miner" style="width: 256px; height: 200px; margin: auto" data-key="QbgpjAPTac4TDxpWZto4zId8XNCiISZo"><br>    <em>Loading…</em><br></div>

<p>而如果你想要了解更多有关门罗币、Coinhive、浏览器挖矿的事情，推荐你阅读文章开头提到的那篇文章，即使不是前端开发者也可以轻松阅读。</p>
<p>最后提一下我对加密货币目前火热的市场的个人观点。对绝大多数普通人（或者说，散户）来说，现在才开始炒币是不会赚的，而且大概率成为韭菜。加密货币的匿名性、无政府监管性使得它有更大的可操作空间。就算侥幸小赚，也很难弥补你付出的时间、精力和焦虑。因此学习可以，发家致富的想法还是尽早掐灭为好。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;18.02.05 更新：&lt;strong&gt;挖矿现已停止，一是因为用部分浏览器访问本博客时会因为挖矿被拦截，二是避免对各位读者的电脑造成损伤。因此，下述文字仅是对这次尝试的一个小介绍。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;昨天读到了余博伦老师的&lt;a href=&quot;https
    
    </summary>
    
      <category term="程序猿喜欢折腾" scheme="http://kyonhuang.top/categories/%E7%A8%8B%E5%BA%8F%E7%8C%BF%E5%96%9C%E6%AC%A2%E6%8A%98%E8%85%BE/"/>
    
    
      <category term="挖矿" scheme="http://kyonhuang.top/tags/%E6%8C%96%E7%9F%BF/"/>
    
      <category term="门罗币" scheme="http://kyonhuang.top/tags/%E9%97%A8%E7%BD%97%E5%B8%81/"/>
    
      <category term="Coinhive" scheme="http://kyonhuang.top/tags/Coinhive/"/>
    
  </entry>
  
  <entry>
    <title>算法一篇通——贪心算法</title>
    <link href="http://kyonhuang.top/greedy-algorithm/"/>
    <id>http://kyonhuang.top/greedy-algorithm/</id>
    <published>2017-12-29T13:24:35.000Z</published>
    <updated>2018-04-25T15:15:36.744Z</updated>
    
    <content type="html"><![CDATA[<p>之前在写<a href="http://kyonhuang.top/dynamic-programming/">算法一篇通——动态规划</a>时，看到不少相关的资料都谈到了贪心算法。原本我对贪心算法的认知比较简单，但是越看越混，尤其是和动态规划的差异，少有文章能说的准确透彻。因此，这几天也对贪心算法加以了解学习。</p>
<p>给出 n 个物体，第 i 个物体重量为 wi，要求选择尽量多的物体，使得总重量不超过 C。对于这个问题，我们很容易想到，因为在对总重量有要求的情况下要选择尽量多的物体，因此挑轻的肯定比挑重的划算。这样，我们将所有物体按重量从小到大排序，依次选择每个物体，直到装不下为止。</p>
<p>这就一种典型的贪心算法，只顾眼前利益，做出局部最优的选择，寄希望于这样的选择能导致全局最优解。</p>
<a id="more"></a>
<h2 id="概念理解"><a href="#概念理解" class="headerlink" title="概念理解"></a>概念理解</h2><p><strong>贪心算法（Greedy Algorithm，又称贪婪算法）</strong>，指在对问题求解时，不从整体最优上加以考虑，而总是做出在当前看来是最好的选择。也就是说，所做出的是在某种意义上的<strong>局部最优解</strong>。</p>
<p>贪心算法<strong>不是对所有问题都能得到整体最优解</strong>，关键是贪心策略的选择，选择的贪心策略必须具备<strong>无后效性</strong>，即某个状态只与它前面出现的状态有关，而独立于后面的状态。</p>
<p>贪心算法的两个性质是<strong>贪心选择性质</strong>和<strong>最优子结构性质</strong>：</p>
<ul>
<li><p><strong>贪心选择性质</strong>：指所求的问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来得到。贪心选择是采用从顶向下、以迭代的方法做出相继选择，每做一次贪心选择，就将所求问题简化为一个规模更小的子问题。</p>
</li>
<li><p><strong>最优子结构（optimal substructure）性质</strong>：如果<strong>原问题的最优解包含的子问题的最优解</strong>，而这些子问题可以独立求解，我们就称该问题具有最优子结构性质。其包含“<strong>全局最优解包含局部最优解</strong>”的思想。</p>
</li>
</ul>
<h2 id="贪心算法与动态规划的区别"><a href="#贪心算法与动态规划的区别" class="headerlink" title="贪心算法与动态规划的区别"></a>贪心算法与动态规划的区别</h2><ol>
<li>贪心算法的每一次操作都<strong>对结果产生直接影响</strong>，而动态规划则不是。</li>
<li>贪心算法对每个子问题的解决方案都做出选择，<strong>不能回退</strong>；动态规划则会根据以前的选择结果对当前进行选择，有回退功能。</li>
<li>动态规划主要运用于二维或三维问题，而贪心一般是一维问题。</li>
</ol>
<p>实际上，贪心算法是一种特殊的动态规划，由于其具有贪心选择性质，保证了子问题只会被计算一次，不会被多次计算。</p>
<p>尽管贪心算法和动态规划都有最优子结构性质，我认为这个性质在两种算法中有着不太一样的含义：贪心的局部最优能达成全局最优，而动态规划的全局最优值中不一定全是局部最优，只是求解全局最优时要以局部最优作为基础。或者，我们可以认为，贪心算法通常都是自顶向下进行设计的，而动态规划则自顶向上。</p>
<h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><p>贪心算法的基本思路是从问题的某一个初始解出发一步一步地进行，根据某个优化测度，每一步都要确保能获得局部最优解。每一步只考虑一个数据，<strong>选取应该满足局部优化的条件</strong>。若下一个数据和部分最优解连在一起不再是可行解时，就不把该数据添加到部分解中，直到把所有数据枚举完，或者不能再添加算法停止。</p>
<h2 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h2><p><img src="/images/brush-is-the-best.png"></p>
<h3 id="菜鸟级"><a href="#菜鸟级" class="headerlink" title="菜鸟级"></a>菜鸟级</h3><p>这里我选了 LeetCode 的第 122 题 Best Time to Buy and Sell Stock II。题目是这样的：给定一个数组，第 i 个元素代表第 i 天石头的买卖价。找到一种赚取最大利润的方法，你可以进行任意次交易，但是不能同时处于两笔交易中（即必须先将手上的石头卖出去才能再买）。</p>
<h4 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h4><p>根据贪心选择的性质，只要能赚到钱，我们就卖掉手上的石头。那么，只要后一天的价格比前一天高，我们就做买入卖出这一笔买卖。于是有代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfit</span><span class="params">(<span class="keyword">int</span>[] prices)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> total = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; prices.length-<span class="number">1</span>; i++)</div><div class="line">        <span class="keyword">if</span> (prices[i+<span class="number">1</span>] &gt; prices[i]) </div><div class="line">            total += prices[i+<span class="number">1</span>]-prices[i];</div><div class="line"></div><div class="line">    <span class="keyword">return</span> total;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这样的思路是简单粗暴而有效的，但是可能需要结合多种情况考虑一下，为什么这样做是对的（我们设第 i 天的价格为 s[i]）：</p>
<ul>
<li>s[i] &lt; s[i+1] &lt; s[i+2]：这样的话，按照之前的解法，相当于省略掉中间那一笔卖出买入，只考虑第 i 天和第 i+2 天；</li>
<li>s[i] &gt; s[i+1] &lt; s[i+2]：这样的话，我们的算法会当作没有买入过第 i 天的石头。</li>
</ul>
<h3 id="普通级"><a href="#普通级" class="headerlink" title="普通级"></a>普通级</h3><h3 id="挑战者级"><a href="#挑战者级" class="headerlink" title="挑战者级"></a>挑战者级</h3><p>这里我选择的是 LeetCode 的第 135 题，是一道 hard 难度的题目。N 个小朋友排排坐，每个小朋友有一个分值。你需要给小朋友发糖，遵循以下规则：</p>
<ul>
<li>每个小朋友保底一块糖；</li>
<li>若比左右邻居得分高，则得到的糖更多。</li>
</ul>
<p>求最少发多少糖。</p>
<h4 id="解答-1"><a href="#解答-1" class="headerlink" title="解答"></a>解答</h4><p>需要拿一个与输入数组同样大小的数组来存储每个孩子的糖果树。</p>
<p>先从 0 开始向右遍历一次：第 0 个孩子先拿一块；i &gt; 0 时，如果 ratings[i] &gt; ratings[i-1]，那么第 i 个孩子在第 i-1 个孩子所拥有的糖果数上多拿一块，否则拿保底的一块。这一次遍历将右边的 rating 比左边大的情况全部搞定。</p>
<p>再从 len-1 开始向左遍历一次：第 len-1 个孩子不变，如果 ratings[i] &lt; ratings[i-1]，那么，除非第 i-1 个孩子本身拥有的糖果数已经比多拿这一块后还要多，否则第 i－1 个孩子在第 i 个孩子所拥有的糖果数上多拿一块。这一次遍历将左边的 rating 比右边大的情况全部搞定，并且不会影响到上一次遍历所完成的工作。</p>
<p>因为每一次发糖都遵循贪心选择性质，最多多给一块，并且没有后效性，因此也是贪心算法的运用。</p>
<p>尽管时间复杂度和空间复杂度都不是最优的，但上述解法能够 AC，并且简洁易懂。当然，这个思路还是比较巧妙的，也很难短时间内想出来。</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>和动态规划一样，贪心算法也扩展许多衍生的问题与算法。例如，深度学习中的梯度下降算法就是贪心的。更著名的一些如下。</p>
<h3 id="哈夫曼编码"><a href="#哈夫曼编码" class="headerlink" title="哈夫曼编码"></a>哈夫曼编码</h3><p>我们可以用 01 编码串来代表一个字符，例如 a 为 0，c 为 00，f 为 1100。这样，可能因为其中一个字符的编码是另一个字符的前缀而导致歧义。满足<strong>任何一个编码都不是另一个的前缀的编码</strong>被称为<strong>前缀码（Prefix Code）</strong>。</p>
<p>这样，我们很容易想到，给定 n 个字符在文件中的出现频率 ci，求一套总长度（每个字符的频率与编码长度乘积的总和）尽量小的编码。根据一个已知结论：<strong>任何一个前缀编码都可以表示成每个非叶结点恰好有两个子结点的二叉树</strong>，我们可以通过构造一棵最优的编码树来解决这个问题。</p>
<p><strong>Huffman 算法</strong>：把每个字符看作一个单结点子树放在一个树集合中，每棵子树的权值等于对应字符的频率。每次取权值最小的两棵子树合并成一棵新树，并重新放到集合中。新树的权值等于两棵子树权值之和。</p>
<p>从以下结论可以体现 Huffman 算法是一种贪心算法：</p>
<ul>
<li>设 x 与 y 是频率最小的两个字符，则存在前缀码使得 x 和 y 具有相同码长，且仅有最后一位编码不同。这体现了贪心算法的<strong>贪心选择性质</strong>。</li>
<li>设 T 是加权字符集 C 的最优编码树，x 和 y 是树 T 中的两个叶子，且互为兄弟结点，z 是它们的父结点。若把 z 看作具有频率 f(z) = f(x) + f(y) 的字符，则树 T’ = T - {x, y} 是字符集 C’ = C - {x, y}U{z} 的一棵最优编码树。这体现了贪心算法的<strong>最优子结构性质</strong>。</li>
</ul>
<h3 id="Prim-算法-和-Kruskal-算法"><a href="#Prim-算法-和-Kruskal-算法" class="headerlink" title="Prim 算法 和 Kruskal 算法"></a>Prim 算法 和 Kruskal 算法</h3><p>Prim 算法 和 Kruskal 算法都是在加权无向图找到最小生成树的算法，它们也都是贪心算法。</p>
<p><strong>Prim 算法</strong>：每一步都会为一棵生长中的树添加一条边。一开始这棵树只有一个顶点，然后会向它添加 V-1 条边，每次总是将下一条<strong>连接树中的顶点与不在树中的顶点且权重最小的边加入树中</strong>。</p>
<p><strong>Kruskal 算法</strong>：按照边的权重顺序（从小到大）处理它们，将边加入最小生成树中，<strong>加入的边不会与已经加入的边构成环</strong>，直到树中含有 V-1 条边为止。我们从一片由 V 棵单顶点的树构成的森林开始并不断将两颗树合并（用可以找到的最短边），直到只剩下一棵树，它就是最小生成树。</p>
<p>如果你想要更详细地了解这部分内容，可以查看我《算法》笔记的相关章节：<a href="https://github.com/bighuang624/Algorithms-notes/blob/master/%E7%AC%94%E8%AE%B0/4.3_%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91.md" target="_blank" rel="external">Algorithms-notes/笔记/4.3 最小生成树
</a>。</p>
<h3 id="启发式算法"><a href="#启发式算法" class="headerlink" title="启发式算法"></a>启发式算法</h3><p>很多的<strong>启发式算法</strong>（也叫智能算法），例如遗传算法，模拟退火算法，本质上就是<strong>贪心算法和随机化算法结合</strong>。这样的算法结果虽然也是局部最优解，但是比单纯的贪心算法更佳靠近最优解。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>随着第二篇算法学习的总结笔记出炉，我发现除开大二上学期《算法与数据结构》课程提到的基础而有限的算法之外，还有很多算法处于我的认知边缘之外。我准备把对这些算法的学习全部汇总到一个系列，取名为“算法一篇通”，希望写作效果能够恰如其名。</p>
<p>贪心算法也不简单。之后我可能还会再做一些这个方面的题，届时再进行补充。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><h3 id="写作参考"><a href="#写作参考" class="headerlink" title="写作参考"></a>写作参考</h3><ul>
<li><a href="https://baike.baidu.com/item/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/5411800?fr=aladdin" target="_blank" rel="external">贪心算法_百度百科</a></li>
<li>《算法竞赛入门经典（第 2 版）》第 8 章</li>
<li>《算法导论》第 16 章</li>
</ul>
<h3 id="学习参考"><a href="#学习参考" class="headerlink" title="学习参考"></a>学习参考</h3><ul>
<li><a href="http://www.cnblogs.com/heaad/archive/2010/12/20/1911614.html" target="_blank" rel="external">大白话解析模拟退火算法 - 苍梧 - 博客园</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前在写&lt;a href=&quot;http://kyonhuang.top/dynamic-programming/&quot;&gt;算法一篇通——动态规划&lt;/a&gt;时，看到不少相关的资料都谈到了贪心算法。原本我对贪心算法的认知比较简单，但是越看越混，尤其是和动态规划的差异，少有文章能说的准确透彻。因此，这几天也对贪心算法加以了解学习。&lt;/p&gt;
&lt;p&gt;给出 n 个物体，第 i 个物体重量为 wi，要求选择尽量多的物体，使得总重量不超过 C。对于这个问题，我们很容易想到，因为在对总重量有要求的情况下要选择尽量多的物体，因此挑轻的肯定比挑重的划算。这样，我们将所有物体按重量从小到大排序，依次选择每个物体，直到装不下为止。&lt;/p&gt;
&lt;p&gt;这就一种典型的贪心算法，只顾眼前利益，做出局部最优的选择，寄希望于这样的选择能导致全局最优解。&lt;/p&gt;
    
    </summary>
    
      <category term="算法笔记" scheme="http://kyonhuang.top/categories/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="算法" scheme="http://kyonhuang.top/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="贪心算法" scheme="http://kyonhuang.top/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
